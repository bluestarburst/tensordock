This file is a merged representation of a subset of the codebase, containing specifically included files and files not matching ignore patterns, combined into a single document by Repomix.
The content has been processed where empty lines have been removed.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of a subset of the repository's contents that is considered the most important context.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: **/*, .cursorrules, .cursor/rules/*, .clinerules, CLAUDE.md
- Files matching these patterns are excluded: .*.*, **/*.pbxproj, **/node_modules/**, **/dist/**, **/build/**, **/compile/**, **/*.spec.*, **/*.pyc, **/.env, **/.env.*, **/*.env, **/*.env.*, **/*.lock, **/*.lockb, **/package-lock.*, **/pnpm-lock.*, **/*.tsbuildinfo, **/certdata.txt
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Empty lines have been removed from all files
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
core/
  __init__.py
  config.py
  exceptions.py
  logging.py
jupyter_module/
  __init__.py
  jupyter_manager.py
  kernel_manager.py
  session_manager.py
  websocket_manager.py
messaging/
  __init__.py
  action_processor.py
  message_broker.py
  worker_manager.py
services/
  __init__.py
  canvas_service.py
  http_proxy.py
  websocket_bridge.py
  widget_service.py
utils/
webrtc/
  __init__.py
  data_channel.py
  message_handler.py
  peer_manager.py
  signaling.py
__main__.py
.gitignore
.gitmodules
.prettierignore
export.html
README.md
requirements.txt
run_modular.py
server_modular.py
start.sh
test_websocket_bridge.py
test_widgets.py
tmp.ipynb
Untitled.ipynb
view_logs.sh
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".gitignore">
*.bundle.*
lib/
node_modules/
*.log
.eslintcache
.stylelintcache
*.egg-info/
.ipynb_checkpoints
*.tsbuildinfo
tensordock/labextension
# Version file is handled by hatchling
tensordock/_version.py

# Integration tests
ui-tests/test-results/
ui-tests/playwright-report/

# Created by https://www.gitignore.io/api/python
# Edit at https://www.gitignore.io/?templates=python

### Python ###
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
pip-wheel-metadata/
share/python-wheels/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage/
coverage.xml
*.cover
.hypothesis/
.pytest_cache/

# Translations
*.mo
*.pot

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
target/

# pyenv
.python-version

# celery beat schedule file
celerybeat-schedule

# SageMath parsed files
*.sage.py

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# Mr Developer
.mr.developer.cfg
.project
.pydevproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# End of https://www.gitignore.io/api/python

# OSX files
.DS_Store

# Yarn cache
.yarn/

key.pem
cert.pem
server.log

push.sh
</file>

<file path=".gitmodules">
[submodule "tensorboard"]
	path = tensorboard
	url = https://github.com/bluestarburst/tensorboard
</file>

<file path=".prettierignore">
node_modules
**/node_modules
**/lib
**/package.json
!/package.json
tensordock
</file>

<file path="requirements.txt">
aiohappyeyeballs==2.4.3
aiohttp==3.10.10
aioice==0.9.0
aiortc==1.9.0
aiosignal==1.3.1
anyio==4.8.0
argon2-cffi==23.1.0
argon2-cffi-bindings==21.2.0
arrow==1.3.0
asttokens==2.4.1
attrs==24.2.0
av==12.3.0
beautifulsoup4==4.13.3
bleach==6.2.0
certifi==2025.1.31
cffi==1.17.1
charset-normalizer==3.4.1
comm==0.2.2
cryptography==43.0.3
debugpy==1.8.8
decorator==5.1.1
defusedxml==0.7.1
dnspython==2.7.0
executing==2.1.0
fastjsonschema==2.21.1
fqdn==1.5.1
frozenlist==1.5.0
google-crc32c==1.6.0
idna==3.10
ifaddr==0.2.0
ipykernel==6.29.5
ipython==8.26.0
isoduration==20.11.0
jedi==0.19.2
Jinja2==3.1.5
jsonpointer==3.0.0
jsonschema==4.23.0
jsonschema-specifications==2024.10.1
jupyter_client==8.6.2
jupyter_core==5.7.2
jupyter-events==0.12.0
jupyter-kernel-gateway==3.0.1
jupyter_server==2.15.0
jupyter_server_terminals==0.5.3
jupyterlab_pygments==0.3.0
MarkupSafe==3.0.2
matplotlib-inline==0.1.7
mistune==3.1.1
multidict==6.1.0
nbclient==0.10.2
nbconvert==7.16.6
nbformat==5.10.4
nest-asyncio==1.6.0
overrides==7.7.0
packaging==24.2
pandocfilters==1.5.1
parso==0.8.4
pexpect==4.9.0
pip==25.0.1
platformdirs==4.3.6
prometheus_client==0.21.1
prompt_toolkit==3.0.48
propcache==0.2.0
psutil==6.1.0
ptyprocess==0.7.0
pure_eval==0.2.3
pycparser==2.22
pyee==12.0.0
Pygments==2.18.0
pylibsrtp==0.10.0
pyOpenSSL==24.2.1
python-dateutil==2.9.0.post0
python-json-logger==3.2.1
PyYAML==6.0.2
pyzmq==26.2.0
referencing==0.36.2
requests==2.32.3
rfc3339-validator==0.1.4
rfc3986-validator==0.1.1
rpds-py==0.22.3
Send2Trash==1.8.3
setuptools==75.1.0
six==1.16.0
sniffio==1.3.1
soupsieve==2.6
stack-data==0.6.3
terminado==0.18.1
tinycss2==1.4.0
tornado==6.4.1
traitlets==5.14.3
types-python-dateutil==2.9.0.20241206
typing_extensions==4.12.2
uri-template==1.3.0
urllib3==2.3.0
wcwidth==0.2.13
webcolors==24.11.1
webencodings==0.5.1
websocket-client==1.8.0
websockets==13.1
wheel==0.44.0
yarl==1.17.1
</file>

<file path="tmp.ipynb">
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "349fcf350c564c999ca29242a61dad50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pip install transformers[torch] torchvision accelerate datasets evaluate ipywidgets scikit-learn\n",
    "\n",
    "from huggingface_hub import login\n",
    "\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
</file>

<file path="Untitled.ipynb">
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"bye\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
</file>

<file path="core/__init__.py">
"""
Core module for TensorDock server.
Contains configuration, logging, and common utilities.
"""
from .config import ServerConfig
from .logging import setup_logging, debug_log
from .exceptions import TensorDockError, ConnectionError, KernelError
__all__ = [
    'ServerConfig',
    'setup_logging', 
    'debug_log',
    'TensorDockError',
    'ConnectionError',
    'KernelError'
]
</file>

<file path="core/config.py">
"""
Configuration management for TensorDock server.
"""
import os
from dataclasses import dataclass
from typing import List, Optional
# Make aiortc import optional for testing
try:
    from aiortc import RTCConfiguration, RTCIceServer
    AIORTC_AVAILABLE = True
except ImportError:
    AIORTC_AVAILABLE = False
    # Create mock classes for testing
    class RTCConfiguration:
        def __init__(self, ice_servers):
            self.ice_servers = ice_servers
    class RTCIceServer:
        def __init__(self, urls, username=None, credential=None):
            self.urls = urls
            self.username = username
            self.credential = credential
@dataclass
class ServerConfig:
    """Server configuration settings."""
    # Environment detection
    is_local: bool = False
    # TURN server configuration
    turn_server_address: str = "0.0.0.0:6000?transport=udp"
    turn_client_address: str = "0.0.0.0:6000?transport=udp"
    turn_username: str = "user"
    turn_password: str = "password"
    # Jupyter configuration
    jupyter_url: str = "http://localhost:8888"
    jupyter_token: str = "test"
    # Server ports
    vast_udp_port: int = 6000
    vast_tcp_port: int = 8765
    # WebRTC configuration
    rtc_config: Optional[RTCConfiguration] = None
    def __post_init__(self):
        """Initialize configuration from environment variables."""
        self.is_local = os.environ.get('IS_LOCAL', 'false') == 'true'
        # TURN server settings
        self.turn_server_address = os.environ.get(
            'TURN_ADDRESS', 
            f"0.0.0.0:{os.environ.get('VAST_UDP_PORT_70001', self.vast_udp_port)}?transport=udp"
        )
        self.turn_client_address = os.environ.get(
            'TURN_ADDRESS', 
            f"{os.environ.get('PUBLIC_IPADDR', '0.0.0.0')}:{os.environ.get('VAST_UDP_PORT_70001', self.vast_udp_port)}?transport=udp"
        )
        self.turn_username = os.environ.get('TURN_USERNAME', 'user')
        self.turn_password = os.environ.get('TURN_PASSWORD', 'password')
        # Jupyter settings
        self.jupyter_url = os.environ.get('JUPYTER_URL', 'http://localhost:8888')
        self.jupyter_token = os.environ.get('JUPYTER_TOKEN', 'test')
        # Server ports
        self.vast_udp_port = int(os.environ.get('VAST_UDP_PORT_70001', 6000))
        self.vast_tcp_port = int(os.environ.get('VAST_TCP_PORT_70000', 8765))
        # Build WebRTC configuration
        self._build_rtc_config()
    def _build_rtc_config(self):
        """Build WebRTC configuration based on environment."""
        if not AIORTC_AVAILABLE:
            print("⚠️  Warning: aiortc not available, using mock configuration")
            self.rtc_config = None
            return
        ice_servers = [
            RTCIceServer(urls="stun:stun.l.google.com:19302")
        ]
        if not self.is_local:
            ice_servers.append(
                RTCIceServer(
                    urls=f"turn:{self.turn_server_address}",
                    username=self.turn_username,
                    credential=self.turn_password
                )
            )
        self.rtc_config = RTCConfiguration(ice_servers)
    def get_jupyter_headers(self) -> dict:
        """Get headers for Jupyter API requests."""
        return {'Authorization': f'Token {self.jupyter_token}'}
    def get_ws_url(self, kernel_id: str, session_id: str) -> str:
        """Get WebSocket URL for Jupyter kernel."""
        base = self.jupyter_url.split('://')[-1]
        return f"ws://{base}/api/kernels/{kernel_id}/channels?session_id={session_id}"
    def __str__(self) -> str:
        """String representation of configuration."""
        return f"ServerConfig(is_local={self.is_local}, jupyter_url={self.jupyter_url}, tcp_port={self.vast_tcp_port})"
</file>

<file path="core/exceptions.py">
"""
Custom exception classes for TensorDock server.
"""
class TensorDockError(Exception):
    """Base exception for TensorDock server."""
    def __init__(self, message: str, details: dict = None):
        super().__init__(message)
        self.details = details or {}
    def __str__(self):
        if self.details:
            return f"{super().__str__()} - {self.details}"
        return super().__str__()
class ConnectionError(TensorDockError):
    """Raised when there's a connection-related error."""
    pass
class KernelError(TensorDockError):
    """Raised when there's a kernel-related error."""
    pass
class WebRTCError(TensorDockError):
    """Raised when there's a WebRTC-related error."""
    pass
class JupyterError(TensorDockError):
    """Raised when there's a Jupyter-related error."""
    pass
class MessageError(TensorDockError):
    """Raised when there's a message processing error."""
    pass
</file>

<file path="jupyter_module/__init__.py">
"""
Jupyter module for TensorDock server.
Handles kernel management, session lifecycle, and WebSocket communication.
"""
from .kernel_manager import KernelManager
from .session_manager import SessionManager
from .websocket_manager import WebSocketManager
from .jupyter_manager import JupyterManager
__all__ = [
    'KernelManager',
    'SessionManager', 
    'WebSocketManager',
    'JupyterManager'
]
</file>

<file path="jupyter_module/jupyter_manager.py">
"""
Unified Jupyter manager for TensorDock server.
Coordinates kernel, session, and WebSocket management.
"""
import asyncio
import json
import datetime
from typing import Optional, Dict, Any, Callable
# Use absolute imports to avoid relative import issues
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from core.logging import LoggerMixin, debug_log
from core.config import ServerConfig
from .kernel_manager import KernelManager
from .session_manager import SessionManager
# from .websocket_manager import WebSocketManager # Removed as WebSocket management is now handled by bridge
class JupyterManager(LoggerMixin):
    """Unified manager for Jupyter integration."""
    def __init__(self, config: ServerConfig):
        self.config = config
        # Component managers
        self.session_manager = SessionManager(config)
        self.kernel_manager = KernelManager(config)
        # Note: WebSocket management is now handled by the WebSocket bridge service
        # State
        self.initialized = False
        self.initialization_task = None
        # Message handling
        self.message_handlers: Dict[str, Callable] = {}
        self.broadcast_callback: Optional[Callable] = None
        # Tasks
        self.message_listener_task = None
    async def initialize(self) -> bool:
        """Initialize the Jupyter manager and create kernel."""
        try:
            debug_log(f"🚀 [Jupyter] Initializing Jupyter manager")
            # Check if we already have a kernel to prevent duplicates
            if self.initialized and self.kernel_manager.kernel_id:
                debug_log(f"⚠️ [Jupyter] Already initialized with kernel, skipping duplicate creation", {
                    "existing_kernel_id": self.kernel_manager.kernel_id,
                    "initialized": self.initialized
                })
                print(f"⚠️ [Jupyter] Already initialized with kernel: {self.kernel_manager.kernel_id}")
                return True
            # Create session
            session_id = await self.session_manager.create_session()
            # Create kernel
            kernel_id = await self.kernel_manager.create_kernel()
            # Connect WebSocket
            # ws_url = self.config.get_ws_url(kernel_id, session_id) # Removed as WebSocket management is now handled by bridge
            # headers = self.config.get_jupyter_headers() # Removed as WebSocket management is now handled by bridge
            # connected = await self.websocket_manager.connect(ws_url, headers) # Removed as WebSocket management is now handled by bridge
            # if not connected: # Removed as WebSocket management is now handled by bridge
            #     raise Exception("Failed to connect WebSocket") # Removed as WebSocket management is now handled by bridge
            # CRITICAL: Set broadcast callback for WebSocket manager to send messages to frontend # Removed as WebSocket management is now handled by bridge
            # if hasattr(self, 'broadcast_callback') and self.broadcast_callback: # Removed as WebSocket management is now handled by bridge
            #     self.websocket_manager.set_broadcast_callback(self.broadcast_callback) # Removed as WebSocket management is now handled by bridge
            #     debug_log(f"📡 [Jupyter] WebSocket broadcast callback set") # Removed as WebSocket management is now handled by bridge
            #     print(f"📡 [Jupyter] WebSocket broadcast callback set") # Removed as WebSocket management is now handled by bridge
            # Start message listener # Removed as WebSocket management is now handled by bridge
            # self.message_listener_task = asyncio.create_task( # Removed as WebSocket management is now handled by bridge
            #     self.websocket_manager.listen_for_messages(self._handle_kernel_message) # Removed as WebSocket management is now handled by bridge
            # ) # Removed as WebSocket management is now handled by bridge
            self.initialized = True
            debug_log(f"🚀 [Jupyter] Jupyter manager initialized successfully", {
                "session_id": session_id,
                "kernel_id": kernel_id,
                # "ws_connected": connected # Removed as WebSocket management is now handled by bridge
            })
            return True
        except Exception as e:
            debug_log(f"❌ [Jupyter] Failed to initialize Jupyter manager", {
                "error": str(e),
                "error_type": type(e).__name__
            })
            return False
    async def _handle_kernel_message(self, message: str):
        """Handle incoming kernel messages."""
        try:
            # Parse message
            msg = json.loads(message)
            msg_type = msg.get('header', {}).get('msg_type', 'unknown')
            debug_log(f"📥 [Jupyter] Kernel message received", {
                "msg_type": msg_type,
                "msg_id": msg.get('header', {}).get('msg_id', 'unknown')
            })
            print(f"📥 [Jupyter] Kernel message: {msg_type}")
            # Store in kernel response queue for processing
            await self.kernel_manager.response_queue.put(msg)
        except Exception as e:
            debug_log(f"❌ [Jupyter] Error handling kernel message", {
                "error": str(e),
                "error_type": type(e).__name__
            })
            print(f"❌ [Jupyter] Error handling kernel message: {e}")
    async def execute_code(self, code: str, cell_id: str) -> Optional[str]:
        """Execute Python code in the kernel."""
        if not self.initialized:
            await self.initialize()
        try:
            debug_log(f"⚡ [Jupyter] Executing code", {
                "cell_id": cell_id,
                "code_length": len(code)
            })
            # Send execute request through WebSocket
            msg_id = await self._send_execute_request(code, cell_id)
            # Wait for execution reply
            execution_count = await self._wait_for_execution_reply(msg_id)
            debug_log(f"⚡ [Jupyter] Code execution completed", {
                "cell_id": cell_id,
                "execution_count": execution_count,
                "msg_id": msg_id
            })
            return execution_count
        except Exception as e:
            debug_log(f"❌ [Jupyter] Code execution failed", {
                "error": str(e),
                "error_type": type(e).__name__
            })
            return None
    async def _send_execute_request(self, code: str, cell_id: str) -> str:
        """Send execute request to kernel."""
        msg_id = str(hash(f"{cell_id}_{datetime.datetime.now().isoformat()}"))
        msg = {
            'header': {
                'msg_id': msg_id,
                'msg_type': 'execute_request',
                'username': 'user',
                'session': 'session',
                'date': datetime.datetime.now().isoformat(),
                'version': '5.0'
            },
            'parent_header': {},
            'metadata': {},
            'content': {
                'code': code,
                'silent': False,
                'store_history': True,
                'user_expressions': {},
                'allow_stdin': False
            }
        }
        # success = await self.websocket_manager.send_message(msg) # Removed as WebSocket management is now handled by bridge
        # if not success: # Removed as WebSocket management is now handled by bridge
        #     raise Exception("Failed to send execute request") # Removed as WebSocket management is now handled by bridge
        return msg_id
    async def _wait_for_execution_reply(self, msg_id: str) -> Optional[int]:
        """Wait for execution reply from kernel."""
        timeout = 30  # 30 second timeout
        start_time = datetime.datetime.now()
        while (datetime.datetime.now() - start_time).seconds < timeout:
            if not self.kernel_manager.response_queue.empty():
                msg = await self.kernel_manager.response_queue.get()
                if (msg.get('parent_header', {}).get('msg_id') == msg_id and 
                    msg.get('msg_type') == 'execute_reply'):
                    execution_count = msg['content'].get('execution_count')
                    self.kernel_manager.execution_count = execution_count
                    return execution_count
            await asyncio.sleep(0.1)
        debug_log(f"⏰ [Jupyter] Execution reply timeout", {
            "msg_id": msg_id,
            "timeout_seconds": timeout
        })
        return None
    async def send_kernel_message(self, message: Dict[str, Any]) -> bool:
        """Send a message to the kernel via WebSocket bridge."""
        if not self.can_handle_kernel_messages():
            debug_log(f"❌ [Jupyter] Cannot send message, not ready for kernel messages", {
                "initialized": self.initialized,
                "kernel_id": self.kernel_manager.kernel_id if self.kernel_manager else None
            })
            print(f"❌ [Jupyter] Cannot send message, not ready for kernel messages")
            print(f"❌ [Jupyter] Initialized: {self.initialized}")
            print(f"❌ [Jupyter] Kernel ID: {self.kernel_manager.kernel_id if self.kernel_manager else None}")
            return False
        try:
            # Extract message details
            msg_type = message.get('header', {}).get('msg_type', 'unknown')
            msg_id = message.get('header', {}).get('msg_id', 'unknown')
            debug_log(f"📤 [Jupyter] Sending kernel message via WebSocket bridge", {
                "msg_type": msg_type,
                "msg_id": msg_id,
                "kernel_id": self.kernel_manager.kernel_id
            })
            # Send message through WebSocket bridge
            if hasattr(self, 'websocket_bridge') and self.websocket_bridge:
                # Create a message with the format expected by WebSocket bridge
                bridge_message = {
                    'instanceId': f"instance_{msg_id}",
                    'kernelId': self.kernel_manager.kernel_id,
                    'data': message
                }
                success = await self.websocket_bridge.send_message(
                    bridge_message['instanceId'],
                    self.kernel_manager.kernel_id,
                    bridge_message['data']
                )
                if success:
                    debug_log(f"✅ [Jupyter] Message sent via WebSocket bridge", {
                        "msg_type": msg_type,
                        "msg_id": msg_id
                    })
                    return True
                else:
                    debug_log(f"❌ [Jupyter] Failed to send message via WebSocket bridge", {
                        "msg_type": msg_type,
                        "msg_id": msg_id
                    })
                    return False
            else:
                debug_log(f"❌ [Jupyter] WebSocket bridge not available", {
                    "msg_type": msg_type,
                    "msg_id": msg_id
                })
                print(f"❌ [Jupyter] WebSocket bridge not available")
                return False
        except Exception as e:
            debug_log(f"❌ [Jupyter] Error sending kernel message", {
                "error": str(e),
                "error_type": type(e).__name__,
                "message": message
            })
            print(f"❌ [Jupyter] Error sending kernel message: {e}")
            return False
    async def restart_kernel(self) -> bool:
        """Restart the current kernel."""
        try:
            debug_log(f"🔄 [Jupyter] Restarting kernel")
            # Cleanup existing components
            await self.cleanup()
            # Reinitialize
            success = await self.initialize()
            if success:
                debug_log(f"🔄 [Jupyter] Kernel restarted successfully")
            else:
                debug_log(f"❌ [Jupyter] Kernel restart failed")
            return success
        except Exception as e:
            debug_log(f"❌ [Jupyter] Kernel restart error", {
                "error": str(e),
                "error_type": type(e).__name__
            })
            return False
    def set_broadcast_callback(self, callback: Callable):
        """Set the callback for broadcasting messages to clients."""
        self.broadcast_callback = callback
        debug_log(f"📡 [Jupyter] Broadcast callback set")
    def set_websocket_bridge(self, websocket_bridge):
        """Set the WebSocket bridge reference for sending kernel messages."""
        self.websocket_bridge = websocket_bridge
        debug_log(f"🔌 [Jupyter] WebSocket bridge reference set")
        print(f"🔌 [Jupyter] WebSocket bridge reference set")
    def can_handle_kernel_messages(self) -> bool:
        """Check if the manager can handle kernel messages."""
        return (self.initialized and 
                # self.websocket_manager and # Removed as WebSocket management is now handled by bridge
                # self.websocket_manager.is_connected() and # Removed as WebSocket management is now handled by bridge
                self.kernel_manager and 
                self.kernel_manager.kernel_id)
    def get_kernel_id(self) -> Optional[str]:
        """Get the current kernel ID."""
        return self.kernel_manager.kernel_id if self.kernel_manager else None
    async def create_kernel(self) -> str:
        """Create a new kernel using the same pattern as initialization."""
        try:
            debug_log(f"🚀 [Jupyter] Creating new kernel from action processor")
            # CRITICAL: Check if we already have a kernel to prevent duplicates
            if self.kernel_manager.kernel_id:
                debug_log(f"⚠️ [Jupyter] Kernel already exists, returning existing ID", {
                    "existing_kernel_id": self.kernel_manager.kernel_id
                })
                print(f"⚠️ [Jupyter] Kernel already exists: {self.kernel_manager.kernel_id}")
                return self.kernel_manager.kernel_id
            # CRITICAL: Check if we're already initialized
            if self.initialized:
                debug_log(f"⚠️ [Jupyter] Already initialized, returning existing kernel", {
                    "kernel_id": self.kernel_manager.kernel_id
                })
                return self.kernel_manager.kernel_id
            # Only create a new kernel if we don't have one and aren't initialized
            debug_log(f"🚀 [Jupyter] No existing kernel found, creating new one")
            # Create session
            session_id = await self.session_manager.create_session()
            # Create kernel
            kernel_id = await self.kernel_manager.create_kernel()
            # Connect WebSocket
            # ws_url = self.config.get_ws_url(kernel_id, session_id) # Removed as WebSocket management is now handled by bridge
            # headers = self.config.get_jupyter_headers() # Removed as WebSocket management is now handled by bridge
            # connected = await self.websocket_manager.connect(ws_url, headers) # Removed as WebSocket management is now handled by bridge
            # if not connected: # Removed as WebSocket management is now handled by bridge
            #     raise Exception("Failed to connect WebSocket") # Removed as WebSocket management is now handled by bridge
            # Set broadcast callback for WebSocket manager # Removed as WebSocket management is now handled by bridge
            # if self.broadcast_callback: # Removed as WebSocket management is now handled by bridge
            #     self.websocket_manager.set_broadcast_callback(self.broadcast_callback) # Removed as WebSocket management is now handled by bridge
            #     debug_log(f"📡 [Jupyter] WebSocket broadcast callback set for new kernel") # Removed as WebSocket management is now handled by bridge
            # Start message listener if not already running # Removed as WebSocket management is now handled by bridge
            # if not self.message_listener_task or self.message_listener_task.done(): # Removed as WebSocket management is now handled by bridge
            #     self.message_listener_task = asyncio.create_task( # Removed as WebSocket management is now handled by bridge
            #         self.websocket_manager.listen_for_messages(self._handle_kernel_message) # Removed as WebSocket management is now handled by bridge
            #     ) # Removed as WebSocket management is now handled by bridge
            # Mark as initialized # Removed as WebSocket management is now handled by bridge
            self.initialized = True # Removed as WebSocket management is now handled by bridge
            debug_log(f"🚀 [Jupyter] New kernel created successfully", {
                "session_id": session_id,
                "kernel_id": kernel_id,
                # "ws_connected": connected # Removed as WebSocket management is now handled by bridge
            })
            return kernel_id
        except Exception as e:
            debug_log(f"❌ [Jupyter] Failed to create new kernel", {
                "error": str(e),
                "error_type": type(e).__name__
            })
            raise
    async def cleanup(self):
        """Clean up resources."""
        try:
            debug_log(f"🧹 [Jupyter] Cleaning up Jupyter manager")
            # Cancel tasks
            if self.message_listener_task:
                self.message_listener_task.cancel()
                try:
                    await self.message_listener_task
                except asyncio.CancelledError:
                    pass
            # Cleanup components
            # if self.websocket_manager: # Removed as WebSocket management is now handled by bridge
            #     await self.websocket_manager.cleanup() # Removed as WebSocket management is now handled by bridge
            if self.kernel_manager:
                await self.kernel_manager.cleanup()
            if self.session_manager:
                await self.session_manager.cleanup()
            # Reset state
            self.initialized = False
            self.message_listener_task = None
            debug_log(f"🧹 [Jupyter] Jupyter manager cleanup completed")
        except Exception as e:
            debug_log(f"❌ [Jupyter] Cleanup error", {
                "error": str(e),
                "error_type": type(e).__name__
            })
    def get_status(self) -> Dict[str, Any]:
        """Get the current status of the Jupyter manager."""
        return {
            'initialized': self.initialized,
            'kernel_id': self.kernel_manager.kernel_id if self.kernel_manager else None,
            # 'websocket_connected': self.websocket_manager.is_connected() if self.websocket_manager else False, # Removed as WebSocket management is now handled by bridge
            'session_id': self.session_manager.get_session_id() if hasattr(self.session_manager, 'get_session_id') else None,
            'message_listener_active': self.message_listener_task and not self.message_listener_task.done()
        }
</file>

<file path="jupyter_module/kernel_manager.py">
"""
Kernel management for Jupyter integration.
Handles kernel creation, execution, and lifecycle management.
"""
import asyncio
import json
import datetime
from typing import Optional, Dict, Any, Callable
from websockets.client import connect
# Use absolute imports to avoid relative import issues
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from core.logging import LoggerMixin, debug_log
from core.config import ServerConfig
class KernelManager(LoggerMixin):
    """Manages Jupyter kernel lifecycle and communication."""
    def __init__(self, config: ServerConfig):
        self.config = config
        self.kernel_id: Optional[str] = None
        self.kernel_ws = None
        self.kernel_status = "disconnected"
        self.execution_count = 0
        # Message handling
        self.message_handlers: Dict[str, Callable] = {}
        self.response_queue = asyncio.Queue()
        # Connection state
        self.connected = False
        self.reconnect_attempts = 0
        self.max_reconnect_attempts = 10
        # Ping task
        self.ping_task = None
    async def create_kernel(self) -> str:
        """Create a new Jupyter kernel."""
        try:
            debug_log(f"🚀 [Kernel] Creating new kernel")
            # Create session first
            session_id = await self._create_session()
            # Get kernel info
            kernel_id = await self._get_kernel_info(session_id)
            # Connect WebSocket
            await self._connect_websocket(session_id, kernel_id)
            self.kernel_id = kernel_id
            self.connected = True
            self.reconnect_attempts = 0
            debug_log(f"🚀 [Kernel] Kernel created successfully", {
                "kernel_id": kernel_id,
                "session_id": session_id,
                "status": "connected"
            })
            return kernel_id
        except Exception as e:
            debug_log(f"❌ [Kernel] Failed to create kernel", {
                "error": str(e),
                "error_type": type(e).__name__
            })
            raise
    async def _create_session(self) -> str:
        """Create a new Jupyter session."""
        import requests
        url = f"{self.config.jupyter_url}/api/sessions"
        headers = self.config.get_jupyter_headers()
        session_data = {
            'name': 'python3',
            'path': '/tmp/test.ipynb',
            'type': 'notebook',
            'kernel': {
                'name': 'python3'
            }
        }
        response = requests.post(url, headers=headers, json=session_data)
        if response.status_code != 201:
            raise Exception(f"Session creation failed: {response.status_code}")
        session_info = json.loads(response.text)
        return session_info['id']
    async def _get_kernel_info(self, session_id: str) -> str:
        """Get kernel information for a session."""
        import requests
        url = f"{self.config.jupyter_url}/api/sessions/{session_id}"
        headers = self.config.get_jupyter_headers()
        response = requests.get(url, headers=headers)
        if response.status_code != 200:
            raise Exception(f"Failed to get session info: {response.status_code}")
        session_info = json.loads(response.text)
        kernel_id = session_info['kernel']['id']
        # Get detailed kernel info
        url = f"{self.config.jupyter_url}/api/kernels/{kernel_id}"
        response = requests.get(url, headers=headers)
        if response.status_code != 200:
            raise Exception(f"Failed to get kernel info: {response.status_code}")
        kernel_info = json.loads(response.text)
        debug_log(f"🔌 [Kernel] Kernel info retrieved", {
            "kernel_id": kernel_id,
            "kernel_name": kernel_info.get('name'),
            "kernel_status": kernel_info.get('execution_state')
        })
        return kernel_id
    async def _connect_websocket(self, session_id: str, kernel_id: str):
        """Connect to kernel WebSocket."""
        ws_url = self.config.get_ws_url(kernel_id, session_id)
        headers = self.config.get_jupyter_headers()
        debug_log(f"🔌 [Kernel] Connecting to WebSocket", {
            "ws_url": ws_url,
            "session_id": session_id,
            "kernel_id": kernel_id
        })
        self.kernel_ws = await connect(ws_url, extra_headers=headers)
        debug_log(f"🔌 [Kernel] WebSocket connected", {
            "ws_status": "open" if self.kernel_ws.open else "closed",
            "session_id": session_id,
            "kernel_id": kernel_id
        })
        # Start ping task
        self.ping_task = asyncio.create_task(self._ping_loop())
    async def _ping_loop(self):
        """Keep WebSocket connection alive with pings."""
        while self.connected and self.kernel_ws and self.kernel_ws.open:
            try:
                await self.kernel_ws.ping()
                await asyncio.sleep(10)  # Ping every 10 seconds
            except Exception as e:
                debug_log(f"❌ [Kernel] Ping failed", {
                    "error": str(e),
                    "error_type": type(e).__name__
                })
                break
    async def execute_code(self, code: str, cell_id: str) -> str:
        """Execute Python code in the kernel."""
        if not self.connected or not self.kernel_ws:
            await self.create_kernel()
        msg_id = await self._send_execute_request(code, cell_id)
        # Wait for execution to complete
        execution_count = await self._wait_for_execution_reply(msg_id)
        debug_log(f"⚡ [Kernel] Code execution completed", {
            "cell_id": cell_id,
            "execution_count": execution_count,
            "msg_id": msg_id
        })
        return execution_count
    async def _send_execute_request(self, code: str, cell_id: str) -> str:
        """Send execute request to kernel."""
        msg_id = str(hash(f"{cell_id}_{datetime.datetime.now().isoformat()}"))
        msg = {
            'header': {
                'msg_id': msg_id,
                'msg_type': 'execute_request',
                'username': 'user',
                'session': 'session',
                'date': datetime.datetime.now().isoformat(),
                'version': '5.0'
            },
            'parent_header': {},
            'metadata': {},
            'content': {
                'code': code,
                'silent': False,
                'store_history': True,
                'user_expressions': {},
                'allow_stdin': False
            }
        }
        await self.kernel_ws.send(json.dumps(msg))
        debug_log(f"📤 [Kernel] Execute request sent", {
            "msg_id": msg_id,
            "cell_id": cell_id,
            "code_length": len(code)
        })
        return msg_id
    async def _wait_for_execution_reply(self, msg_id: str) -> Optional[int]:
        """Wait for execution reply from kernel."""
        timeout = 30  # 30 second timeout
        start_time = datetime.datetime.now()
        while (datetime.datetime.now() - start_time).seconds < timeout:
            if not self.response_queue.empty():
                msg = await self.response_queue.get()
                if (msg.get('parent_header', {}).get('msg_id') == msg_id and 
                    msg.get('msg_type') == 'execute_reply'):
                    execution_count = msg['content'].get('execution_count')
                    self.execution_count = execution_count
                    return execution_count
            await asyncio.sleep(0.1)
        debug_log(f"⏰ [Kernel] Execution reply timeout", {
            "msg_id": msg_id,
            "timeout_seconds": timeout
        })
        return None
    async def send_message(self, message: Dict[str, Any]):
        """Send a message to the kernel."""
        if not self.connected or not self.kernel_ws:
            raise Exception("Kernel not connected")
        await self.kernel_ws.send(json.dumps(message))
        debug_log(f"📤 [Kernel] Message sent to kernel", {
            "msg_type": message.get('header', {}).get('msg_type', 'unknown'),
            "msg_id": message.get('header', {}).get('msg_id', 'unknown')
        })
    async def restart_kernel(self):
        """Restart the current kernel."""
        debug_log(f"🔄 [Kernel] Restarting kernel")
        if self.kernel_ws:
            await self.kernel_ws.close()
        if self.ping_task:
            self.ping_task.cancel()
        self.kernel_id = None
        self.kernel_ws = None
        self.connected = False
        # Create new kernel
        await self.create_kernel()
        debug_log(f"🔄 [Kernel] Kernel restarted successfully")
    async def shutdown_kernel(self):
        """Shutdown the current kernel."""
        debug_log(f"🛑 [Kernel] Shutting down kernel")
        if self.kernel_ws:
            await self.kernel_ws.close()
        if self.ping_task:
            self.ping_task.cancel()
        self.kernel_id = None
        self.kernel_ws = None
        self.connected = False
        debug_log(f"🛑 [Kernel] Kernel shutdown complete")
    def get_status(self) -> Dict[str, Any]:
        """Get current kernel status."""
        return {
            'kernel_id': self.kernel_id,
            'connected': self.connected,
            'status': self.kernel_status,
            'execution_count': self.execution_count,
            'reconnect_attempts': self.reconnect_attempts
        }
    def is_connected(self) -> bool:
        """Check if kernel is connected."""
        return self.connected and self.kernel_ws and self.kernel_ws.open
</file>

<file path="jupyter_module/session_manager.py">
"""
Session management for Jupyter integration.
Handles session creation, validation, and lifecycle management.
"""
import asyncio
import json
import datetime
from typing import Optional, Dict, Any, List
import requests
# Use absolute imports to avoid relative import issues
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from core.logging import LoggerMixin, debug_log
from core.config import ServerConfig
class SessionManager(LoggerMixin):
    """Manages Jupyter session lifecycle and validation."""
    def __init__(self, config: ServerConfig):
        self.config = config
        self.session_id: Optional[str] = None
        self.session_name: str = "python3"
        self.session_path: str = "/tmp/test.ipynb"
        self.session_type: str = "notebook"
        self.kernel_name: str = "python3"
        # Session state
        self.active = False
        self.created_at: Optional[datetime.datetime] = None
        self.last_activity: Optional[datetime.datetime] = None
        # Session validation
        self.validation_interval = 30  # seconds
        self.validation_task = None
    def get_session_id(self) -> Optional[str]:
        """Get the current session ID."""
        return self.session_id
    async def create_session(self) -> str:
        """Create a new Jupyter session."""
        try:
            debug_log(f"📝 [Session] Creating new session")
            url = f"{self.config.jupyter_url}/api/sessions"
            headers = self.config.get_jupyter_headers()
            session_data = {
                'name': self.session_name,
                'path': self.session_path,
                'type': self.session_type,
                'kernel': {
                    'name': self.kernel_name
                }
            }
            response = requests.post(url, headers=headers, json=session_data)
            if response.status_code != 201:
                raise Exception(f"Session creation failed: {response.status_code}")
            session_info = json.loads(response.text)
            self.session_id = session_info['id']
            self.session_name = session_info.get('name', self.session_name)
            self.active = True
            self.created_at = datetime.datetime.now()
            self.last_activity = datetime.datetime.now()
            debug_log(f"📝 [Session] Session created successfully", {
                "session_id": self.session_id,
                "session_name": self.session_name,
                "created_at": self.created_at.isoformat()
            })
            # Start validation task
            self._start_validation_task()
            return self.session_id
        except Exception as e:
            debug_log(f"❌ [Session] Failed to create session", {
                "error": str(e),
                "error_type": type(e).__name__
            })
            raise
    async def validate_session(self, session_id: str) -> bool:
        """Validate if a session is still active."""
        try:
            url = f"{self.config.jupyter_url}/api/sessions/{session_id}"
            headers = self.config.get_jupyter_headers()
            response = requests.get(url, headers=headers)
            if response.status_code != 200:
                debug_log(f"❌ [Session] Session validation failed", {
                    "session_id": session_id,
                    "status_code": response.status_code
                })
                return False
            session_info = json.loads(response.text)
            is_valid = session_info.get('id') == session_id
            if is_valid:
                self.last_activity = datetime.datetime.now()
                debug_log(f"✅ [Session] Session validated", {
                    "session_id": session_id,
                    "session_name": session_info.get('name'),
                    "last_activity": self.last_activity.isoformat()
                })
            else:
                debug_log(f"❌ [Session] Session ID mismatch", {
                    "expected": session_id,
                    "actual": session_info.get('id')
                })
            return is_valid
        except Exception as e:
            debug_log(f"❌ [Session] Session validation error", {
                "session_id": session_id,
                "error": str(e),
                "error_type": type(e).__name__
            })
            return False
    async def validate_kernel(self, kernel_id: str) -> bool:
        """Validate if a kernel is still active."""
        try:
            url = f"{self.config.jupyter_url}/api/kernels/{kernel_id}"
            headers = self.config.get_jupyter_headers()
            response = requests.get(url, headers=headers)
            if response.status_code != 200:
                debug_log(f"❌ [Session] Kernel validation failed", {
                    "kernel_id": kernel_id,
                    "status_code": response.status_code
                })
                return False
            kernel_info = json.loads(response.text)
            is_valid = kernel_info.get('id') == kernel_id
            if is_valid:
                debug_log(f"✅ [Session] Kernel validated", {
                    "kernel_id": kernel_id,
                    "kernel_name": kernel_info.get('name'),
                    "kernel_status": kernel_info.get('execution_state')
                })
            else:
                debug_log(f"❌ [Session] Kernel ID mismatch", {
                    "expected": kernel_id,
                    "actual": kernel_info.get('id')
                })
            return is_valid
        except Exception as e:
            debug_log(f"❌ [Session] Kernel validation error", {
                "kernel_id": kernel_id,
                "error": str(e),
                "error_type": type(e).__name__
            })
            return False
    async def get_session_info(self, session_id: str) -> Optional[Dict[str, Any]]:
        """Get detailed session information."""
        try:
            url = f"{self.config.jupyter_url}/api/sessions/{session_id}"
            headers = self.config.get_jupyter_headers()
            response = requests.get(url, headers=headers)
            if response.status_code != 200:
                return None
            session_info = json.loads(response.text)
            debug_log(f"📋 [Session] Session info retrieved", {
                "session_id": session_id,
                "session_name": session_info.get('name'),
                "kernel_id": session_info.get('kernel', {}).get('id')
            })
            return session_info
        except Exception as e:
            debug_log(f"❌ [Session] Failed to get session info", {
                "session_id": session_id,
                "error": str(e),
                "error_type": type(e).__name__
            })
            return None
    async def list_sessions(self) -> List[Dict[str, Any]]:
        """List all active sessions."""
        try:
            url = f"{self.config.jupyter_url}/api/sessions"
            headers = self.config.get_jupyter_headers()
            response = requests.get(url, headers=headers)
            if response.status_code != 200:
                return []
            sessions = json.loads(response.text)
            debug_log(f"📋 [Session] Listed {len(sessions)} sessions")
            return sessions
        except Exception as e:
            debug_log(f"❌ [Session] Failed to list sessions", {
                "error": str(e),
                "error_type": type(e).__name__
            })
            return []
    async def delete_session(self, session_id: str) -> bool:
        """Delete a session."""
        try:
            url = f"{self.config.jupyter_url}/api/sessions/{session_id}"
            headers = self.config.get_jupyter_headers()
            response = requests.delete(url, headers=headers)
            if response.status_code != 204:
                debug_log(f"❌ [Session] Failed to delete session", {
                    "session_id": session_id,
                    "status_code": response.status_code
                })
                return False
            debug_log(f"🗑️ [Session] Session deleted", {
                "session_id": session_id
            })
            # Update local state if this was our active session
            if self.session_id == session_id:
                self.session_id = None
                self.active = False
                self.last_activity = None
            return True
        except Exception as e:
            debug_log(f"❌ [Session] Failed to delete session", {
                "session_id": session_id,
                "error": str(e),
                "error_type": type(e).__name__
            })
            return False
    def _start_validation_task(self):
        """Start periodic session validation."""
        if self.validation_task:
            self.validation_task.cancel()
        self.validation_task = asyncio.create_task(self._validation_loop())
    async def _validation_loop(self):
        """Periodically validate the active session."""
        while self.active and self.session_id:
            try:
                await asyncio.sleep(self.validation_interval)
                if not await self.validate_session(self.session_id):
                    debug_log(f"⚠️ [Session] Session validation failed, marking as inactive")
                    self.active = False
                    break
            except asyncio.CancelledError:
                break
            except Exception as e:
                debug_log(f"❌ [Session] Validation loop error", {
                    "error": str(e),
                    "error_type": type(e).__name__
                })
                await asyncio.sleep(5)  # Wait before retrying
    def get_status(self) -> Dict[str, Any]:
        """Get current session status."""
        return {
            'session_id': self.session_id,
            'session_name': self.session_name,
            'active': self.active,
            'created_at': self.created_at.isoformat() if self.created_at else None,
            'last_activity': self.last_activity.isoformat() if self.last_activity else None,
            'validation_interval': self.validation_interval
        }
    def is_active(self) -> bool:
        """Check if session is active."""
        return self.active and self.session_id is not None
    async def cleanup(self):
        """Clean up session resources."""
        if self.validation_task:
            self.validation_task.cancel()
            try:
                await self.validation_task
            except asyncio.CancelledError:
                pass
        if self.session_id:
            await self.delete_session(self.session_id)
        self.session_id = None
        self.active = False
        self.created_at = None
        self.last_activity = None
        debug_log(f"🧹 [Session] Session cleanup completed")
</file>

<file path="messaging/__init__.py">
"""
Messaging module for TensorDock server.
Handles message routing, worker management, and action processing.
"""
from .message_broker import MessageBroker
from .worker_manager import WorkerManager
from .action_processor import ActionProcessor
__all__ = [
    'MessageBroker',
    'WorkerManager',
    'ActionProcessor'
]
</file>

<file path="messaging/message_broker.py">
"""
Message broker for TensorDock server.
Handles message routing, queuing, and distribution to appropriate handlers.
"""
import asyncio
import json
import datetime
from typing import Dict, Any, Callable, Optional, List
from collections import defaultdict
# Use absolute imports to avoid relative import issues
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from core.logging import LoggerMixin, debug_log
class MessageBroker(LoggerMixin):
    """Routes and distributes messages to appropriate handlers."""
    def __init__(self):
        # Message queues
        self.action_queue = asyncio.Queue()
        self.input_queue = asyncio.Queue()
        self.response_queue = asyncio.Queue()
        # Message handlers by action type
        self.action_handlers: Dict[str, List[Callable]] = defaultdict(list)
        # Message routing rules
        self.routing_rules: Dict[str, str] = {}
        # Worker manager reference (to be set by server)
        self.worker_manager = None
        # Message statistics
        self.message_stats = {
            'total_messages': 0,
            'messages_by_action': defaultdict(int),
            'messages_by_handler': defaultdict(int),
            'errors': 0,
            'start_time': datetime.datetime.now()
        }
        # Broker state
        self.running = False
        self.processing_task = None
        debug_log(f"📨 [MessageBroker] Message broker initialized")
    def set_worker_manager(self, worker_manager):
        """Set the worker manager reference."""
        self.worker_manager = worker_manager
        debug_log(f"🔗 [MessageBroker] Worker manager reference set")
    def register_handler(self, action: str, handler: Callable, priority: int = 0):
        """Register a handler for a specific action type."""
        self.action_handlers[action].append((priority, handler))
        # Sort handlers by priority (higher priority first)
        self.action_handlers[action].sort(key=lambda x: x[0], reverse=True)
        debug_log(f"➕ [MessageBroker] Handler registered", {
            "action": action,
            "handler": handler.__name__,
            "priority": priority,
            "total_handlers": len(self.action_handlers[action])
        })
    def unregister_handler(self, action: str, handler: Callable):
        """Unregister a handler for a specific action type."""
        if action in self.action_handlers:
            # Remove handler by finding and removing the tuple
            handlers = self.action_handlers[action]
            handlers[:] = [(p, h) for p, h in handlers if h != handler]
            debug_log(f"➖ [MessageBroker] Handler unregistered", {
                "action": action,
                "handler": handler.__name__,
                "remaining_handlers": len(handlers)
            })
    def add_routing_rule(self, action: str, target_queue: str):
        """Add a routing rule for message distribution."""
        self.routing_rules[action] = target_queue
        debug_log(f"🛣️ [MessageBroker] Routing rule added", {
            "action": action,
            "target_queue": target_queue
        })
    async def route_message(self, message: Dict[str, Any]) -> bool:
        """Route a message to the appropriate queue and handlers."""
        try:
            action = message.get('action', 'unknown')
            debug_log(f"📨 [MessageBroker] Routing message", {
                "action": action,
                "message_keys": list(message.keys()),
                "timestamp": datetime.datetime.now().isoformat()
            })
            # Update statistics
            self.message_stats['total_messages'] += 1
            self.message_stats['messages_by_action'][action] += 1
            # Route to appropriate queue based on action type
            if action in self.routing_rules:
                target_queue = self.routing_rules[action]
                if target_queue == 'action':
                    await self.action_queue.put(message)
                    # Also submit to worker manager for processing
                    if self.worker_manager:
                        await self.worker_manager.submit_task(action, message)
                elif target_queue == 'input':
                    await self.input_queue.put(message)
                elif target_queue == 'response':
                    await self.response_queue.put(message)
            # Default routing for common actions
            elif action in ['execute_code', 'comm_msg', 'kernel_message']:
                await self.action_queue.put(message)
                # Also submit to worker manager for processing
                if self.worker_manager:
                    await self.worker_manager.submit_task(action, message)
            elif action == 'input':
                await self.input_queue.put(message)
            else:
                # Unknown action, put in action queue for processing
                await self.action_queue.put(message)
                # Also submit to worker manager for processing
                if self.worker_manager:
                    await self.worker_manager.submit_task(action, message)
            # Notify handlers
            await self._notify_handlers(action, message)
            return True
        except Exception as e:
            self.message_stats['errors'] += 1
            debug_log(f"❌ [MessageBroker] Message routing error", {
                "error": str(e),
                "error_type": type(e).__name__,
                "message": message
            })
            return False
    async def _notify_handlers(self, action: str, message: Dict[str, Any]):
        """Notify all registered handlers for an action."""
        if action in self.action_handlers:
            handlers = self.action_handlers[action]
            debug_log(f"🔔 [MessageBroker] Notifying handlers", {
                "action": action,
                "handler_count": len(handlers)
            })
            # Create tasks for all handlers
            tasks = []
            for priority, handler in handlers:
                try:
                    task = asyncio.create_task(handler(message))
                    tasks.append(task)
                    debug_log(f"🔔 [MessageBroker] Handler task created", {
                        "action": action,
                        "handler": handler.__name__,
                        "priority": priority
                    })
                except Exception as e:
                    debug_log(f"❌ [MessageBroker] Handler task creation error", {
                        "action": action,
                        "handler": handler.__name__,
                        "error": str(e),
                        "error_type": type(e).__name__
                    })
            # Wait for all handlers to complete
            if tasks:
                try:
                    await asyncio.gather(*tasks, return_exceptions=True)
                    debug_log(f"✅ [MessageBroker] All handlers completed", {
                        "action": action,
                        "handler_count": len(tasks)
                    })
                except Exception as e:
                    debug_log(f"❌ [MessageBroker] Handler execution error", {
                        "action": action,
                        "error": str(e),
                        "error_type": type(e).__name__
                    })
    async def broadcast_message(self, message: Dict[str, Any], exclude_client_id: Optional[str] = None):
        """Broadcast a message to all connected clients."""
        try:
            debug_log(f"📤 [MessageBroker] Broadcasting message", {
                "action": message.get('action'),
                "exclude_client_id": exclude_client_id
            })
            # This would integrate with the WebRTC broadcast system
            # For now, we'll just log the broadcast
            debug_log(f"📤 [MessageBroker] Broadcast message logged", {
                "message": message,
                "exclude_client_id": exclude_client_id
            })
            return True
        except Exception as e:
            debug_log(f"❌ [MessageBroker] Broadcast error", {
                "error": str(e),
                "error_type": type(e).__name__
            })
            return False
    def get_queue_status(self) -> Dict[str, Any]:
        """Get status of all message queues."""
        return {
            'action_queue_size': self.action_queue.qsize(),
            'input_queue_size': self.input_queue.qsize(),
            'response_queue_size': self.response_queue.qsize(),
            'total_handlers': sum(len(handlers) for handlers in self.action_handlers.values()),
            'routing_rules': len(self.routing_rules)
        }
    def get_statistics(self) -> Dict[str, Any]:
        """Get message processing statistics."""
        uptime = datetime.datetime.now() - self.message_stats['start_time']
        return {
            'total_messages': self.message_stats['total_messages'],
            'messages_by_action': dict(self.message_stats['messages_by_action']),
            'errors': self.message_stats['errors'],
            'uptime_seconds': uptime.total_seconds(),
            'start_time': self.message_stats['start_time'].isoformat()
        }
    async def start(self):
        """Start the message broker."""
        if self.running:
            return
        self.running = True
        self.processing_task = asyncio.create_task(self._message_processor())
        debug_log(f"🚀 [MessageBroker] Message broker started")
    async def stop(self):
        """Stop the message broker."""
        if not self.running:
            return
        self.running = False
        if self.processing_task:
            self.processing_task.cancel()
            try:
                await self.processing_task
            except asyncio.CancelledError:
                pass
        debug_log(f"🛑 [MessageBroker] Message broker stopped")
    async def _message_processor(self):
        """Background message processor."""
        debug_log(f"⚙️ [MessageBroker] Message processor started")
        while self.running:
            try:
                # Process messages from all queues
                await asyncio.sleep(0.1)
            except asyncio.CancelledError:
                break
            except Exception as e:
                debug_log(f"❌ [MessageBroker] Message processor error", {
                    "error": str(e),
                    "error_type": type(e).__name__
                })
                await asyncio.sleep(1)  # Wait before retrying
        debug_log(f"⚙️ [MessageBroker] Message processor stopped")
    async def cleanup(self):
        """Clean up message broker resources."""
        debug_log(f"🧹 [MessageBroker] Cleaning up message broker")
        await self.stop()
        # Clear queues
        while not self.action_queue.empty():
            try:
                self.action_queue.get_nowait()
                self.action_queue.task_done()
            except:
                pass
        while not self.input_queue.empty():
            try:
                self.input_queue.get_nowait()
                self.input_queue.task_done()
            except:
                pass
        while not self.response_queue.empty():
            try:
                self.response_queue.get_nowait()
                self.response_queue.task_done()
            except:
                pass
        # Clear handlers
        self.action_handlers.clear()
        self.routing_rules.clear()
        debug_log(f"🧹 [MessageBroker] Message broker cleanup completed")
</file>

<file path="messaging/worker_manager.py">
"""
Worker manager for TensorDock server.
Handles background task processing and worker lifecycle management.
"""
import asyncio
import threading
import datetime
from typing import Dict, Any, Callable, Optional, List
from concurrent.futures import ThreadPoolExecutor
# Use absolute imports to avoid relative import issues
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from core.logging import LoggerMixin, debug_log
class WorkerManager(LoggerMixin):
    """Manages background workers and task processing."""
    def __init__(self, max_workers: int = 4):
        self.max_workers = max_workers
        # Worker pools
        self.async_workers: List[asyncio.Task] = []
        self.thread_workers: List[threading.Thread] = []
        self.thread_pool = ThreadPoolExecutor(max_workers=max_workers)
        # Task queues
        self.task_queue = asyncio.Queue()
        self.priority_queue = asyncio.Queue()
        # Worker state
        self.running = False
        self.worker_count = 0
        self.active_tasks = 0
        # Task statistics
        self.task_stats = {
            'total_tasks': 0,
            'completed_tasks': 0,
            'failed_tasks': 0,
            'tasks_by_type': {},
            'start_time': datetime.datetime.now()
        }
        # Task handlers
        self.task_handlers: Dict[str, Callable] = {}
        debug_log(f"👷 [WorkerManager] Worker manager initialized", {
            "max_workers": max_workers
        })
    def register_task_handler(self, task_type: str, handler: Callable):
        """Register a handler for a specific task type."""
        self.task_handlers[task_type] = handler
        debug_log(f"➕ [WorkerManager] Task handler registered", {
            "task_type": task_type,
            "handler": handler.__name__,
            "total_handlers": len(self.task_handlers)
        })
    def unregister_task_handler(self, task_type: str):
        """Unregister a task handler."""
        if task_type in self.task_handlers:
            del self.task_handlers[task_type]
            debug_log(f"➖ [WorkerManager] Task handler unregistered", {
                "task_type": task_type,
                "total_handlers": len(self.task_handlers)
            })
    async def submit_task(self, task_type: str, data: Dict[str, Any], priority: int = 0) -> str:
        """Submit a task for processing."""
        try:
            task_id = f"{task_type}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S_%f')}"
            task = {
                'id': task_id,
                'type': task_type,
                'data': data,
                'priority': priority,
                'submitted_at': datetime.datetime.now(),
                'status': 'pending'
            }
            if priority > 0:
                await self.priority_queue.put(task)
            else:
                await self.task_queue.put(task)
            self.task_stats['total_tasks'] += 1
            self.task_stats['tasks_by_type'][task_type] = self.task_stats['tasks_by_type'].get(task_type, 0) + 1
            debug_log(f"📋 [WorkerManager] Task submitted", {
                "task_id": task_id,
                "task_type": task_type,
                "priority": priority,
                "queue_size": self.task_queue.qsize() + self.priority_queue.qsize()
            })
            return task_id
        except Exception as e:
            debug_log(f"❌ [WorkerManager] Task submission error", {
                "error": str(e),
                "error_type": type(e).__name__,
                "task_type": task_type
            })
            raise
    async def start_workers(self):
        """Start the worker pool."""
        if self.running:
            return
        self.running = True
        # Start async workers
        for i in range(self.max_workers):
            worker = asyncio.create_task(self._async_worker(f"async_worker_{i}"))
            self.async_workers.append(worker)
        # Start priority worker
        priority_worker = asyncio.create_task(self._priority_worker())
        self.async_workers.append(priority_worker)
        debug_log(f"🚀 [WorkerManager] Workers started", {
            "async_workers": len(self.async_workers),
            "max_workers": self.max_workers
        })
    async def stop_workers(self):
        """Stop all workers."""
        if not self.running:
            return
        self.running = False
        # Cancel async workers
        for worker in self.async_workers:
            worker.cancel()
        # Wait for workers to finish
        if self.async_workers:
            await asyncio.gather(*self.async_workers, return_exceptions=True)
        # Shutdown thread pool
        self.thread_pool.shutdown(wait=True)
        debug_log(f"🛑 [WorkerManager] Workers stopped")
    async def _async_worker(self, worker_name: str):
        """Async worker that processes tasks from the queue."""
        debug_log(f"👷 [WorkerManager] {worker_name} started")
        while self.running:
            try:
                # Get task from queue with timeout
                try:
                    task = await asyncio.wait_for(self.task_queue.get(), timeout=1.0)
                except asyncio.TimeoutError:
                    continue
                if task is None:
                    break
                await self._process_task(task, worker_name)
                self.task_queue.task_done()
            except asyncio.CancelledError:
                break
            except Exception as e:
                debug_log(f"❌ [WorkerManager] {worker_name} error", {
                    "error": str(e),
                    "error_type": type(e).__name__
                })
                await asyncio.sleep(1)  # Wait before retrying
        debug_log(f"👷 [WorkerManager] {worker_name} stopped")
    async def _priority_worker(self):
        """Priority worker that processes high-priority tasks."""
        debug_log(f"👷 [WorkerManager] Priority worker started")
        while self.running:
            try:
                # Get priority task from queue with timeout
                try:
                    task = await asyncio.wait_for(self.priority_queue.get(), timeout=1.0)
                except asyncio.TimeoutError:
                    continue
                if task is None:
                    break
                await self._process_task(task, "priority_worker")
                self.priority_queue.task_done()
            except asyncio.CancelledError:
                break
            except Exception as e:
                debug_log(f"❌ [WorkerManager] Priority worker error", {
                    "error": str(e),
                    "error_type": type(e).__name__
                })
                await asyncio.sleep(1)  # Wait before retrying
        debug_log(f"👷 [WorkerManager] Priority worker stopped")
    async def _process_task(self, task: Dict[str, Any], worker_name: str):
        """Process a single task."""
        task_id = task['id']
        task_type = task['type']
        task_data = task['data']
        try:
            debug_log(f"⚙️ [WorkerManager] Processing task", {
                "worker": worker_name,
                "task_id": task_id,
                "task_type": task_type
            })
            task['status'] = 'processing'
            task['worker'] = worker_name
            task['started_at'] = datetime.datetime.now()
            self.active_tasks += 1
            # Check if we have a handler for this task type
            if task_type in self.task_handlers:
                handler = self.task_handlers[task_type]
                # Execute handler
                if asyncio.iscoroutinefunction(handler):
                    result = await handler(task_data)
                else:
                    # Run in thread pool for sync handlers
                    loop = asyncio.get_event_loop()
                    result = await loop.run_in_executor(self.thread_pool, handler, task_data)
                task['status'] = 'completed'
                task['result'] = result
                task['completed_at'] = datetime.datetime.now()
                self.task_stats['completed_tasks'] += 1
                debug_log(f"✅ [WorkerManager] Task completed", {
                    "worker": worker_name,
                    "task_id": task_id,
                    "task_type": task_type
                })
            else:
                task['status'] = 'failed'
                task['error'] = f"No handler registered for task type: {task_type}"
                task['failed_at'] = datetime.datetime.now()
                self.task_stats['failed_tasks'] += 1
                debug_log(f"❌ [WorkerManager] Task failed - no handler", {
                    "worker": worker_name,
                    "task_id": task_id,
                    "task_type": task_type
                })
        except Exception as e:
            task['status'] = 'failed'
            task['error'] = str(e)
            task['error_type'] = type(e).__name__
            task['failed_at'] = datetime.datetime.now()
            self.task_stats['failed_tasks'] += 1
            debug_log(f"❌ [WorkerManager] Task processing error", {
                "worker": worker_name,
                "task_id": task_id,
                "task_type": task_type,
                "error": str(e),
                "error_type": type(e).__name__
            })
        finally:
            self.active_tasks -= 1
    def get_worker_status(self) -> Dict[str, Any]:
        """Get current worker status."""
        return {
            'running': self.running,
            'max_workers': self.max_workers,
            'active_workers': len(self.async_workers),
            'active_tasks': self.active_tasks,
            'task_queue_size': self.task_queue.qsize(),
            'priority_queue_size': self.priority_queue.qsize(),
            'total_handlers': len(self.task_handlers)
        }
    def get_task_statistics(self) -> Dict[str, Any]:
        """Get task processing statistics."""
        uptime = datetime.datetime.now() - self.task_stats['start_time']
        return {
            'total_tasks': self.task_stats['total_tasks'],
            'completed_tasks': self.task_stats['completed_tasks'],
            'failed_tasks': self.task_stats['failed_tasks'],
            'success_rate': (self.task_stats['completed_tasks'] / max(self.task_stats['total_tasks'], 1)) * 100,
            'tasks_by_type': dict(self.task_stats['tasks_by_type']),
            'uptime_seconds': uptime.total_seconds(),
            'start_time': self.task_stats['start_time'].isoformat()
        }
    async def wait_for_completion(self, timeout: Optional[float] = None):
        """Wait for all tasks to complete."""
        try:
            await asyncio.wait_for(
                asyncio.gather(
                    self.task_queue.join(),
                    self.priority_queue.join()
                ),
                timeout=timeout
            )
            debug_log(f"✅ [WorkerManager] All tasks completed")
        except asyncio.TimeoutError:
            debug_log(f"⏰ [WorkerManager] Wait timeout reached")
        except Exception as e:
            debug_log(f"❌ [WorkerManager] Wait error", {
                "error": str(e),
                "error_type": type(e).__name__
            })
    async def cleanup(self):
        """Clean up worker manager resources."""
        debug_log(f"🧹 [WorkerManager] Cleaning up worker manager")
        await self.stop_workers()
        # Clear queues
        while not self.task_queue.empty():
            try:
                self.task_queue.get_nowait()
                self.task_queue.task_done()
            except:
                pass
        while not self.priority_queue.empty():
            try:
                self.priority_queue.get_nowait()
                self.priority_queue.task_done()
            except:
                pass
        # Clear handlers
        self.task_handlers.clear()
        debug_log(f"🧹 [WorkerManager] Worker manager cleanup completed")
</file>

<file path="services/__init__.py">
"""
Services module for TensorDock server.
Handles HTTP proxy, canvas operations, widget communication, and WebSocket bridging.
"""
from .http_proxy import HTTPProxyService
from .canvas_service import CanvasService
from .widget_service import WidgetService
from .websocket_bridge import WebSocketBridge
__all__ = [
    'HTTPProxyService',
    'CanvasService',
    'WidgetService',
    'WebSocketBridge'
]
</file>

<file path="services/canvas_service.py">
"""
Canvas service for TensorDock server.
Handles canvas data operations and client state management.
"""
import json
import datetime
from typing import Dict, Any, Optional, List, Set
from collections import defaultdict
# Use absolute imports to avoid relative import issues
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from core.logging import LoggerMixin, debug_log
class CanvasService(LoggerMixin):
    """Handles canvas data operations and client state."""
    def __init__(self):
        # Debug mode for controlling logging verbosity
        self.debug_mode = os.environ.get('TENSORDOCK_DEBUG', 'false').lower() == 'true'
        # Canvas data storage
        self.canvas_data: Dict[str, Dict[str, Any]] = {}
        self.client_canvases: Dict[str, Set[str]] = defaultdict(set)
        # Client state tracking
        self.client_states: Dict[str, Dict[str, Any]] = {}
        self.client_connections: Set[str] = set()
        # Canvas statistics
        self.canvas_stats = {
            'total_operations': 0,
            'operations_by_type': defaultdict(int),
            'active_clients': 0,
            'total_canvas_elements': 0,
            'start_time': datetime.datetime.now()
        }
        debug_log(f"🎨 [Canvas] Canvas service initialized")
    async def handle_canvas_data(self, data: Dict[str, Any], client_id: str) -> Dict[str, Any]:
        """Handle incoming canvas data from a client."""
        try:
            operation_type = data.get('type', 'unknown')
            # Reduce logging verbosity for frequent operations
            # if operation_type in ['move', 'resize', 'update']:
            #     if self.debug_mode:
            #         debug_log(f"🎨 [Canvas] {operation_type} operation for client {client_id}")
            # else:
            #     debug_log(f"🎨 [Canvas] Processing canvas data", {
            #         "client_id": client_id,
            #         "operation_type": operation_type,
            #         "data_keys": list(data.keys()),
            #         "timestamp": datetime.datetime.now().isoformat()
            #     })
            # Update statistics
            self.canvas_stats['total_operations'] += 1
            self.canvas_stats['operations_by_type'][operation_type] += 1
            # Handle different operation types
            if operation_type == 'create':
                result = await self._handle_create_operation(data, client_id)
            elif operation_type == 'update':
                result = await self._handle_update_operation(data, client_id)
            elif operation_type == 'delete':
                result = await self._handle_delete_operation(data, client_id)
            elif operation_type == 'move':
                result = await self._handle_move_operation(data, client_id)
            elif operation_type == 'resize':
                result = await self._handle_resize_operation(data, client_id)
            elif operation_type == 'connect':
                result = await self._handle_connect_operation(data, client_id)
            elif operation_type == 'disconnect':
                result = await self._handle_disconnect_operation(data, client_id)
            else:
                result = await self._handle_unknown_operation(data, client_id)
            # Update client state
            self._update_client_state(client_id, operation_type, data)
            return result
        except Exception as e:
            debug_log(f"❌ [Canvas] Canvas data handling error", {
                "client_id": client_id,
                "error": str(e),
                "error_type": type(e).__name__,
                "data": data
            })
            return {
                'success': False,
                'error': str(e),
                'error_type': type(e).__name__
            }
    async def _handle_create_operation(self, data: Dict[str, Any], client_id: str) -> Dict[str, Any]:
        """Handle canvas element creation."""
        element_id = data.get('id')
        element_data = data.get('data', {})
        if element_id:
            self.canvas_data[element_id] = {
                **element_data,
                'created_by': client_id,
                'created_at': datetime.datetime.now().isoformat(),
                'last_modified': datetime.datetime.now().isoformat()
            }
            self.client_canvases[client_id].add(element_id)
            self.canvas_stats['total_canvas_elements'] += 1
            debug_log(f"✅ [Canvas] Element created", {
                "client_id": client_id,
                "element_id": element_id,
                "element_type": element_data.get('type')
            })
            return {
                'success': True,
                'element_id': element_id,
                'operation': 'create'
            }
        return {
            'success': False,
            'error': 'Missing element ID'
        }
    async def _handle_update_operation(self, data: Dict[str, Any], client_id: str) -> Dict[str, Any]:
        """Handle canvas element update."""
        element_id = data.get('id')
        updates = data.get('updates', {})
        if element_id and element_id in self.canvas_data:
            # Update element data
            self.canvas_data[element_id].update(updates)
            self.canvas_data[element_id]['last_modified'] = datetime.datetime.now().isoformat()
            self.canvas_data[element_id]['modified_by'] = client_id
            debug_log(f"✅ [Canvas] Element updated", {
                "client_id": client_id,
                "element_id": element_id,
                "update_keys": list(updates.keys())
            })
            return {
                'success': True,
                'element_id': element_id,
                'operation': 'update'
            }
        return {
            'success': False,
            'error': 'Element not found'
        }
    async def _handle_delete_operation(self, data: Dict[str, Any], client_id: str) -> Dict[str, Any]:
        """Handle canvas element deletion."""
        element_id = data.get('id')
        if element_id and element_id in self.canvas_data:
            # Remove element
            del self.canvas_data[element_id]
            # Remove from client canvases
            for client_canvas in self.client_canvases.values():
                client_canvas.discard(element_id)
            self.canvas_stats['total_canvas_elements'] = max(0, self.canvas_stats['total_canvas_elements'] - 1)
            debug_log(f"✅ [Canvas] Element deleted", {
                "client_id": client_id,
                "element_id": element_id
            })
            return {
                'success': True,
                'element_id': element_id,
                'operation': 'delete'
            }
        return {
            'success': False,
            'error': 'Element not found'
        }
    async def _handle_move_operation(self, data: Dict[str, Any], client_id: str) -> Dict[str, Any]:
        """Handle canvas element movement."""
        element_id = data.get('id')
        position = data.get('position', {})
        if element_id and element_id in self.canvas_data:
            # Update position
            self.canvas_data[element_id]['position'] = position
            self.canvas_data[element_id]['last_modified'] = datetime.datetime.now().isoformat()
            self.canvas_data[element_id]['modified_by'] = client_id
            debug_log(f"✅ [Canvas] Element moved", {
                "client_id": client_id,
                "element_id": element_id,
                "position": position
            })
            return {
                'success': True,
                'element_id': element_id,
                'operation': 'move',
                'position': position
            }
        return {
            'success': False,
            'error': 'Element not found'
        }
    async def _handle_resize_operation(self, data: Dict[str, Any], client_id: str) -> Dict[str, Any]:
        """Handle canvas element resizing."""
        element_id = data.get('id')
        dimensions = data.get('dimensions', {})
        if element_id and element_id in self.canvas_data:
            # Update dimensions
            self.canvas_data[element_id]['dimensions'] = dimensions
            self.canvas_data[element_id]['last_modified'] = datetime.datetime.now().isoformat()
            self.canvas_data[element_id]['modified_by'] = client_id
            debug_log(f"✅ [Canvas] Element resized", {
                "client_id": client_id,
                "element_id": element_id,
                "dimensions": dimensions
            })
            return {
                'success': True,
                'element_id': element_id,
                'operation': 'resize',
                'dimensions': dimensions
            }
        return {
            'success': False,
            'error': 'Element not found'
        }
    async def _handle_connect_operation(self, data: Dict[str, Any], client_id: str) -> Dict[str, Any]:
        """Handle client connection."""
        self.client_connections.add(client_id)
        self.client_states[client_id] = {
            'connected_at': datetime.datetime.now().isoformat(),
            'last_activity': datetime.datetime.now().isoformat(),
            'status': 'connected'
        }
        self.canvas_stats['active_clients'] = len(self.client_connections)
        debug_log(f"✅ [Canvas] Client connected", {
            "client_id": client_id,
            "total_clients": len(self.client_connections)
        })
        return {
            'success': True,
            'operation': 'connect',
            'client_id': client_id
        }
    async def _handle_disconnect_operation(self, data: Dict[str, Any], client_id: str) -> Dict[str, Any]:
        """Handle client disconnection."""
        self.client_connections.discard(client_id)
        if client_id in self.client_states:
            self.client_states[client_id]['status'] = 'disconnected'
            self.client_states[client_id]['disconnected_at'] = datetime.datetime.now().isoformat()
        self.canvas_stats['active_clients'] = len(self.client_connections)
        debug_log(f"✅ [Canvas] Client disconnected", {
            "client_id": client_id,
            "total_clients": len(self.client_connections)
        })
        return {
            'success': True,
            'operation': 'disconnect',
            'client_id': client_id
        }
    async def _handle_unknown_operation(self, data: Dict[str, Any], client_id: str) -> Dict[str, Any]:
        """Handle unknown operation types."""
        operation_type = data.get('type', 'unknown')
        # debug_log(f"⚠️ [Canvas] Unknown operation type", {
        #     "client_id": client_id,
        #     "operation_type": operation_type,
        #     "data": data
        # })
        return {
            'success': False,
            'error': f'Unknown operation type: {operation_type}'
        }
    def _update_client_state(self, client_id: str, operation_type: str, data: Dict[str, Any]):
        """Update client state information."""
        if client_id in self.client_states:
            self.client_states[client_id]['last_activity'] = datetime.datetime.now().isoformat()
            self.client_states[client_id]['last_operation'] = operation_type
            self.client_states[client_id]['operation_count'] = self.client_states[client_id].get('operation_count', 0) + 1
    def get_canvas_data(self, client_id: Optional[str] = None) -> Dict[str, Any]:
        """Get canvas data for a specific client or all data."""
        if client_id:
            # Return only elements owned by the client
            client_elements = self.client_canvases.get(client_id, set())
            return {element_id: self.canvas_data[element_id] for element_id in client_elements if element_id in self.canvas_data}
        else:
            # Return all canvas data
            return self.canvas_data.copy()
    def get_client_status(self, client_id: str) -> Dict[str, Any]:
        """Get status information for a specific client."""
        if client_id in self.client_states:
            return self.client_states[client_id].copy()
        return {}
    def get_canvas_statistics(self) -> Dict[str, Any]:
        """Get canvas operation statistics."""
        uptime = datetime.datetime.now() - self.canvas_stats['start_time']
        return {
            'total_operations': self.canvas_stats['total_operations'],
            'operations_by_type': dict(self.canvas_stats['operations_by_type']),
            'active_clients': self.canvas_stats['active_clients'],
            'total_canvas_elements': self.canvas_stats['total_canvas_elements'],
            'uptime_seconds': uptime.total_seconds(),
            'start_time': self.canvas_stats['start_time'].isoformat()
        }
    def get_status(self) -> Dict[str, Any]:
        """Get canvas service status."""
        return {
            'total_canvas_elements': self.canvas_stats['total_canvas_elements'],
            'active_clients': len(self.client_connections),
            'total_clients': len(self.client_states),
            'total_operations': self.canvas_stats['total_operations']
        }
    async def cleanup(self):
        """Clean up canvas service resources."""
        debug_log(f"🧹 [Canvas] Cleaning up canvas service")
        # Clear all data
        self.canvas_data.clear()
        self.client_canvases.clear()
        self.client_states.clear()
        self.client_connections.clear()
        # Reset statistics
        self.canvas_stats.clear()
        self.canvas_stats['start_time'] = datetime.datetime.now()
        debug_log(f"🧹 [Canvas] Canvas service cleanup completed")
    def set_debug_mode(self, enabled: bool):
        """Enable or disable debug logging for canvas operations."""
        self.debug_mode = enabled
        debug_log(f"🔧 [Canvas] Debug mode {'enabled' if enabled else 'disabled'}")
    def get_debug_mode(self) -> bool:
        """Get current debug mode status."""
        return self.debug_mode
</file>

<file path="services/widget_service.py">
"""
Widget service for TensorDock server.
Handles widget communication and comm message management.
"""
import json
import datetime
from typing import Dict, Any, Optional, List, Set
from collections import defaultdict
# Use absolute imports to avoid relative import issues
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from core.logging import LoggerMixin, debug_log
class WidgetService(LoggerMixin):
    """Handles widget communication and comm message management."""
    def __init__(self):
        # Widget state tracking
        self.widget_states: Dict[str, Dict[str, Any]] = {}
        self.widget_models: Dict[str, Dict[str, Any]] = {}
        self.comm_managers: Dict[str, Dict[str, Any]] = {}
        # Comm message tracking
        self.comm_messages: Dict[str, List[Dict[str, Any]]] = defaultdict(list)
        self.comm_handlers: Dict[str, List[Dict[str, Any]]] = defaultdict(list)
        # Client widget associations
        self.client_widgets: Dict[str, Set[str]] = defaultdict(set)
        # Widget statistics
        self.widget_stats = {
            'total_comm_messages': 0,
            'messages_by_type': defaultdict(int),
            'active_widgets': 0,
            'total_handlers': 0,
            'start_time': datetime.datetime.now()
        }
        debug_log(f"🎛️ [Widget] Widget service initialized")
    async def handle_comm_message(self, comm_id: str, data: Dict[str, Any], client_id: str) -> Dict[str, Any]:
        """Handle incoming comm message from a client."""
        try:
            msg_type = data.get('msg_type', 'unknown')
            debug_log(f"🎛️ [Widget] Processing comm message", {
                "client_id": client_id,
                "comm_id": comm_id,
                "msg_type": msg_type,
                "data_keys": list(data.keys()),
                "timestamp": datetime.datetime.now().isoformat()
            })
            # Update statistics
            self.widget_stats['total_comm_messages'] += 1
            self.widget_stats['messages_by_type'][msg_type] += 1
            # Handle different message types
            if msg_type == 'comm_open':
                result = await self._handle_comm_open(comm_id, data, client_id)
            elif msg_type == 'comm_msg':
                result = await self._handle_comm_msg(comm_id, data, client_id)
            elif msg_type == 'comm_close':
                result = await self._handle_comm_close(comm_id, data, client_id)
            else:
                result = await self._handle_unknown_comm_msg(comm_id, data, client_id)
            # Store comm message
            self.comm_messages[comm_id].append({
                'timestamp': datetime.datetime.now().isoformat(),
                'client_id': client_id,
                'msg_type': msg_type,
                'data': data,
                'result': result
            })
            return result
        except Exception as e:
            debug_log(f"❌ [Widget] Comm message handling error", {
                "client_id": client_id,
                "comm_id": comm_id,
                "error": str(e),
                "error_type": type(e).__name__,
                "data": data
            })
            return {
                'success': False,
                'error': str(e),
                'error_type': type(e).__name__
            }
    async def _handle_comm_open(self, comm_id: str, data: Dict[str, Any], client_id: str) -> Dict[str, Any]:
        """Handle comm_open message for widget initialization."""
        try:
            # Extract widget information
            target_name = data.get('target_name', 'jupyter.widget')
            model_id = data.get('model_id', comm_id)
            # Create widget state
            self.widget_states[comm_id] = {
                'comm_id': comm_id,
                'model_id': model_id,
                'target_name': target_name,
                'client_id': client_id,
                'status': 'open',
                'created_at': datetime.datetime.now().isoformat(),
                'last_activity': datetime.datetime.now().isoformat()
            }
            # Create comm manager
            self.comm_managers[comm_id] = {
                'comm_id': comm_id,
                'client_id': client_id,
                'status': 'active',
                'message_count': 0,
                'created_at': datetime.datetime.now().isoformat()
            }
            # Associate with client
            self.client_widgets[client_id].add(comm_id)
            self.widget_stats['active_widgets'] += 1
            debug_log(f"✅ [Widget] Comm opened", {
                "client_id": client_id,
                "comm_id": comm_id,
                "target_name": target_name,
                "model_id": model_id
            })
            return {
                'success': True,
                'comm_id': comm_id,
                'operation': 'comm_open',
                'widget_state': self.widget_states[comm_id]
            }
        except Exception as e:
            debug_log(f"❌ [Widget] Comm open error", {
                "comm_id": comm_id,
                "error": str(e),
                "error_type": type(e).__name__
            })
            raise
    async def _handle_comm_msg(self, comm_id: str, data: Dict[str, Any], client_id: str) -> Dict[str, Any]:
        """Handle comm_msg message for widget communication."""
        try:
            if comm_id not in self.widget_states:
                return {
                    'success': False,
                    'error': 'Comm not found'
                }
            # Update widget state
            self.widget_states[comm_id]['last_activity'] = datetime.datetime.now().isoformat()
            self.widget_states[comm_id]['message_count'] = self.widget_states[comm_id].get('message_count', 0) + 1
            # Update comm manager
            self.comm_managers[comm_id]['message_count'] += 1
            self.comm_managers[comm_id]['last_activity'] = datetime.datetime.now().isoformat()
            # Process message data
            message_data = data.get('data', {})
            debug_log(f"✅ [Widget] Comm message processed", {
                "client_id": client_id,
                "comm_id": comm_id,
                "message_data_keys": list(message_data.keys()) if message_data else [],
                "message_count": self.widget_states[comm_id]['message_count']
            })
            return {
                'success': True,
                'comm_id': comm_id,
                'operation': 'comm_msg',
                'message_data': message_data
            }
        except Exception as e:
            debug_log(f"❌ [Widget] Comm message error", {
                "comm_id": comm_id,
                "error": str(e),
                "error_type": type(e).__name__
            })
            raise
    async def _handle_comm_close(self, comm_id: str, data: Dict[str, Any], client_id: str) -> Dict[str, Any]:
        """Handle comm_close message for widget cleanup."""
        try:
            if comm_id not in self.widget_states:
                return {
                    'success': False,
                    'error': 'Comm not found'
                }
            # Update widget state
            self.widget_states[comm_id]['status'] = 'closed'
            self.widget_states[comm_id]['closed_at'] = datetime.datetime.now().isoformat()
            # Update comm manager
            self.comm_managers[comm_id]['status'] = 'closed'
            self.comm_managers[comm_id]['closed_at'] = datetime.datetime.now().isoformat()
            # Remove from client associations
            if client_id in self.client_widgets:
                self.client_widgets[client_id].discard(comm_id)
            self.widget_stats['active_widgets'] = max(0, self.widget_stats['active_widgets'] - 1)
            debug_log(f"✅ [Widget] Comm closed", {
                "client_id": client_id,
                "comm_id": comm_id
            })
            return {
                'success': True,
                'comm_id': comm_id,
                'operation': 'comm_close'
            }
        except Exception as e:
            debug_log(f"❌ [Widget] Comm close error", {
                "comm_id": comm_id,
                "error": str(e),
                "error_type": type(e).__name__
            })
            raise
    async def _handle_unknown_comm_msg(self, comm_id: str, data: Dict[str, Any], client_id: str) -> Dict[str, Any]:
        """Handle unknown comm message types."""
        msg_type = data.get('msg_type', 'unknown')
        debug_log(f"⚠️ [Widget] Unknown comm message type", {
            "client_id": client_id,
            "comm_id": comm_id,
            "msg_type": msg_type,
            "data": data
        })
        return {
            'success': False,
            'error': f'Unknown comm message type: {msg_type}'
        }
    async def send_comm_message(self, comm_id: str, data: Dict[str, Any], target_client_id: Optional[str] = None) -> bool:
        """Send a comm message to a widget."""
        try:
            if comm_id not in self.widget_states:
                debug_log(f"❌ [Widget] Cannot send message to non-existent comm", {
                    "comm_id": comm_id
                })
                return False
            # Create message structure
            message = {
                'header': {
                    'msg_id': f"comm_{comm_id}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S_%f')}",
                    'msg_type': 'comm_msg',
                    'username': 'server',
                    'session': 'server',
                    'date': datetime.datetime.now().isoformat(),
                    'version': '5.0'
                },
                'parent_header': {},
                'metadata': {},
                'content': {
                    'comm_id': comm_id,
                    'data': data
                }
            }
            # Update widget state
            self.widget_states[comm_id]['last_activity'] = datetime.datetime.now().isoformat()
            self.widget_states[comm_id]['outgoing_message_count'] = self.widget_states[comm_id].get('outgoing_message_count', 0) + 1
            debug_log(f"✅ [Widget] Comm message sent", {
                "comm_id": comm_id,
                "target_client_id": target_client_id,
                "data_keys": list(data.keys()) if data else []
            })
            return True
        except Exception as e:
            debug_log(f"❌ [Widget] Failed to send comm message", {
                "comm_id": comm_id,
                "error": str(e),
                "error_type": type(e).__name__
            })
            return False
    def get_widget_state(self, comm_id: str) -> Optional[Dict[str, Any]]:
        """Get state information for a specific widget."""
        return self.widget_states.get(comm_id)
    def get_client_widgets(self, client_id: str) -> List[Dict[str, Any]]:
        """Get all widgets associated with a client."""
        widget_ids = self.client_widgets.get(client_id, set())
        return [self.widget_states.get(widget_id, {}) for widget_id in widget_ids if widget_id in self.widget_states]
    def get_widget_statistics(self) -> Dict[str, Any]:
        """Get widget operation statistics."""
        uptime = datetime.datetime.now() - self.widget_stats['start_time']
        return {
            'total_comm_messages': self.widget_stats['total_comm_messages'],
            'messages_by_type': dict(self.widget_stats['messages_by_type']),
            'active_widgets': self.widget_stats['active_widgets'],
            'total_handlers': self.widget_stats['total_handlers'],
            'uptime_seconds': uptime.total_seconds(),
            'start_time': self.widget_stats['start_time'].isoformat()
        }
    def get_status(self) -> Dict[str, Any]:
        """Get widget service status."""
        return {
            'active_widgets': self.widget_stats['active_widgets'],
            'total_comm_messages': self.widget_stats['total_comm_messages'],
            'total_widget_states': len(self.widget_states),
            'total_comm_managers': len(self.comm_managers),
            'total_clients_with_widgets': len(self.client_widgets)
        }
    async def cleanup(self):
        """Clean up widget service resources."""
        debug_log(f"🧹 [Widget] Cleaning up widget service")
        # Clear all data
        self.widget_states.clear()
        self.widget_models.clear()
        self.comm_managers.clear()
        self.comm_messages.clear()
        self.comm_handlers.clear()
        self.client_widgets.clear()
        # Reset statistics
        self.widget_stats.clear()
        self.widget_stats['start_time'] = datetime.datetime.now()
        debug_log(f"🧹 [Widget] Widget service cleanup completed")
</file>

<file path="webrtc/__init__.py">
"""
WebRTC module for TensorDock server.
Handles peer connections, data channels, and message routing.
"""
from .peer_manager import WebRTCPeerManager
from .data_channel import DataChannelManager
from .message_handler import WebRTCMessageHandler
from .signaling import SignalingManager
__all__ = [
    'WebRTCPeerManager',
    'DataChannelManager', 
    'WebRTCMessageHandler',
    'SignalingManager'
]
</file>

<file path="webrtc/data_channel.py">
"""
Data channel management for WebRTC connections.
"""
import json
import datetime
from typing import Dict, Optional, Callable, Any
# Make aiortc import optional for testing
try:
    from aiortc import RTCDataChannel
    AIORTC_AVAILABLE = True
except ImportError:
    AIORTC_AVAILABLE = False
    # Create mock class for testing
    class RTCDataChannel:
        def __init__(self):
            self.label = "mock-channel"
            self.ordered = True
            self.protocol = ""
            self.readyState = "open"
            self.bufferedAmount = 0
        def on(self, event):
            def decorator(func):
                return func
            return decorator
        def send(self, data):
            pass
# Use absolute imports to avoid relative import issues
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from core.logging import LoggerMixin, debug_log
class DataChannelManager(LoggerMixin):
    """Manages WebRTC data channels and their lifecycle."""
    def __init__(self):
        super().__init__()
        self.data_channels: Dict[int, RTCDataChannel] = {}
        self.message_handlers: Dict[int, Callable] = {}
        self.close_handlers: Dict[int, Callable] = {}
    def add_channel(self, client_id: int, channel: RTCDataChannel, 
                   message_handler: Callable, close_handler: Callable):
        """Add a new data channel."""
        self.log_info(f"Adding data channel", {
            "client_id": client_id,
            "channel_label": channel.label,
            "total_channels": len(self.data_channels)
        })
        self.data_channels[client_id] = channel
        self.message_handlers[client_id] = message_handler
        self.close_handlers[client_id] = close_handler
        # Set up channel event handlers
        self._setup_channel_handlers(client_id, channel)
    def remove_channel(self, client_id: int):
        """Remove a data channel."""
        if client_id in self.data_channels:
            self.log_info(f"Removing data channel", {
                "client_id": client_id,
                "total_channels": len(self.data_channels)
            })
            del self.data_channels[client_id]
            del self.message_handlers[client_id]
            del self.close_handlers[client_id]
    def _setup_channel_handlers(self, client_id: int, channel: RTCDataChannel):
        """Set up event handlers for a data channel."""
        @channel.on("message")
        async def on_message(message):
            """Handle incoming messages on the data channel."""
            if client_id in self.message_handlers:
                handler = self.message_handlers[client_id]
                try:
                    result = handler(message, channel)
                    # If handler returns a coroutine, await it
                    import asyncio
                    if asyncio.iscoroutine(result):
                        await result
                except Exception as e:
                    self.log_error("Error handling data channel message", {
                        "client_id": client_id,
                        "error": str(e),
                        "error_type": type(e).__name__
                    })
        @channel.on("close")
        def on_close():
            """Handle data channel closure."""
            self.log_info(f"Data channel closed", {
                "client_id": client_id,
                "total_channels": len(self.data_channels)
            })
            if client_id in self.close_handlers:
                self.close_handlers[client_id]()
            self.remove_channel(client_id)
    def send_message(self, client_id: int, message: Dict[str, Any]) -> bool:
        """Send a message to a specific client."""
        if client_id not in self.data_channels:
            self.log_warning(f"Cannot send message: client not found", {
                "client_id": client_id,
                "available_clients": list(self.data_channels.keys())
            })
            return False
        try:
            channel = self.data_channels[client_id]
            message_str = json.dumps(message)
            debug_log(f"📤 [DataChannel] Sending message to client", {
                "client_id": client_id,
                "action": message.get('action'),
                "message_length": len(message_str),
                "timestamp": datetime.datetime.now().isoformat()
            })
            channel.send(message_str)
            return True
        except Exception as e:
            self.log_error(f"Failed to send message to client", {
                "client_id": client_id,
                "error": str(e),
                "error_type": type(e).__name__
            })
            return False
    def broadcast_message(self, message: Dict[str, Any], exclude_client_id: Optional[int] = None) -> int:
        """Broadcast a message to all clients except the excluded one."""
        sent_count = 0
        debug_log(f"📤 [DataChannel] Broadcasting message", {
            "action": message.get('action'),
            "exclude_client_id": exclude_client_id,
            "total_clients": len(self.data_channels),
            "message_keys": list(message.keys()),
            "timestamp": datetime.datetime.now().isoformat()
        })
        for client_id, channel in self.data_channels.items():
            if client_id != exclude_client_id:
                if self.send_message(client_id, message):
                    sent_count += 1
        debug_log(f"📤 [DataChannel] Broadcast completed", {
            "sent_count": sent_count,
            "total_clients": len(self.data_channels)
        })
        return sent_count
    def get_channel_info(self, client_id: int) -> Optional[Dict[str, Any]]:
        """Get information about a specific data channel."""
        if client_id not in self.data_channels:
            return None
        channel = self.data_channels[client_id]
        return {
            "client_id": client_id,
            "label": channel.label,
            "ordered": channel.ordered,
            "protocol": channel.protocol,
            "ready_state": channel.readyState,
            "buffered_amount": channel.bufferedAmount
        }
    def get_all_channels_info(self) -> Dict[int, Dict[str, Any]]:
        """Get information about all data channels."""
        return {
            client_id: self.get_channel_info(client_id)
            for client_id in self.data_channels.keys()
        }
    def is_client_connected(self, client_id: int) -> bool:
        """Check if a client is connected."""
        return client_id in self.data_channels
    def get_connected_clients(self) -> list:
        """Get list of connected client IDs."""
        return list(self.data_channels.keys())
    def get_channel_count(self) -> int:
        """Get total number of data channels."""
        return len(self.data_channels)
</file>

<file path="webrtc/message_handler.py">
"""
WebRTC message handling and routing.
"""
import json
import datetime
from typing import Any, Dict, Callable, Set
# Make aiortc import optional for testing
try:
    from aiortc import RTCDataChannel
    AIORTC_AVAILABLE = True
except ImportError:
    AIORTC_AVAILABLE = False
    # Create mock class for testing
    class RTCDataChannel:
        def __init__(self):
            self.label = "mock-channel"
            self.readyState = "open"
# Use absolute imports to avoid relative import issues
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from core.logging import LoggerMixin, debug_log
class WebRTCMessageHandler(LoggerMixin):
    """Handles incoming WebRTC messages and routes them to appropriate handlers."""
    def __init__(self):
        super().__init__()
        self.action_listeners: Dict[str, Set[Callable]] = {}
        self.client_id: int = None
    def set_client_id(self, client_id: int):
        """Set the client ID for this message handler."""
        self.client_id = client_id
    def add_listener(self, action: str, callback: Callable):
        """Add a listener for a specific action."""
        if action not in self.action_listeners:
            self.action_listeners[action] = set()
        self.action_listeners[action].add(callback)
    def remove_listener(self, action: str, callback: Callable):
        """Remove a listener for a specific action."""
        if action in self.action_listeners:
            self.action_listeners[action].discard(callback)
    def handle_message(self, message: str, data_channel: RTCDataChannel):
        """Handle incoming WebRTC message."""
        try:
            debug_log(f"🔵 [WebRTC] Message received from client {self.client_id}", {
                "message_length": len(message) if hasattr(message, '__len__') else 'unknown',
                "message_type": type(message).__name__,
                "timestamp": datetime.datetime.now().isoformat()
            })
            data = json.loads(message)
            debug_log(f"🔵 [WebRTC] Parsed message data", {
                "action": data.get('action'),
                "client_id": self.client_id,
                "message_keys": list(data.keys()),
                "timestamp": datetime.datetime.now().isoformat()
            })
            # Route message to appropriate handler
            action = data.get('action')
            if action:
                self._route_message(action, data, data_channel)
            else:
                self.log_warning(f"Message missing action field", data)
        except json.JSONDecodeError as e:
            self.log_error(f"Failed to parse message as JSON", {
                "error": str(e),
                "message": message[:200] if hasattr(message, '__len__') else str(message)[:200]
            })
        except Exception as e:
            self.log_error(f"Error handling message", {
                "error": str(e),
                "error_type": type(e).__name__,
                "message": message[:200] if hasattr(message, '__len__') else str(message)[:200]
            })
    def _route_message(self, action: str, data: Dict[str, Any], data_channel: RTCDataChannel):
        """Route message to appropriate handler based on action."""
        # Find exact match first
        listeners = self.action_listeners.get(action)
        # If no exact match and it's an HTTP response, try pattern matching
        if not listeners and action.startswith('http_response_'):
            for action_key, action_listeners in self.action_listeners.items():
                if action_key == 'sudo_http_response' or action_key == action:
                    listeners = action_listeners
                    break
        if listeners:
            self._call_listeners(action, data, listeners)
        else:
            self.log_warning(f"No listeners found for action", {
                "action": action,
                "available_actions": list(self.action_listeners.keys())
            })
    def _call_listeners(self, action: str, data: Dict[str, Any], listeners: Set[Callable]):
        """Call all listeners for an action with processed message data."""
        # Process message data based on action type
        if action == 'kernel':
            message_data = self._process_kernel_message(data)
        elif action == 'kernel_message':
            # Handle kernel_message action specifically
            message_data = data
            debug_log(f"🔵 [WebRTC] Kernel message received", {
                "action": action,
                "has_data": 'data' in data,
                "message_keys": list(data.keys())
            })
        elif action == 'events':
            message_data = data.get('data')
        elif action == 'sudo_http_request':
            # CRITICAL: For HTTP requests, preserve the full message structure
            # Don't extract just the 'data' field, keep url, method, headers, msgId
            message_data = data
            debug_log(f"🔵 [WebRTC] HTTP request - preserving full message structure", {
                "action": action,
                "has_url": 'url' in data,
                "has_method": 'method' in data,
                "has_headers": 'headers' in data,
                "has_msgId": 'msgId' in data,
                "has_data": 'data' in data,
                "message_keys": list(data.keys())
            })
        elif action == 'canvas_data':
            # Reduce logging for canvas data (mouse movements)
            message_data = data
            # Only log every 100th canvas message to reduce spam
            if not hasattr(self, '_canvas_log_counter'):
                self._canvas_log_counter = 0
            self._canvas_log_counter += 1
            if self._canvas_log_counter % 100 == 0:
                debug_log(f"🎨 [WebRTC] Canvas data (logged every 100th)", {
                    "action": action,
                    "count": self._canvas_log_counter,
                    "message_keys": list(data.keys())
                })
        elif data.get('data'):
            message_data = data['data']
        else:
            # Messages without data property (like execution_complete)
            message_data = {k: v for k, v in data.items() if k != 'action'}
        # Add client_id to message data for action processing
        if hasattr(self, 'client_id') and self.client_id is not None:
            message_data['client_id'] = self.client_id
        debug_log(f"🔵 [WebRTC] Calling listeners for action", {
            "action": action,
            "listener_count": len(listeners),
            "message_data": message_data,
            "client_id": getattr(self, 'client_id', None)
        })
        # Call all listeners
        for callback in listeners:
            try:
                callback(message_data)
            except Exception as e:
                self.log_error(f"Error in listener callback", {
                    "action": action,
                    "error": str(e),
                    "error_type": type(e).__name__
                })
    def _process_kernel_message(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Process kernel message data."""
        try:
            kernel_data = data.get('data')
            if isinstance(kernel_data, str):
                message_data = json.loads(kernel_data)
                debug_log(f"🔵 [WebRTC] Kernel message parsed", {
                    "msg_type": message_data.get('header', {}).get('msg_type'),
                    "msg_id": message_data.get('header', {}).get('msg_id'),
                    "parent_header": message_data.get('parent_header'),
                    "content": message_data.get('content'),
                    "metadata": message_data.get('metadata'),
                    "buffers": message_data.get('buffers')
                })
                return message_data
            else:
                return kernel_data
        except Exception as e:
            self.log_error(f"Error parsing kernel message", {
                "error": str(e),
                "data": data
            })
            raise
    def get_available_actions(self) -> list:
        """Get list of available actions."""
        return list(self.action_listeners.keys())
    def get_listener_count(self, action: str) -> int:
        """Get number of listeners for an action."""
        return len(self.action_listeners.get(action, set()))
</file>

<file path="webrtc/peer_manager.py">
"""
WebRTC peer connection management.
"""
import datetime
from typing import Dict, Set, Optional, Callable, Any
# Make aiortc import optional for testing
try:
    from aiortc import RTCPeerConnection, RTCSessionDescription, RTCDataChannel
    AIORTC_AVAILABLE = True
except ImportError:
    AIORTC_AVAILABLE = False
    # Create mock classes for testing
    class RTCPeerConnection:
        def __init__(self, configuration=None):
            self.configuration = configuration
            self.iceConnectionState = "new"
            self.iceGatheringState = "new"
            self.signalingState = "stable"
            self.connectionState = "new"
        def on(self, event):
            def decorator(func):
                return func
            return decorator
        async def setRemoteDescription(self, description):
            pass
        async def createAnswer(self):
            return RTCSessionDescription("answer", "mock-sdp")
        async def setLocalDescription(self, description):
            pass
    class RTCSessionDescription:
        def __init__(self, type, sdp):
            self.type = type
            self.sdp = sdp
    class RTCDataChannel:
        def __init__(self):
            self.label = "mock-channel"
            self.ordered = True
            self.protocol = ""
            self.readyState = "open"
            self.bufferedAmount = 0
        def on(self, event):
            def decorator(func):
                return func
            return decorator
        def send(self, data):
            pass
# Use absolute imports to avoid relative import issues
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from core.logging import LoggerMixin, debug_log
from core.config import ServerConfig
from webrtc.data_channel import DataChannelManager
from webrtc.message_handler import WebRTCMessageHandler
class WebRTCPeerManager(LoggerMixin):
    """Manages WebRTC peer connections and their lifecycle."""
    def __init__(self, config: ServerConfig):
        super().__init__()
        self.config = config
        self.peer_connections: Set[RTCPeerConnection] = set()
        self.data_channel_manager = DataChannelManager()
        self.message_handlers: Dict[int, WebRTCMessageHandler] = {}
        # Connection event callbacks
        self.connection_callbacks: Dict[str, Set[Callable]] = {
            'new_peer': set(),
            'peer_disconnected': set(),
            'data_channel_ready': set()
        }
    def add_connection_callback(self, event: str, callback: Callable):
        """Add a callback for connection events."""
        if event in self.connection_callbacks:
            self.connection_callbacks[event].add(callback)
    def remove_connection_callback(self, event: str, callback: Callable):
        """Remove a callback for connection events."""
        if event in self.connection_callbacks:
            self.connection_callbacks[event].discard(callback)
    async def handle_client_offer(self, offer: Dict[str, Any]) -> Dict[str, Any]:
        """Handle a new client connection offer."""
        client_id = id(offer)  # Use offer object ID as temporary client ID
        debug_log(f"🔗 [PeerManager] New client connection request", {
            "offer_type": offer.get("type"),
            "sdp_length": len(offer.get("sdp", "")) if offer.get("sdp") else 0,
            "timestamp": datetime.datetime.now().isoformat()
        })
        # Create peer connection
        pc = RTCPeerConnection(configuration=self.config.rtc_config)
        self.peer_connections.add(pc)
        # Set up peer connection event handlers
        self._setup_peer_connection_handlers(pc, client_id)
        # Set remote description
        debug_log(f"🔗 [PeerManager] Setting remote description", {
            "client_id": client_id,
            "offer_type": offer.get("type"),
            "timestamp": datetime.datetime.now().isoformat()
        })
        await pc.setRemoteDescription(RTCSessionDescription(
            sdp=offer["sdp"],
            type=offer["type"]
        ))
        # Create and set local description
        debug_log(f"🔗 [PeerManager] Creating answer", {
            "client_id": client_id,
            "timestamp": datetime.datetime.now().isoformat()
        })
        answer = await pc.createAnswer()
        await pc.setLocalDescription(answer)
        debug_log(f"🔗 [PeerManager] Client connection established", {
            "client_id": client_id,
            "answer_type": answer.type,
            "sdp_length": len(answer.sdp),
            "timestamp": datetime.datetime.now().isoformat()
        })
        # Notify connection callbacks
        self._notify_callbacks('new_peer', client_id, pc)
        return {"sdp": pc.localDescription.sdp, "type": pc.localDescription.type}
    def _setup_peer_connection_handlers(self, pc: RTCPeerConnection, client_id: int):
        """Set up event handlers for a peer connection."""
        @pc.on("iceconnectionstatechange")
        async def on_ice_connection_state_change():
            debug_log(f"🔗 [PeerManager] ICE connection state changed", {
                "client_id": client_id,
                "ice_state": pc.iceConnectionState,
                "timestamp": datetime.datetime.now().isoformat()
            })
        @pc.on("datachannel")
        def on_datachannel(channel: RTCDataChannel):
            self._handle_data_channel(client_id, channel)
        @pc.on("icecandidate")
        async def on_ice_candidate(candidate):
            debug_log(f"🧊 [PeerManager] ICE candidate generated", {
                "client_id": client_id,
                "candidate_type": candidate.type if candidate else 'unknown',
                "timestamp": datetime.datetime.now().isoformat()
            })
            # Broadcast ICE candidate to client
            await self.data_channel_manager.broadcast_message({
                'action': 'ice_candidate',
                'candidate': candidate
            }, exclude_client_id=client_id)
        @pc.on("icegatheringstatechange")
        async def on_ice_gathering_state_change():
            debug_log(f"🧊 [PeerManager] ICE gathering state changed", {
                "client_id": client_id,
                "ice_state": pc.iceGatheringState,
                "timestamp": datetime.datetime.now().isoformat()
            })
        @pc.on("signalingstatechange")
        async def on_signaling_state_change():
            debug_log(f"📡 [PeerManager] Signaling state changed", {
                "client_id": client_id,
                "signaling_state": pc.signalingState,
                "timestamp": datetime.datetime.now().isoformat()
            })
        @pc.on("connectionstatechange")
        async def on_connection_state_change():
            debug_log(f"🔗 [PeerManager] Connection state changed", {
                "client_id": client_id,
                "connection_state": pc.connectionState,
                "timestamp": datetime.datetime.now().isoformat()
            })
            # Handle connection state changes
            if pc.connectionState == "failed":
                self._handle_peer_failure(client_id, pc)
            elif pc.connectionState == "closed":
                self._handle_peer_disconnection(client_id, pc)
        @pc.on("negotiationneeded")
        async def on_negotiation_needed():
            debug_log(f"🤝 [PeerManager] Negotiation needed", {
                "client_id": client_id,
                "timestamp": datetime.datetime.now().isoformat()
            })
    def _handle_data_channel(self, client_id: int, channel: RTCDataChannel):
        """Handle a new data channel from a peer connection."""
        debug_log(f"🔗 [PeerManager] Data channel established", {
            "client_id": client_id,
            "channel_label": channel.label,
            "total_channels": self.data_channel_manager.get_channel_count(),
            "timestamp": datetime.datetime.now().isoformat()
        })
        # Create message handler for this client
        message_handler = WebRTCMessageHandler()
        message_handler.set_client_id(client_id)
        self.message_handlers[client_id] = message_handler
        # Add data channel to manager
        self.data_channel_manager.add_channel(
            client_id=client_id,
            channel=channel,
            message_handler=message_handler.handle_message,
            close_handler=lambda: self._handle_client_disconnection(client_id)
        )
        # Notify data channel ready callbacks
        self._notify_callbacks('data_channel_ready', client_id, channel)
    def _handle_peer_failure(self, client_id: int, pc: RTCPeerConnection):
        """Handle peer connection failure."""
        self.log_error(f"Peer connection failed", {
            "client_id": client_id,
            "connection_state": pc.connectionState
        })
        # Clean up failed connection
        self._cleanup_peer_connection(client_id, pc)
    def _handle_peer_disconnection(self, client_id: int, pc: RTCPeerConnection):
        """Handle peer disconnection."""
        debug_log(f"🔌 [PeerManager] Peer disconnected", {
            "client_id": client_id,
            "connection_state": pc.connectionState,
            "timestamp": datetime.datetime.now().isoformat()
        })
        # Clean up disconnected connection
        self._cleanup_peer_connection(client_id, pc)
    def _handle_client_disconnection(self, client_id: int):
        """Handle client disconnection from data channel."""
        debug_log(f"🔌 [PeerManager] Client disconnected", {
            "client_id": client_id,
            "timestamp": datetime.datetime.now().isoformat()
        })
        # Notify disconnection callbacks
        self._notify_callbacks('peer_disconnected', client_id)
        # Clean up client resources
        if client_id in self.message_handlers:
            del self.message_handlers[client_id]
    def _cleanup_peer_connection(self, client_id: int, pc: RTCPeerConnection):
        """Clean up a peer connection."""
        if pc in self.peer_connections:
            self.peer_connections.remove(pc)
        # Clean up data channel
        self.data_channel_manager.remove_channel(client_id)
        # Clean up message handler
        if client_id in self.message_handlers:
            del self.message_handlers[client_id]
    def _notify_callbacks(self, event: str, client_id: int, data: Any = None):
        """Notify all callbacks for an event."""
        if event in self.connection_callbacks:
            for callback in self.connection_callbacks[event]:
                try:
                    callback(client_id, data)
                except Exception as e:
                    self.log_error(f"Error in connection callback", {
                        "event": event,
                        "client_id": client_id,
                        "error": str(e)
                    })
    def get_peer_connection_count(self) -> int:
        """Get total number of peer connections."""
        return len(self.peer_connections)
    def get_connected_clients(self) -> list:
        """Get list of connected client IDs."""
        return self.data_channel_manager.get_connected_clients()
    def get_message_handler(self, client_id: int) -> Optional[WebRTCMessageHandler]:
        """Get message handler for a specific client."""
        return self.message_handlers.get(client_id)
    def broadcast_message(self, message: Dict[str, Any], exclude_client_id: Optional[int] = None) -> int:
        """Broadcast a message to all connected clients."""
        return self.data_channel_manager.broadcast_message(message, exclude_client_id)
    def send_message(self, client_id: int, message: Dict[str, Any]) -> bool:
        """Send a message to a specific client."""
        return self.data_channel_manager.send_message(client_id, message)
</file>

<file path="webrtc/signaling.py">
"""
WebRTC signaling management.
"""
from typing import Dict, Any, Optional
# Use absolute imports to avoid relative import issues
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from core.logging import LoggerMixin
class SignalingManager(LoggerMixin):
    """Manages WebRTC signaling and offer/answer exchange."""
    def __init__(self):
        super().__init__()
        self.pending_offers: Dict[str, Dict[str, Any]] = {}
    def create_offer_id(self, offer: Dict[str, Any]) -> str:
        """Create a unique ID for an offer."""
        return f"offer_{id(offer)}"
    def store_offer(self, offer_id: str, offer: Dict[str, Any]):
        """Store a pending offer."""
        self.pending_offers[offer_id] = offer
        self.log_info(f"Stored pending offer", {"offer_id": offer_id})
    def get_offer(self, offer_id: str) -> Optional[Dict[str, Any]]:
        """Retrieve a stored offer."""
        return self.pending_offers.get(offer_id)
    def remove_offer(self, offer_id: str):
        """Remove a stored offer."""
        if offer_id in self.pending_offers:
            del self.pending_offers[offer_id]
            self.log_info(f"Removed pending offer", {"offer_id": offer_id})
    def validate_offer(self, offer: Dict[str, Any]) -> bool:
        """Validate an offer structure."""
        required_fields = ['type', 'sdp']
        for field in required_fields:
            if field not in offer:
                self.log_warning(f"Offer missing required field", {
                    "field": field,
                    "offer_keys": list(offer.keys())
                })
                return False
        if offer['type'] != 'offer':
            self.log_warning(f"Invalid offer type", {
                "expected": "offer",
                "received": offer['type']
            })
            return False
        if not offer['sdp'] or len(offer['sdp']) < 10:
            self.log_warning(f"Invalid SDP in offer", {
                "sdp_length": len(offer['sdp']) if offer['sdp'] else 0
            })
            return False
        return True
    def create_answer(self, offer: Dict[str, Any], sdp: str, answer_type: str = 'answer') -> Dict[str, Any]:
        """Create an answer response."""
        return {
            'type': answer_type,
            'sdp': sdp
        }
    def get_pending_offer_count(self) -> int:
        """Get number of pending offers."""
        return len(self.pending_offers)
    def cleanup_expired_offers(self, max_age_seconds: int = 300):
        """Clean up expired offers (placeholder for future implementation)."""
        # TODO: Implement offer expiration cleanup
        pass
</file>

<file path="__main__.py">
"""
Main entry point for the tensordock module.
Run with: python -m tensordock
"""
import asyncio
import sys
import os
# Add the current directory to Python path
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)
# Import and run the modular server
from server_modular import main
if __name__ == "__main__":
    asyncio.run(main())
</file>

<file path="export.html">
<html>
  <head>
    <title>Widget export</title>
    <!-- Load RequireJS, used by the IPywidgets for dependency management -->
    <script
      src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"
      integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA="
      crossorigin="anonymous">
    </script>
    <!-- Load IPywidgets bundle for embedding. -->
    <script
      data-jupyter-widgets-cdn="https://unpkg.com/"
      data-jupyter-widgets-cdn-only
      src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@*/dist/embed-amd.js"
      crossorigin="anonymous">
    </script>
    <!-- The state of all the widget models on the page -->
    <script type="application/vnd.jupyter.widget-state+json">
      {"version_major": 2, "version_minor": 0, "state": {"5f14cea19ec648838e3ee48caf8470e5": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {}}, "069fcd62524e485e92a09b203f6ade03": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {}}, "2046c7e1710a4028804464e288f61748": {"model_name": "IntSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "description": "a", "layout": "IPY_MODEL_5f14cea19ec648838e3ee48caf8470e5", "style": "IPY_MODEL_069fcd62524e485e92a09b203f6ade03"}}, "4018c516c2be404aa1fb566b506559d9": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {}}, "b47a3942f69b4110b006a0cfac6f3d6b": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {}}, "54a1d15d414640799f61784006f3d8f4": {"model_name": "IntSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "description": "b", "layout": "IPY_MODEL_4018c516c2be404aa1fb566b506559d9", "style": "IPY_MODEL_b47a3942f69b4110b006a0cfac6f3d6b"}}, "2cb1593f5aae48769335c8ff6ee0a98d": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {}}, "60ed306b1177453c8549a3a1df23cb67": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {}}, "b992f63812b246468e4e8ddcbdb7c795": {"model_name": "IntSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "description": "c", "layout": "IPY_MODEL_2cb1593f5aae48769335c8ff6ee0a98d", "style": "IPY_MODEL_60ed306b1177453c8549a3a1df23cb67"}}, "3ccdc06e29b2417399abc9eb3b9b7d8f": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {}}, "286841232a494f53b9a94d9b69b50e13": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "layout": "IPY_MODEL_3ccdc06e29b2417399abc9eb3b9b7d8f", "outputs": []}}, "0b378091415e4acdacf5bba72ec5e0fd": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {}}, "866db74b1da1401f831ffea7e2095a23": {"model_name": "VBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "children": ["IPY_MODEL_2046c7e1710a4028804464e288f61748", "IPY_MODEL_54a1d15d414640799f61784006f3d8f4", "IPY_MODEL_b992f63812b246468e4e8ddcbdb7c795"], "layout": "IPY_MODEL_0b378091415e4acdacf5bba72ec5e0fd"}}, "47a8490778184f24aebd5895b8b1b07c": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {}}, "13abc25564c5462a83a68d29ecbbc574": {"model_name": "HBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "children": ["IPY_MODEL_866db74b1da1401f831ffea7e2095a23", "IPY_MODEL_286841232a494f53b9a94d9b69b50e13"], "layout": "IPY_MODEL_47a8490778184f24aebd5895b8b1b07c"}}, "7e2d93f89b444692b8b11531172b8caa": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {}}, "c1ecbfdfead54fd39e4eee672b5b78b4": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {}}, "19d3d462ba654128ac43d53be585825f": {"model_name": "IntSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "description": "a", "layout": "IPY_MODEL_7e2d93f89b444692b8b11531172b8caa", "style": "IPY_MODEL_c1ecbfdfead54fd39e4eee672b5b78b4"}}, "53e94a9d8038459194579a6e8eeae639": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {}}, "129df0f9edf94e1cba027be728047515": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {}}, "68ff691cf60c4d36ab282fb1d807c5ed": {"model_name": "IntSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "description": "b", "layout": "IPY_MODEL_53e94a9d8038459194579a6e8eeae639", "style": "IPY_MODEL_129df0f9edf94e1cba027be728047515"}}, "155be8bed98846ea88c559122d7da767": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {}}, "82015db73d3b442b9d4c7bbf9e7a7cd9": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {}}, "8ac051b0f7f1483f803bbceea8e77687": {"model_name": "IntSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "description": "c", "layout": "IPY_MODEL_155be8bed98846ea88c559122d7da767", "style": "IPY_MODEL_82015db73d3b442b9d4c7bbf9e7a7cd9"}}, "1d54111270b444fc8a6966ec0ac299ef": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {}}, "c2e41cc356e24fff8b3892583ab6b94d": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "layout": "IPY_MODEL_1d54111270b444fc8a6966ec0ac299ef", "outputs": []}}, "d780281b6a6f477f8197f451fb1196d8": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {}}, "90281c5b00be470a9907905264adeb54": {"model_name": "VBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "children": ["IPY_MODEL_19d3d462ba654128ac43d53be585825f", "IPY_MODEL_68ff691cf60c4d36ab282fb1d807c5ed", "IPY_MODEL_8ac051b0f7f1483f803bbceea8e77687"], "layout": "IPY_MODEL_d780281b6a6f477f8197f451fb1196d8"}}, "c159824f70de4706ae5fc7e4e7bf1b0d": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {}}, "c11d19b45c3348bea6ac88f5f9a0d8c2": {"model_name": "HBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "children": ["IPY_MODEL_90281c5b00be470a9907905264adeb54", "IPY_MODEL_c2e41cc356e24fff8b3892583ab6b94d"], "layout": "IPY_MODEL_c159824f70de4706ae5fc7e4e7bf1b0d"}}, "4b49d49bc04e496abe61f91fbac69dbc": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {}}, "ad65a44999f1410a8078252f7cf93e27": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {}}, "49c16d826b344543855da6e7f12d82d2": {"model_name": "IntSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "layout": "IPY_MODEL_4b49d49bc04e496abe61f91fbac69dbc", "max": 200, "style": "IPY_MODEL_ad65a44999f1410a8078252f7cf93e27", "value": 100}}, "9f29d071ad504d2c9e772f72239cb45b": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {}}, "2a08c473f3d440fe970f45dc1603a609": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {}}, "3d7319ce527c49eaa836e12c05dfb03c": {"model_name": "IntSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "layout": "IPY_MODEL_9f29d071ad504d2c9e772f72239cb45b", "style": "IPY_MODEL_2a08c473f3d440fe970f45dc1603a609", "value": 40}}, "893174df30e747ccb149d000dd2c4f8f": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {}}, "a099ef1307eb46cab2edb91540646193": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {}}, "26669978f40f4670aeb16bd5aec79f57": {"model_name": "IntSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "layout": "IPY_MODEL_893174df30e747ccb149d000dd2c4f8f", "max": 200, "style": "IPY_MODEL_a099ef1307eb46cab2edb91540646193", "value": 100}}, "998f01fa95004545bb59d4380374c272": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {}}, "648422ebef0a4c03b5dc537cbfa3c5de": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {}}, "9d68aec71ec740e3a7156e32e9c55e72": {"model_name": "IntSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "layout": "IPY_MODEL_998f01fa95004545bb59d4380374c272", "style": "IPY_MODEL_648422ebef0a4c03b5dc537cbfa3c5de", "value": 40}}, "4e27a55e67194eab89da62cee558e1d1": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {}}, "c7dea70ff05a47eb9b69892b0c5d547b": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {}}, "06b1ad45f02f40e683777a3198c54ad4": {"model_name": "IntSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "description": "a", "layout": "IPY_MODEL_4e27a55e67194eab89da62cee558e1d1", "style": "IPY_MODEL_c7dea70ff05a47eb9b69892b0c5d547b"}}, "2af435c9e1cd48d983b97bde06bdd284": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {}}, "21673a84e24042cf9be7eec662c22185": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {}}, "8eb23c129e6b44d4985a3d6c1f60ce6c": {"model_name": "IntSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "description": "b", "layout": "IPY_MODEL_2af435c9e1cd48d983b97bde06bdd284", "style": "IPY_MODEL_21673a84e24042cf9be7eec662c22185"}}, "773a79190f2441e0aa916ebbbc486dac": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {}}, "e2b71456feb54de5bd5e91a183067d15": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {}}, "4d887c94e5f2485da7f06efd61ebefb9": {"model_name": "IntSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "description": "c", "layout": "IPY_MODEL_773a79190f2441e0aa916ebbbc486dac", "style": "IPY_MODEL_e2b71456feb54de5bd5e91a183067d15"}}, "2487a9f0971548a68b6050d6756b9f8e": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {}}, "d6418e26e025463783d0b43db9347f96": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "layout": "IPY_MODEL_2487a9f0971548a68b6050d6756b9f8e", "outputs": []}}, "088f7f3df0a34c7fbab0939823d8d665": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {}}, "39ef03ec2c73478f8c30323b179c4052": {"model_name": "VBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "children": ["IPY_MODEL_06b1ad45f02f40e683777a3198c54ad4", "IPY_MODEL_8eb23c129e6b44d4985a3d6c1f60ce6c", "IPY_MODEL_4d887c94e5f2485da7f06efd61ebefb9"], "layout": "IPY_MODEL_088f7f3df0a34c7fbab0939823d8d665"}}, "be378b1035db411e93d97688291d53e6": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {}}, "8444ccf136b742f3b2b025b05289784c": {"model_name": "HBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "children": ["IPY_MODEL_39ef03ec2c73478f8c30323b179c4052", "IPY_MODEL_d6418e26e025463783d0b43db9347f96"], "layout": "IPY_MODEL_be378b1035db411e93d97688291d53e6"}}, "6a8422d340eb4388b78a4d66bf97cada": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {}}, "43fe1db9f4514f3fbe9ee00491e3bdcb": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {}}, "138e1db6691e4e6b9c90e592ee7e9daa": {"model_name": "IntSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "layout": "IPY_MODEL_6a8422d340eb4388b78a4d66bf97cada", "max": 200, "style": "IPY_MODEL_43fe1db9f4514f3fbe9ee00491e3bdcb", "value": 100}}, "28d5caf9a1274faea8cee31fb5b5fc14": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {}}, "09363bac5cbe4ce09008f524fdf71d4b": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {}}, "3390c4dd146047d1b003c4753de6b463": {"model_name": "IntSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "layout": "IPY_MODEL_28d5caf9a1274faea8cee31fb5b5fc14", "style": "IPY_MODEL_09363bac5cbe4ce09008f524fdf71d4b", "value": 40}}, "52cd0bf0820c414fbec802cab704c67d": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {}}, "a9262632be624ea2a9d38ed98ed8fb8b": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {}}, "e2668ecddef54c0387798382258631ec": {"model_name": "IntSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "layout": "IPY_MODEL_52cd0bf0820c414fbec802cab704c67d", "max": 200, "style": "IPY_MODEL_a9262632be624ea2a9d38ed98ed8fb8b", "value": 100}}, "49d1c4f422754b56991c63e09c15c63c": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {}}, "b5d847fc9d9d4a9798633901043a0366": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {}}, "ac54e03eeaf44ce8ba342221d8ebe62e": {"model_name": "IntSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "layout": "IPY_MODEL_49d1c4f422754b56991c63e09c15c63c", "style": "IPY_MODEL_b5d847fc9d9d4a9798633901043a0366", "value": 40}}}}
    </script>
  </head>
  <body>
    <h1>Widget export</h1>
    <div id="first-slider-widget">
      <!-- This script tag will be replaced by the view's DOM tree -->
      <script type="application/vnd.jupyter.widget-view+json">
        {"version_major": 2, "version_minor": 0, "model_id": "e2668ecddef54c0387798382258631ec"}
      </script>
    </div>
    <hrule />
    <div id="second-slider-widget">
      <!-- This script tag will be replaced by the view's DOM tree -->
      <script type="application/vnd.jupyter.widget-view+json">
        {"version_major": 2, "version_minor": 0, "model_id": "ac54e03eeaf44ce8ba342221d8ebe62e"}
      </script>
    </div>
  </body>
</html>
</file>

<file path="README.md">
# README FOR SERVER
</file>

<file path="start.sh">
turnserver \
        -n \
        -a \
        --log-file=stdout \
        --lt-cred-mech \
        --fingerprint \
        --no-stun \
        --no-multicast-peers \
        --no-cli \
        --no-tlsv1 \
        --no-tlsv1_1 \
        --realm="example.org" \
        --user="${TURN_USERNAME:-user}:${TURN_PASSWORD:-password}" \
        -p "${VAST_UDP_PORT_70001:-6000}" \
        -X "${PUBLIC_IPADDR:-localhost}" 2>&1 | tee /var/log/coturn.log &
# run jupyter server in the background
jupyter server &
# run tensordock in the foreground
nohup python3 -u server.py > server.log 2>&1 &
</file>

<file path="test_websocket_bridge.py">
#!/usr/bin/env python3
"""
Test script for WebSocket Bridge implementation.
This script tests the basic functionality of the WebSocket bridge service.
"""
import asyncio
import sys
import os
# Add the current directory to Python path
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)
from services.websocket_bridge import WebSocketBridge
from core.config import ServerConfig
async def test_websocket_bridge():
    """Test the WebSocket bridge functionality."""
    print("🧪 [Test] Starting WebSocket bridge tests...")
    try:
        # Create config
        config = ServerConfig()
        # Create WebSocket bridge
        bridge = WebSocketBridge(config)
        print("✅ [Test] WebSocket bridge created successfully")
        # Test status
        status = bridge.get_status()
        print(f"📊 [Test] Bridge status: {status}")
        # Test broadcast callback setting
        def mock_broadcast(message):
            print(f"📡 [Test] Mock broadcast: {message.get('action', 'unknown')}")
        bridge.set_broadcast_callback(mock_broadcast)
        print("✅ [Test] Broadcast callback set successfully")
        # Test URL building
        test_urls = [
            "http://localhost:8888/api/kernels/123/channels",
            "https://jupyter.example.com/api/kernels/456/channels",
            "/api/kernels/789/channels"
        ]
        for url in test_urls:
            ws_url = bridge._build_websocket_url(url)
            print(f"🔗 [Test] {url} -> {ws_url}")
        print("✅ [Test] URL building tests passed")
        # Test cleanup
        await bridge.cleanup()
        print("✅ [Test] Bridge cleanup completed")
        print("🎉 [Test] All WebSocket bridge tests passed!")
    except Exception as e:
        print(f"❌ [Test] Test failed: {e}")
        import traceback
        traceback.print_exc()
        return False
    return True
if __name__ == "__main__":
    success = asyncio.run(test_websocket_bridge())
    sys.exit(0 if success else 1)
</file>

<file path="test_widgets.py">
#!/usr/bin/env python3
"""
Test script for widget comm message handling.
This script creates widgets and runs a kernel to test bidirectional communication.
"""
import asyncio
import json
import time
from ipywidgets import IntSlider, VBox, HBox
import ipykernel
from jupyter_client import KernelManager
import threading
def create_test_widgets():
    """Create test widgets for comm message testing."""
    print("Creating test widgets...")
    # Create a simple slider
    slider = IntSlider(
        value=0,
        min=0,
        max=100,
        step=1,
        description='Test Slider',
        continuous_update=True
    )
    # Create a container
    container = VBox([
        HBox([
            IntSlider(value=0, description='a'),
            IntSlider(value=0, description='b'),
            IntSlider(value=0, description='c')
        ])
    ])
    print(f"Created slider with model_id: {slider.model_id}")
    print(f"Created container with model_id: {container.model_id}")
    return slider, container
def setup_comm_handling():
    """Set up comm message handling."""
    print("Setting up comm message handling...")
    # This would normally be handled by the Jupyter kernel
    # For testing, we'll simulate the comm handling
    def handle_comm_msg(comm, msg):
        """Handle incoming comm messages."""
        print(f"Received comm message: {msg}")
        if msg.get('method') == 'update':
            state = msg.get('state', {})
            print(f"Updating widget state: {state}")
            # Send echo response back
            echo_msg = {
                'method': 'echo_update',
                'state': state
            }
            print(f"Sending echo response: {echo_msg}")
            # In a real kernel, this would be sent back to the frontend
    return handle_comm_msg
def run_kernel_test():
    """Run a kernel test with widgets."""
    print("Starting kernel test...")
    # Create widgets
    slider, container = create_test_widgets()
    # Set up comm handling
    handle_comm = setup_comm_handling()
    print("Kernel test ready. Widgets created:")
    print(f"- Slider: {slider.model_id}")
    print(f"- Container: {container.model_id}")
    # Keep the script running
    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        print("Kernel test stopped.")
if __name__ == "__main__":
    run_kernel_test()
</file>

<file path="view_logs.sh">
#!/bin/bash
# Script to view TensorDock server logs
LOGS_DIR="logs"
if [ ! -d "$LOGS_DIR" ]; then
    echo "❌ Logs directory not found. Run the server first to generate logs."
    exit 1
fi
echo "📁 Available log files in $LOGS_DIR:"
echo ""
# List all log files with timestamps
for log_file in "$LOGS_DIR"/*.log; do
    if [ -f "$log_file" ]; then
        filename=$(basename "$log_file")
        size=$(du -h "$log_file" | cut -f1)
        modified=$(stat -f "%Sm" "$log_file" 2>/dev/null || stat -c "%y" "$log_file" 2>/dev/null)
        echo "📄 $filename ($size, modified: $modified)"
    fi
done
echo ""
echo "🔍 To view a specific log file, use:"
echo "   tail -f logs/tensordock_server.log    # View server logs in real-time"
echo "   tail -f logs/server_YYYYMMDD_HHMMSS.log  # View specific server run"
echo "   tail -f logs/jupyter_YYYYMMDD_HHMMSS.log  # View specific jupyter run"
echo ""
echo "📊 To view the latest server log:"
echo "   tail -n 50 logs/tensordock_server.log"
echo ""
echo "🔄 To follow logs in real-time:"
echo "   tail -f logs/tensordock_server.log"
</file>

<file path="core/logging.py">
"""
Centralized logging setup for TensorDock server.
"""
import logging
import datetime
import os
from typing import Any, Optional, Dict
def setup_logging(level: str = "INFO", log_file: str = "tensordock_server.log") -> logging.Logger:
    """Setup logging configuration with file output."""
    # Create logs directory if it doesn't exist
    log_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "logs")
    os.makedirs(log_dir, exist_ok=True)
    log_path = os.path.join(log_dir, log_file)
    # Configure logging to write to both file and console
    logging.basicConfig(
        level=getattr(logging, level.upper()),
        format='%(asctime)s [%(levelname)s] %(message)s',
        datefmt='%H:%M:%S',
        handlers=[
            logging.FileHandler(log_path, mode='a', encoding='utf-8'),
            logging.StreamHandler()  # Console output
        ]
    )
    logger = logging.getLogger("tensordock")
    logger.info(f"Logging initialized - output will be written to: {log_path}")
    return logger
def debug_log(message: str, data: Optional[Any] = None, level: str = "INFO") -> None:
    """
    Enhanced debug logging with structured data.
    Args:
        message: The log message
        data: Optional data to log
        level: Log level (INFO, DEBUG, WARNING, ERROR)
    """
    timestamp = datetime.datetime.now().strftime("%H:%M:%S.%f")[:-3]
    if data:
        if isinstance(data, dict):
            # Pretty print complex data structures
            import json
            data_str = json.dumps(data, indent=2, default=str)
            logging.log(
                getattr(logging, level.upper()),
                f"[{timestamp}] {message}\nData: {data_str}"
            )
        else:
            logging.log(
                getattr(logging, level.upper()),
                f"[{timestamp}] {message} - {data}"
            )
    else:
        logging.log(
            getattr(logging, level.upper()),
            f"[{timestamp}] {message}"
        )
class LoggerMixin:
    """Mixin class to add logging capabilities to other classes."""
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.logger = logging.getLogger(f"{self.__class__.__module__}.{self.__class__.__name__}")
    def log_debug(self, message: str, data: Optional[Any] = None):
        """Log debug message."""
        debug_log(message, data, "DEBUG")
    def log_info(self, message: str, data: Optional[Any] = None):
        """Log info message."""
        debug_log(message, data, "INFO")
    def log_warning(self, message: str, data: Optional[Any] = None):
        """Log warning message."""
        debug_log(message, data, "WARNING")
    def log_error(self, message: str, data: Optional[Any] = None):
        """Log error message."""
        debug_log(message, data, "ERROR")
</file>

<file path="jupyter_module/websocket_manager.py">
"""
WebSocket management for Jupyter integration.
Handles WebSocket connections, message processing, and reconnection logic.
"""
import asyncio
import json
import datetime
from typing import Optional, Dict, Any, Callable, List
from websockets.client import connect
# Use absolute imports to avoid relative import issues
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from core.logging import LoggerMixin, debug_log
from core.config import ServerConfig
class WebSocketManager(LoggerMixin):
    """Manages WebSocket connections to Jupyter server."""
    def __init__(self, config: ServerConfig):
        self.config = config
        self.kernel_ws = None
        self.event_ws = None
        # Connection state
        self.connected = False
        self.reconnect_attempts = 0
        self.max_reconnect_attempts = 10
        self.reconnect_delay = 5  # seconds
        # Message handling
        self.message_handlers: Dict[str, Callable] = {}
        self.message_queue = asyncio.Queue()
        self.response_queue = asyncio.Queue()
        # Task management
        self.message_consumer_task = None
        self.response_consumer_task = None
        self.ping_task = None
        self.reconnect_task = None
        # WebRTC broadcast callback for sending messages to frontend
        self.broadcast_callback = None
        # Message processing state
        self.processing_messages = False
        # Priority queues for ordered message processing
        self.high_priority_queue = asyncio.Queue()
        self.medium_priority_queue = asyncio.Queue()
        self.normal_priority_queue = asyncio.Queue()
    async def connect(self, ws_url: str, extra_headers: Dict[str, str] = None) -> bool:
        """Connect to a WebSocket URL."""
        try:
            debug_log(f"🔌 [WebSocket] Connecting to WebSocket", {
                "ws_url": ws_url,
                "has_headers": bool(extra_headers)
            })
            print(f"🔌 [WebSocket] Connecting to: {ws_url}")
            # Create WebSocket connection
            self.kernel_ws = await connect(
                ws_url,
                extra_headers=extra_headers or {},
                ping_interval=None,  # We'll handle pings manually
                ping_timeout=None
            )
            self.connected = True
            self.reconnect_attempts = 0
            debug_log(f"✅ [WebSocket] Connected successfully")
            print(f"✅ [WebSocket] Connected successfully")
            # Start message processing tasks
            self.message_consumer_task = asyncio.create_task(self._message_consumer())
            self.response_consumer_task = asyncio.create_task(self._response_consumer())
            self.ping_task = asyncio.create_task(self._ping_loop())
            return True
        except Exception as e:
            debug_log(f"❌ [WebSocket] Connection failed", {
                "error": str(e),
                "error_type": type(e).__name__
            })
            print(f"❌ [WebSocket] Connection failed: {e}")
            self.connected = False
            return False
    async def _message_consumer(self):
        """Process messages from the message queue."""
        self.processing_messages = True
        while self.processing_messages and self.connected:
            try:
                # Get message from queue
                message = await self.message_queue.get()
                if message is None:  # Shutdown signal
                    break
                # Process the message
                await self._handle_message(message)
                self.message_queue.task_done()
            except asyncio.CancelledError:
                debug_log(f"📥 [WebSocket] Message consumer cancelled")
                print(f"📥 [WebSocket] Message consumer cancelled")
                break
            except Exception as e:
                debug_log(f"❌ [WebSocket] Error in message consumer", {
                    "error": str(e),
                    "error_type": type(e).__name__
                })
                print(f"❌ [WebSocket] Error in message consumer: {e}")
                # Don't break the loop on individual message errors
                if self.message_queue.qsize() > 0:
                    self.message_queue.task_done()
        self.processing_messages = False
        debug_log(f"📥 [WebSocket] Message consumer stopped")
        print(f"📥 [WebSocket] Message consumer stopped")
    async def _response_consumer(self):
        """Process messages from priority queues and send them to the frontend via WebRTC."""
        debug_log(f"📤 [WebSocket] Response consumer started with priority queues")
        print(f"📤 [WebSocket] Response consumer started with priority queues")
        while self.connected:
            try:
                # Process messages in priority order: high -> medium -> normal -> response_queue (legacy)
                message = await self._get_next_priority_message()
                if message is None:  # Shutdown signal
                    break
                msg_type = message.get('header', {}).get('msg_type', 'unknown')
                msg_id = message.get('header', {}).get('msg_id', 'unknown')
                debug_log(f"📤 [WebSocket] Processing priority message", {
                    "msg_type": msg_type,
                    "msg_id": msg_id,
                    "has_channel": bool(message.get('channel')),
                    "channel": message.get('channel', 'unknown')
                })
                print(f"📤 [WebSocket] Processing priority message: {msg_type} (ID: {msg_id})")
                # CRITICAL: Send kernel message back to frontend via WebRTC
                await self._send_kernel_message_to_frontend(message)
            except asyncio.CancelledError:
                debug_log(f"📤 [WebSocket] Response consumer cancelled")
                print(f"📤 [WebSocket] Response consumer cancelled")
                break
            except Exception as e:
                debug_log(f"❌ [WebSocket] Error in response consumer", {
                    "error": str(e),
                    "error_type": type(e).__name__
                })
                print(f"❌ [WebSocket] Error in response consumer: {e}")
                # Continue processing other messages
                await asyncio.sleep(0.01)
        debug_log(f"📤 [WebSocket] Response consumer stopped")
        print(f"📤 [WebSocket] Response consumer stopped")
    async def _send_kernel_message_to_frontend(self, message: Dict[str, Any]):
        """Send a kernel message to the frontend via WebRTC."""
        try:
            # Extract message details for logging
            msg_type = message.get('header', {}).get('msg_type', 'unknown')
            msg_id = message.get('header', {}).get('msg_id', 'unknown')
            channel = message.get('channel', 'unknown')
            debug_log(f"📤 [WebSocket] Sending kernel message to frontend", {
                "msg_type": msg_type,
                "msg_id": msg_id,
                "channel": channel,
                "message_size": len(json.dumps(message))
            })
            print(f"📤 [WebSocket] Sending kernel message to frontend: {msg_type} (ID: {msg_id})")
            # CRITICAL: Send via WebRTC action system
            if hasattr(self, 'broadcast_callback') and self.broadcast_callback:
                # Create the WebRTC message structure
                webrtc_message = {
                    'action': 'kernel_message',
                    'data': message,
                    'msg_type': msg_type,
                    'msg_id': msg_id,
                    'channel': channel,
                    'timestamp': datetime.datetime.now().isoformat()
                }
                debug_log(f"📤 [WebSocket] WebRTC message structure", {
                    "action": webrtc_message['action'],
                    "has_data": bool(webrtc_message['data']),
                    "data_type": type(webrtc_message['data']).__name__,
                    "data_keys": list(webrtc_message['data'].keys()) if isinstance(webrtc_message['data'], dict) else [],
                    "webrtc_keys": list(webrtc_message.keys())
                })
                print(f"📤 [WebSocket] WebRTC message structure: action={webrtc_message['action']}, data_type={type(webrtc_message['data']).__name__}")
                await self.broadcast_callback(webrtc_message)
                debug_log(f"✅ [WebSocket] Kernel message sent to frontend via WebRTC", {
                    "msg_type": msg_type,
                    "msg_id": msg_id
                })
                print(f"✅ [WebSocket] Kernel message sent to frontend: {msg_type}")
            else:
                debug_log(f"⚠️ [WebSocket] No broadcast callback available for kernel message", {
                    "msg_type": msg_type,
                    "msg_id": msg_id
                })
                print(f"⚠️ [WebSocket] No broadcast callback available for kernel message: {msg_type}")
        except Exception as e:
            debug_log(f"❌ [WebSocket] Failed to send kernel message to frontend", {
                "error": str(e),
                "error_type": type(e).__name__,
                "msg_type": message.get('header', {}).get('msg_type', 'unknown')
            })
            print(f"❌ [WebSocket] Failed to send kernel message to frontend: {e}")
    async def _handle_message(self, message: str):
        """Handle incoming WebSocket message with proper ordering."""
        try:
            # Parse message
            msg = json.loads(message)
            msg_type = msg.get('header', {}).get('msg_type', 'unknown')
            msg_id = msg.get('header', {}).get('msg_id', 'unknown')
            parent_msg_id = msg.get('parent_header', {}).get('msg_id', 'none')
            channel = self._get_target_channel(msg_type)
            debug_log(f"📥 [WebSocket] Message received", {
                "msg_type": msg_type,
                "msg_id": msg_id,
                "parent_msg_id": parent_msg_id,
                "channel": channel,
                "message_length": len(message)
            })
            print(f"📥 [WebSocket] Message received: {msg_type} (ID: {msg_id}, Parent: {parent_msg_id}, Channel: {channel})")
            # Add channel information to message for proper routing
            msg['channel'] = channel
            # CRITICAL: Handle different message types with proper priorities
            if msg_type == 'kernel_info_reply':
                debug_log(f"🎯 [WebSocket] Kernel info reply received", {
                    "msg_id": msg_id,
                    "timestamp": datetime.datetime.now().isoformat()
                })
                print(f"🎯 [WebSocket] Kernel info reply received!")
                # High priority - put at front of queue
                await self._priority_queue_put(msg, priority='high')
            elif msg_type == 'status':
                execution_state = msg.get('content', {}).get('execution_state', 'unknown')
                debug_log(f"📊 [WebSocket] Status message received", {
                    "execution_state": execution_state,
                    "msg_id": msg_id,
                    "parent_msg_id": parent_msg_id
                })
                print(f"📊 [WebSocket] Status message: execution_state = {execution_state}")
                # High priority - status updates should be immediate
                await self._priority_queue_put(msg, priority='high')
            elif msg_type in ['execute_reply', 'execute_result', 'stream', 'display_data', 'error']:
                debug_log(f"📤 [WebSocket] Output message received", {
                    "msg_type": msg_type,
                    "msg_id": msg_id,
                    "parent_msg_id": parent_msg_id
                })
                print(f"📤 [WebSocket] Output message: {msg_type}")
                # Medium priority - execution results
                await self._priority_queue_put(msg, priority='medium')
            else:
                # Normal priority - other messages
                await self._priority_queue_put(msg, priority='normal')
            # Call message handlers if registered
            if msg_type in self.message_handlers:
                try:
                    await self.message_handlers[msg_type](msg)
                except Exception as e:
                    debug_log(f"❌ [WebSocket] Error in message handler", {
                        "msg_type": msg_type,
                        "error": str(e)
                    })
                    print(f"❌ [WebSocket] Error in message handler for {msg_type}: {e}")
        except json.JSONDecodeError as e:
            debug_log(f"❌ [WebSocket] JSON decode error", {
                "error": str(e),
                "message_preview": message[:200]
            })
            print(f"❌ [WebSocket] JSON decode error: {e}")
        except Exception as e:
            debug_log(f"❌ [WebSocket] Message handling error", {
                "error": str(e),
                "error_type": type(e).__name__
            })
            print(f"❌ [WebSocket] Message handling error: {e}")
    async def _emit_status_update(self, status: str):
        """Emit a status update event."""
        try:
            debug_log(f"📊 [WebSocket] Emitting status update", {
                "status": status,
                "timestamp": datetime.datetime.now().isoformat()
            })
            print(f"📊 [WebSocket] Emitting status update: {status}")
            # Store in response queue for processing
            # Note: No fake kernel_status_update action - only real JupyterLab messages
            await self.response_queue.put({
                'status': status,
                'timestamp': datetime.datetime.now().isoformat()
            })
        except Exception as e:
            debug_log(f"❌ [WebSocket] Error emitting status update", {
                "error": str(e),
                "status": status
            })
            print(f"❌ [WebSocket] Error emitting status update: {e}")
    async def _process_message(self, message: str):
        """Process a single message."""
        try:
            # Parse JSON message
            msg = json.loads(message)
            # Extract message metadata
            msg_type = msg.get('header', {}).get('msg_type', 'unknown')
            msg_id = msg.get('header', {}).get('msg_id', 'unknown')
            parent_msg_id = msg.get('parent_header', {}).get('msg_id', 'none')
            debug_log(f"📥 [WebSocket] Message parsed", {
                "msg_type": msg_type,
                "msg_id": msg_id,
                "parent_msg_id": parent_msg_id,
                "content_keys": list(msg.get('content', {}).keys()) if msg.get('content') else [],
                "channel": msg.get('channel', 'unknown')
            })
            # Store in response queue for processing
            await self.response_queue.put(msg)
            # Call message handlers if registered
            if msg_type in self.message_handlers:
                try:
                    await self.message_handlers[msg_type](msg)
                except Exception as e:
                    debug_log(f"❌ [WebSocket] Message handler error", {
                        "msg_type": msg_type,
                        "error": str(e),
                        "error_type": type(e).__name__
                    })
        except json.JSONDecodeError as e:
            debug_log(f"❌ [WebSocket] JSON decode error", {
                "error": str(e),
                "message_preview": message[:200] + "..." if len(message) > 200 else message
            })
        except Exception as e:
            debug_log(f"❌ [WebSocket] Message processing error", {
                "error": str(e),
                "error_type": type(e).__name__
            })
    async def _ping_loop(self):
        """Keep WebSocket connection alive with pings."""
        while self.connected and self.kernel_ws and self.kernel_ws.open:
            try:
                await self.kernel_ws.ping()
                await asyncio.sleep(10)  # Ping every 10 seconds
            except Exception as e:
                debug_log(f"❌ [WebSocket] Ping failed", {
                    "error": str(e),
                    "error_type": type(e).__name__
                })
                break
    async def listen_for_messages(self, message_callback: Callable = None):
        """Listen for incoming WebSocket messages."""
        if not self.kernel_ws:
            raise Exception("WebSocket not connected")
        debug_log(f"👂 [WebSocket] Starting message listener")
        try:
            while self.connected and self.kernel_ws and self.kernel_ws.open:
                try:
                    message = await self.kernel_ws.recv()
                    debug_log(f"📡 [WebSocket] Raw message received", {
                        "message_type": type(message).__name__,
                        "message_length": len(message) if hasattr(message, '__len__') else 'unknown'
                    })
                    # Filter out binary messages and control frames
                    if isinstance(message, bytes):
                        debug_log(f"📡 [WebSocket] Binary message received, skipping", {
                            "length": len(message)
                        })
                        continue
                    # Only process text messages
                    if isinstance(message, str):
                        debug_log(f"📡 [WebSocket] Text message queued", {
                            "message_length": len(message),
                            "message_preview": message[:100] + "..." if len(message) > 100 else message
                        })
                        # Add to message queue for processing
                        await self.message_queue.put(message)
                        # Call callback if provided
                        if message_callback:
                            try:
                                await message_callback(message)
                            except Exception as e:
                                debug_log(f"❌ [WebSocket] Message callback error", {
                                    "error": str(e),
                                    "error_type": type(e).__name__
                                })
                    else:
                        debug_log(f"📡 [WebSocket] Non-text message received, skipping", {
                            "message_type": type(message).__name__
                        })
                except Exception as e:
                    debug_log(f"❌ [WebSocket] Error receiving message", {
                        "error": str(e),
                        "error_type": type(e).__name__,
                        "ws_status": "open" if self.kernel_ws and self.kernel_ws.open else "closed"
                    })
                    # Check for connection close errors
                    if "1005" in str(e) or "closed" in str(e).lower():
                        debug_log(f"🔌 [WebSocket] Connection closed, will reconnect")
                        self.connected = False
                        break
                    elif "timeout" in str(e).lower():
                        debug_log(f"⏰ [WebSocket] Timeout, will reconnect")
                        self.connected = False
                        break
                    await asyncio.sleep(0.1)
        except Exception as e:
            debug_log(f"❌ [WebSocket] Fatal error in message listener", {
                "error": str(e),
                "error_type": type(e).__name__
            })
            self.connected = False
        # Start reconnection if needed
        if not self.connected:
            await self._start_reconnection()
    async def _start_reconnection(self):
        """Start reconnection process."""
        if self.reconnect_task:
            self.reconnect_task.cancel()
        self.reconnect_task = asyncio.create_task(self._reconnect_loop())
    async def _reconnect_loop(self):
        """Attempt to reconnect to WebSocket."""
        while not self.connected and self.reconnect_attempts < self.max_reconnect_attempts:
            self.reconnect_attempts += 1
            debug_log(f"🔄 [WebSocket] Reconnection attempt {self.reconnect_attempts}/{self.max_reconnect_attempts}")
            try:
                # Wait before attempting reconnection
                delay = min(self.reconnect_delay * self.reconnect_attempts, 30)
                await asyncio.sleep(delay)
                # Attempt reconnection (this would need the original connection parameters)
                debug_log(f"🔄 [WebSocket] Reconnection not implemented, stopping attempts")
                break
            except Exception as e:
                debug_log(f"❌ [WebSocket] Reconnection error", {
                    "attempt": self.reconnect_attempts,
                    "error": str(e),
                    "error_type": type(e).__name__
                })
        if self.reconnect_attempts >= self.max_reconnect_attempts:
            debug_log(f"❌ [WebSocket] Max reconnection attempts reached")
    async def send_message(self, message: Dict[str, Any]) -> bool:
        """Send a message through the WebSocket."""
        if not self.connected or not self.kernel_ws:
            debug_log(f"❌ [WebSocket] Cannot send message, not connected")
            return False
        try:
            # CRITICAL FIX: Ensure message is properly formatted
            if isinstance(message, str):
                # If it's already a string, send it directly
                message_str = message
                debug_log(f"📤 [WebSocket] Sending string message directly", {
                    "message_length": len(message_str),
                    "message_preview": message_str[:100]
                })
                print(f"📤 [WebSocket] Sending string message directly: {message_str[:100]}...")
            else:
                # If it's a dict, convert to JSON string
                message_str = json.dumps(message)
                debug_log(f"📤 [WebSocket] Message sent", {
                    "msg_type": message.get('header', {}).get('msg_type', 'unknown'),
                    "msg_id": message.get('header', {}).get('msg_id', 'unknown'),
                    "message_length": len(message_str)
                })
                print(f"📤 [WebSocket] Message sent: {message.get('header', {}).get('msg_type', 'unknown')}")
            await self.kernel_ws.send(message_str)
            return True
        except Exception as e:
            debug_log(f"❌ [WebSocket] Failed to send message", {
                "error": str(e),
                "error_type": type(e).__name__
            })
            print(f"❌ [WebSocket] Failed to send message: {e}")
            return False
    def add_message_handler(self, msg_type: str, handler: Callable):
        """Add a message handler for a specific message type."""
        self.message_handlers[msg_type] = handler
        debug_log(f"➕ [WebSocket] Message handler added", {
            "msg_type": msg_type,
            "total_handlers": len(self.message_handlers)
        })
    def remove_message_handler(self, msg_type: str):
        """Remove a message handler for a specific message type."""
        if msg_type in self.message_handlers:
            del self.message_handlers[msg_type]
            debug_log(f"➖ [WebSocket] Message handler removed", {
                "msg_type": msg_type,
                "total_handlers": len(self.message_handlers)
            })
    async def _priority_queue_put(self, message: Dict[str, Any], priority: str = 'normal'):
        """Put message in appropriate priority queue."""
        try:
            if priority == 'high':
                await self.high_priority_queue.put(message)
                debug_log(f"📥 [WebSocket] Message added to high priority queue", {
                    "msg_type": message.get('header', {}).get('msg_type', 'unknown'),
                    "queue_size": self.high_priority_queue.qsize()
                })
            elif priority == 'medium':
                await self.medium_priority_queue.put(message)
                debug_log(f"📥 [WebSocket] Message added to medium priority queue", {
                    "msg_type": message.get('header', {}).get('msg_type', 'unknown'),
                    "queue_size": self.medium_priority_queue.qsize()
                })
            else:
                await self.normal_priority_queue.put(message)
                debug_log(f"📥 [WebSocket] Message added to normal priority queue", {
                    "msg_type": message.get('header', {}).get('msg_type', 'unknown'),
                    "queue_size": self.normal_priority_queue.qsize()
                })
        except Exception as e:
            debug_log(f"❌ [WebSocket] Error adding message to priority queue", {
                "priority": priority,
                "error": str(e)
            })
            # Fallback to response queue
            await self.response_queue.put(message)
    async def _get_next_priority_message(self):
        """Get next message from priority queues in order: high -> medium -> normal -> response_queue."""
        try:
            # Check high priority first
            if not self.high_priority_queue.empty():
                return await self.high_priority_queue.get()
            # Then medium priority
            if not self.medium_priority_queue.empty():
                return await self.medium_priority_queue.get()
            # Then normal priority
            if not self.normal_priority_queue.empty():
                return await self.normal_priority_queue.get()
            # Finally check legacy response queue
            if not self.response_queue.empty():
                message = await self.response_queue.get()
                self.response_queue.task_done()
                return message
            # Wait for any message to arrive
            done, pending = await asyncio.wait([
                asyncio.create_task(self.high_priority_queue.get()),
                asyncio.create_task(self.medium_priority_queue.get()),
                asyncio.create_task(self.normal_priority_queue.get()),
                asyncio.create_task(self.response_queue.get())
            ], return_when=asyncio.FIRST_COMPLETED)
            # Cancel pending tasks
            for task in pending:
                task.cancel()
            # Return the first completed result
            for task in done:
                result = await task
                if result is not None:
                    return result
            return None
        except Exception as e:
            debug_log(f"❌ [WebSocket] Error getting next priority message", {
                "error": str(e)
            })
            return None
    def _get_target_channel(self, msg_type: str) -> str:
        """Determine the target channel for a message type."""
        if msg_type in ['kernel_info_request', 'kernel_info_reply', 'execute_request', 'execute_reply', 
                       'complete_request', 'complete_reply', 'inspect_request', 'inspect_reply',
                       'history_request', 'history_reply', 'is_complete_request', 'is_complete_reply']:
            return 'shell'
        elif msg_type in ['status', 'execute_input', 'execute_result', 'display_data', 'stream', 'error',
                         'clear_output', 'debug_event', 'comm_open', 'comm_msg', 'comm_close']:
            return 'iopub'
        elif msg_type in ['input_request', 'input_reply']:
            return 'stdin'
        elif msg_type in ['interrupt_request', 'interrupt_reply', 'shutdown_request', 'shutdown_reply']:
            return 'control'
        else:
            return 'unknown'
    def get_status(self) -> Dict[str, Any]:
        """Get current WebSocket status."""
        return {
            'connected': self.connected,
            'reconnect_attempts': self.reconnect_attempts,
            'max_reconnect_attempts': self.max_reconnect_attempts,
            'processing_messages': self.processing_messages,
            'message_queue_size': self.message_queue.qsize(),
            'response_queue_size': self.response_queue.qsize(),
            'high_priority_queue_size': self.high_priority_queue.qsize(),
            'medium_priority_queue_size': self.medium_priority_queue.qsize(),
            'normal_priority_queue_size': self.normal_priority_queue.qsize(),
            'total_handlers': len(self.message_handlers)
        }
    def is_connected(self) -> bool:
        """Check if WebSocket is connected."""
        # CRITICAL FIX: More robust connection checking
        if not self.kernel_ws:
            return False
        try:
            # Check if WebSocket is open and healthy
            if hasattr(self.kernel_ws, 'open'):
                return self.kernel_ws.open and self.connected
            else:
                # Fallback for different WebSocket implementations
                return self.connected
        except Exception as e:
            debug_log(f"⚠️ [WebSocket] Error checking connection status", {
                "error": str(e)
            })
            print(f"⚠️ [WebSocket] Error checking connection status: {e}")
            return False
    async def check_connection_health(self):
        """Check WebSocket connection health and reconnect if needed."""
        try:
            if not self.is_connected():
                debug_log(f"⚠️ [WebSocket] Connection unhealthy, attempting reconnection")
                print(f"⚠️ [WebSocket] Connection unhealthy, attempting reconnection")
                # Try to reconnect
                success = await self._reconnect()
                if success:
                    debug_log(f"✅ [WebSocket] Reconnection successful")
                    print(f"✅ [WebSocket] Reconnection successful")
                else:
                    debug_log(f"❌ [WebSocket] Reconnection failed")
                    print(f"❌ [WebSocket] Reconnection failed")
        except Exception as e:
            debug_log(f"❌ [WebSocket] Error in connection health check", {
                "error": str(e)
            })
            print(f"❌ [WebSocket] Error in connection health check: {e}")
    async def disconnect(self):
        """Disconnect the WebSocket."""
        debug_log(f"🔌 [WebSocket] Disconnecting WebSocket")
        self.connected = False
        self.processing_messages = False
        # Cancel tasks
        if self.message_consumer_task:
            self.message_consumer_task.cancel()
        if self.response_consumer_task:
            self.response_consumer_task.cancel()
        if self.ping_task:
            self.ping_task.cancel()
        if self.reconnect_task:
            self.reconnect_task.cancel()
        # Close WebSocket
        if self.kernel_ws:
            await self.kernel_ws.close()
            self.kernel_ws = None
        debug_log(f"🔌 [WebSocket] WebSocket disconnected")
    async def cleanup(self):
        """Clean up WebSocket resources."""
        await self.disconnect()
        # Clear queues
        while not self.message_queue.empty():
            try:
                self.message_queue.get_nowait()
                self.message_queue.task_done()
            except:
                pass
        while not self.response_queue.empty():
            try:
                self.response_queue.get_nowait()
                self.response_queue.task_done()
            except:
                pass
        debug_log(f"🧹 [WebSocket] WebSocket cleanup completed")
    def set_broadcast_callback(self, callback: Callable):
        """Set the callback for broadcasting messages to the frontend via WebRTC."""
        self.broadcast_callback = callback
        debug_log(f"📡 [WebSocket] Broadcast callback set")
        print(f"📡 [WebSocket] Broadcast callback set")
    async def _reconnect(self):
        """Attempt to reconnect the WebSocket."""
        try:
            debug_log(f"🔄 [WebSocket] Attempting to reconnect", {
                "attempt": self.reconnect_attempts + 1,
                "max_attempts": self.max_reconnect_attempts
            })
            print(f"🔄 [WebSocket] Attempting to reconnect (attempt {self.reconnect_attempts + 1})")
            if self.reconnect_attempts >= self.max_reconnect_attempts:
                debug_log(f"❌ [WebSocket] Max reconnection attempts reached")
                print(f"❌ [WebSocket] Max reconnection attempts reached")
                return False
            self.reconnect_attempts += 1
            # Wait before reconnecting
            await asyncio.sleep(self.reconnect_delay)
            # Try to reconnect
            if self.kernel_ws:
                try:
                    await self.kernel_ws.close()
                except:
                    pass
            # Reconnect logic would go here
            # For now, we'll just mark as disconnected
            self.connected = False
            debug_log(f"❌ [WebSocket] Reconnection not implemented yet")
            print(f"❌ [WebSocket] Reconnection not implemented yet")
            return False
        except Exception as e:
            debug_log(f"❌ [WebSocket] Reconnection error", {
                "error": str(e),
                "error_type": type(e).__name__
            })
            print(f"❌ [WebSocket] Reconnection error: {e}")
            return False
    async def reconnect(self, ws_url: str, extra_headers: Dict[str, str] = None) -> bool:
        """Reconnect to a WebSocket URL."""
        try:
            debug_log(f"🔄 [WebSocket] Reconnecting to WebSocket", {
                "ws_url": ws_url,
                "has_headers": bool(extra_headers)
            })
            print(f"🔄 [WebSocket] Reconnecting to: {ws_url}")
            # Close existing connection
            if self.kernel_ws:
                try:
                    await self.kernel_ws.close()
                except:
                    pass
                self.kernel_ws = None
            # Reset connection state
            self.connected = False
            self.processing_messages = False
            # Attempt new connection
            success = await self.connect(ws_url, extra_headers)
            if success:
                debug_log(f"✅ [WebSocket] Reconnection successful")
                print(f"✅ [WebSocket] Reconnection successful")
                self.reconnect_attempts = 0
            else:
                debug_log(f"❌ [WebSocket] Reconnection failed")
                print(f"❌ [WebSocket] Reconnection failed")
            return success
        except Exception as e:
            debug_log(f"❌ [WebSocket] Reconnection error", {
                "error": str(e),
                "error_type": type(e).__name__
            })
            print(f"❌ [WebSocket] Reconnection error: {e}")
            return False
</file>

<file path="services/http_proxy.py">
"""
HTTP proxy service for TensorDock server.
Handles sudo HTTP requests and Jupyter API proxying.
"""
import json
import datetime
from typing import Dict, Any, Optional
import requests
# Use absolute imports to avoid relative import issues
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from core.logging import LoggerMixin, debug_log
from core.config import ServerConfig
class HTTPProxyService(LoggerMixin):
    """Handles HTTP proxy requests to Jupyter server."""
    def __init__(self, config: ServerConfig):
        self.config = config
        self.base_url = config.jupyter_url
        self.headers = config.get_jupyter_headers()
        # Request statistics
        self.request_stats = {
            'total_requests': 0,
            'successful_requests': 0,
            'failed_requests': 0,
            'requests_by_method': {},
            'start_time': datetime.datetime.now()
        }
        debug_log(f"🌐 [HTTPProxy] HTTP proxy service initialized", {
            "base_url": self.base_url,
            "has_headers": bool(self.headers)
        })
    async def sudo_http_request(self, url: str, method: str, body: Optional[Dict[str, Any]] = None, headers: Optional[Dict[str, str]] = None) -> Dict[str, Any]:
        """Execute an HTTP request with elevated privileges."""
        try:
            # CRITICAL: Validate inputs to prevent errors
            if url is None:
                raise ValueError("URL cannot be None")
            if method is None:
                raise ValueError("Method cannot be None")
            # Ensure body is not None for logging
            safe_body = body if body is not None else {}
            # debug_log(f"🌐 [HTTPProxy] Processing sudo HTTP request", {
            #     "url": url,
            #     "method": method,
            #     "body_keys": list(safe_body.keys()) if isinstance(safe_body, dict) else [],
            #     "timestamp": datetime.datetime.now().isoformat()
            # })
            # Update statistics
            self.request_stats['total_requests'] += 1
            self.request_stats['requests_by_method'][method] = self.request_stats['requests_by_method'].get(method, 0) + 1
            # Build full URL - CRITICAL: Prevent double http:// issues
            if url.startswith('http://') or url.startswith('https://'):
                # URL is already absolute, use as-is
                full_url = url
                debug_log(f"🌐 [HTTPProxy] Using absolute URL as-is", {
                    "url": url,
                    "full_url": full_url
                })
            else:
                # URL is relative, construct full URL
                # Remove leading slash to avoid double slashes
                clean_url = url.lstrip('/') if url else ''
                full_url = f"{self.base_url}/{clean_url}" if clean_url else self.base_url
                debug_log(f"🌐 [HTTPProxy] Constructed relative URL", {
                    "url": url,
                    "clean_url": clean_url,
                    "base_url": self.base_url,
                    "full_url": full_url
                })
            # Execute request
            response = await self._execute_request(full_url, method, body, headers)
            if response['status'] < 400:
                self.request_stats['successful_requests'] += 1
                debug_log(f"✅ [HTTPProxy] Request successful", {
                    "url": url,
                    "method": method,
                    "status": response['status']
                })
            else:
                self.request_stats['failed_requests'] += 1
                debug_log(f"❌ [HTTPProxy] Request failed", {
                    "url": url,
                    "method": method,
                    "status": response['status']
                })
            return response
        except Exception as e:
            self.request_stats['failed_requests'] += 1
            debug_log(f"❌ [HTTPProxy] Request error", {
                "url": url,
                "method": method,
                "error": str(e),
                "error_type": type(e).__name__
            })
            return {
                'status': 500,
                'data': f"Error: {str(e)}",
                'headers': {},
                'error': str(e),
                'error_type': type(e).__name__
            }
    async def _execute_request(self, url: str, method: str, body: Optional[Dict[str, Any]] = None, headers: Optional[Dict[str, str]] = None) -> Dict[str, Any]:
        """Execute the actual HTTP request."""
        try:
            # Prepare request parameters
            # CRITICAL: Merge custom headers with default Jupyter headers
            request_headers = self.headers.copy()
            if headers:
                request_headers.update(headers)
                debug_log(f"🌐 [HTTPProxy] Merged headers", {
                    "default_headers": list(self.headers.keys()),
                    "custom_headers": list(headers.keys()),
                    "final_headers": list(request_headers.keys())
                })
            kwargs = {
                'headers': request_headers,
                'timeout': 30
            }
            # CRITICAL: Always ensure body is properly handled
            # Even if body is None or empty, we need to handle it properly
            if body is not None:
                # Handle both string and object bodies
                # Frontend sends stringified JSON from JupyterLab
                if isinstance(body, str):
                    try:
                        # Parse string to get the actual data
                        parsed_body = json.loads(body)
                        kwargs['json'] = parsed_body
                        debug_log(f"🌐 [HTTPProxy] Parsed string body to JSON", {
                            "original_body_type": type(body),
                            "parsed_body_keys": list(parsed_body.keys()) if isinstance(parsed_body, dict) else []
                        })
                    except json.JSONDecodeError:
                        # If it's not valid JSON, send as data
                        kwargs['data'] = body
                        debug_log(f"🌐 [HTTPProxy] Sending string body as data (not JSON)")
                else:
                    # Body is already an object, send as JSON
                    kwargs['json'] = body
                    debug_log(f"🌐 [HTTPProxy] Sending object body as JSON", {
                        "body_type": type(body),
                        "body_keys": list(body.keys()) if isinstance(body, dict) else []
                    })
            else:
                # CRITICAL: Ensure empty body is handled properly
                # Some Jupyter endpoints require an empty JSON body even for GET requests
                if method.upper() in ['POST', 'PUT', 'PATCH']:
                    kwargs['json'] = {}
                    debug_log(f"🌐 [HTTPProxy] Adding empty JSON body for {method} request")
            # Execute request based on method in a thread pool to avoid blocking
            import asyncio
            loop = asyncio.get_event_loop()
            def make_request():
                try:
                    if method.upper() == 'GET':
                        response = requests.get(url, **kwargs)
                    elif method.upper() == 'POST':
                        debug_log(f"🌐 [HTTPProxy] Making POST request", {
                            "url": url,
                            "kwargs": kwargs,
                            "body_type": type(body).__name__ if body else None
                        })
                        response = requests.post(url, **kwargs)
                    elif method.upper() == 'PUT':
                        response = requests.put(url, **kwargs)
                    elif method.upper() == 'DELETE':
                        response = requests.delete(url, **kwargs)
                    elif method.upper() == 'PATCH':
                        response = requests.patch(url, **kwargs)
                    else:
                        raise ValueError(f"Unsupported HTTP method: {method}")
                    # Log response details for debugging
                    debug_log(f"🌐 [HTTPProxy] Response received", {
                        "status_code": response.status_code,
                        "headers": dict(response.headers),
                        "content_length": len(response.content) if response.content else 0
                    })
                    return response
                except Exception as e:
                    debug_log(f"❌ [HTTPProxy] Request failed in make_request", {
                        "error": str(e),
                        "error_type": type(e).__name__,
                        "url": url,
                        "method": method,
                        "kwargs": kwargs
                    })
                    raise
            # Run the synchronous request in a thread pool
            response = await loop.run_in_executor(None, make_request)
            # Parse response
            try:
                response_data = response.json() if response.content else {}
            except json.JSONDecodeError:
                response_data = response.text
            # Log detailed response information for debugging
            debug_log(f"🌐 [HTTPProxy] Response parsing completed", {
                "status_code": response.status_code,
                "content_type": response.headers.get('content-type'),
                "data_type": type(response_data).__name__,
                "data_preview": str(response_data)[:200] if response_data else None
            })
            return {
                'status': response.status_code,
                'data': response_data,
                'headers': dict(response.headers),
                'url': url,
                'method': method
            }
        except requests.exceptions.RequestException as e:
            debug_log(f"❌ [HTTPProxy] Request exception", {
                "url": url,
                "method": method,
                "error": str(e),
                "error_type": type(e).__name__
            })
            raise
    async def get_jupyter_info(self) -> Dict[str, Any]:
        """Get Jupyter server information."""
        try:
            response = await self.sudo_http_request('api', 'GET')
            return response
        except Exception as e:
            debug_log(f"❌ [HTTPProxy] Failed to get Jupyter info", {
                "error": str(e),
                "error_type": type(e).__name__
            })
            return {'status': 500, 'data': 'Failed to get Jupyter info'}
    async def list_kernels(self) -> Dict[str, Any]:
        """List all running kernels."""
        try:
            response = await self.sudo_http_request('api/kernels', 'GET')
            return response
        except Exception as e:
            debug_log(f"❌ [HTTPProxy] Failed to list kernels", {
                "error": str(e),
                "error_type": type(e).__name__
            })
            return {'status': 500, 'data': 'Failed to list kernels'}
    async def list_sessions(self) -> Dict[str, Any]:
        """List all active sessions."""
        try:
            response = await self.sudo_http_request('api/sessions', 'GET')
            return response
        except Exception as e:
            debug_log(f"❌ [HTTPProxy] Failed to list sessions", {
                "error": str(e),
                "error_type": type(e).__name__
            })
            return {'status': 500, 'data': 'Failed to list sessions'}
    async def create_session(self, session_data: Dict[str, Any]) -> Dict[str, Any]:
        """Create a new Jupyter session."""
        try:
            response = await self.sudo_http_request('api/sessions', 'POST', session_data)
            return response
        except Exception as e:
            debug_log(f"❌ [HTTPProxy] Failed to create session", {
                "error": str(e),
                "error_type": type(e).__name__,
                "session_data": session_data
            })
            return {'status': 500, 'data': 'Failed to create session'}
    async def delete_session(self, session_id: str) -> Dict[str, Any]:
        """Delete a Jupyter session."""
        try:
            response = await self.sudo_http_request(f'api/sessions/{session_id}', 'DELETE')
            return response
        except Exception as e:
            debug_log(f"❌ [HTTPProxy] Failed to delete session", {
                "error": str(e),
                "error_type": type(e).__name__,
                "session_id": session_id
            })
            return {'status': 500, 'data': 'Failed to delete session'}
    def get_statistics(self) -> Dict[str, Any]:
        """Get HTTP proxy statistics."""
        uptime = datetime.datetime.now() - self.request_stats['start_time']
        return {
            'total_requests': self.request_stats['total_requests'],
            'successful_requests': self.request_stats['successful_requests'],
            'failed_requests': self.request_stats['failed_requests'],
            'success_rate': (self.request_stats['successful_requests'] / max(self.request_stats['total_requests'], 1)) * 100,
            'requests_by_method': dict(self.request_stats['requests_by_method']),
            'uptime_seconds': uptime.total_seconds(),
            'start_time': self.request_stats['start_time'].isoformat()
        }
    def get_status(self) -> Dict[str, Any]:
        """Get HTTP proxy service status."""
        return {
            'base_url': self.base_url,
            'has_headers': bool(self.headers),
            'total_requests': self.request_stats['total_requests']
        }
    async def cleanup(self):
        """Clean up HTTP proxy service resources."""
        debug_log(f"🧹 [HTTPProxy] Cleaning up HTTP proxy service")
        # Clear statistics
        self.request_stats.clear()
        debug_log(f"🧹 [HTTPProxy] HTTP proxy service cleanup completed")
</file>

<file path="run_modular.py">
#!/usr/bin/env python3
"""
Simple launcher for the modular TensorDock server.
This script sets up the Python path correctly and runs the server.
"""
import sys
import os
import datetime
# Get the directory containing this script
script_dir = os.path.dirname(os.path.abspath(__file__))
# Create logs directory if it doesn't exist
logs_dir = os.path.join(script_dir, "logs")
os.makedirs(logs_dir, exist_ok=True)
# Create a timestamped log file for this run
timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
log_file = os.path.join(logs_dir, f"server_run_{timestamp}.log")
# Redirect stdout and stderr to the log file
class Logger:
    def __init__(self, filename):
        self.terminal = sys.stdout
        self.log = open(filename, 'a', encoding='utf-8')
    def write(self, message):
        self.terminal.write(message)
        self.log.write(message)
        self.log.flush()
    def flush(self):
        self.terminal.flush()
        self.log.flush()
# Redirect stdout and stderr
sys.stdout = Logger(log_file)
sys.stderr = Logger(log_file)
# Add the script directory to Python path
sys.path.insert(0, script_dir)
# Now we can import our modules
try:
    from server_modular import main
    import asyncio
    print("🚀 Starting Modular TensorDock Server...")
    print("🔗 WebRTC Bridge: Ready for Jupyter communication")   
    print("🌐 HTTP Proxy: Integrated for API requests")   
    print("📡 WebSocket Bridge: Ready for kernel messages")   
    print("⚙️  Message Routing: Action processor configured")   
    print(f"📁 Working directory: {script_dir}")
    print(f"🐍 Python path: {sys.path[0]}")
    print(f"📝 All output will be logged to: {log_file}")
    # Run the server
    asyncio.run(main())
except ImportError as e:
    print(f"❌ Import error: {e}")
    print("💡 Make sure you're running this from the tensordock directory")
    print("💡 Try: cd tensordock && python run_modular.py")
    sys.exit(1)
except Exception as e:
    print(f"❌ Error starting server: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)
</file>

<file path="server_modular.py">
"""
Modular TensorDock server using the new WebRTC, Jupyter, Messaging, and Service layer structure.
This is a fully refactored version of the original server.py with no legacy code.
"""
import asyncio
import json
import threading
import time
import uuid
import datetime
import sys
import os
from aiohttp import web
# Add the tensordock directory to Python path for imports
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)
from core.config import ServerConfig
from core.logging import setup_logging, debug_log
from webrtc.peer_manager import WebRTCPeerManager
from webrtc.signaling import SignalingManager
from jupyter_module import JupyterManager
from messaging import MessageBroker, WorkerManager, ActionProcessor
from services import HTTPProxyService, CanvasService, WidgetService, WebSocketBridge
class ModularTensorDockServer:
    """Modular TensorDock server using the new module structure."""
    def __init__(self):
        # Initialize configuration
        self.config = ServerConfig()
        # Initialize modules
        self.peer_manager = WebRTCPeerManager(self.config)
        self.signaling_manager = SignalingManager()
        self.jupyter_manager = JupyterManager(self.config)
        # Initialize messaging system
        self.message_broker = MessageBroker()
        self.worker_manager = WorkerManager(max_workers=4)
        self.action_processor = ActionProcessor()
        # Initialize service layer
        self.http_proxy_service = HTTPProxyService(self.config)
        self.canvas_service = CanvasService()
        self.widget_service = WidgetService()
        self.websocket_bridge = WebSocketBridge(self.config)
        # Set up module integrations
        self._setup_module_integrations()
        # Set up cross-references between messaging components
        self.message_broker.set_worker_manager(self.worker_manager)
        # Start messaging system
        asyncio.create_task(self._start_messaging_system())
        # Initialize Jupyter manager
        asyncio.create_task(self.initialize_jupyter())
        debug_log(f"🚀 [Server] Modular TensorDock server initialized")
    def _setup_module_integrations(self):
        """Set up integrations between modules."""
        # Set up Jupyter manager
        self.jupyter_manager.set_broadcast_callback(self.broadcast)
        self.jupyter_manager.set_websocket_bridge(self.websocket_bridge)
        # Set up action processor
        self.action_processor.set_jupyter_manager(self.jupyter_manager)
        self.action_processor.set_broadcast_callback(self.broadcast)
        self.action_processor.set_http_proxy_service(self.http_proxy_service)
        self.action_processor.set_canvas_service(self.canvas_service)
        self.action_processor.set_widget_service(self.widget_service)
        self.action_processor.set_peer_manager(self.peer_manager)
        self.action_processor.set_websocket_bridge(self.websocket_bridge)
        # Set up WebSocket bridge broadcast callback
        self.websocket_bridge.set_broadcast_callback(self.broadcast)
        # Route WebRTC data channel messages into the message broker
        self.peer_manager.add_connection_callback('data_channel_ready', self._on_data_channel_ready)
        # Set up message broker routing rules
        self.message_broker.add_routing_rule('execute_code', 'action')
        self.message_broker.add_routing_rule('comm_msg', 'action')
        self.message_broker.add_routing_rule('kernel_message', 'action')
        self.message_broker.add_routing_rule('input', 'input')
        self.message_broker.add_routing_rule('sudo_http_request', 'action')
        self.message_broker.add_routing_rule('canvas_data', 'action')
        self.message_broker.add_routing_rule('start_kernel', 'action')
        self.message_broker.add_routing_rule('restart_kernel', 'action')
        self.message_broker.add_routing_rule('websocket_connect', 'action')
        self.message_broker.add_routing_rule('websocket_message', 'action')
        self.message_broker.add_routing_rule('websocket_close', 'action')
        # Register action handlers with worker manager
        self.worker_manager.register_task_handler('execute_code', self.action_processor._handle_execute_code)
        self.worker_manager.register_task_handler('comm_msg', self.action_processor._handle_comm_msg)
        self.worker_manager.register_task_handler('kernel_message', self.action_processor._handle_kernel_message)
        self.worker_manager.register_task_handler('start_kernel', self.action_processor._handle_start_kernel)
        self.worker_manager.register_task_handler('restart_kernel', self.action_processor._handle_restart_kernel)
        self.worker_manager.register_task_handler('interrupt_kernel', self.action_processor._handle_interrupt_kernel)
        self.worker_manager.register_task_handler('input', self.action_processor._handle_input)
        self.worker_manager.register_task_handler('sudo_http_request', self.action_processor._handle_sudo_http_request)
        self.worker_manager.register_task_handler('canvas_data', self.action_processor._handle_canvas_data)
        self.worker_manager.register_task_handler('websocket_connect', self.action_processor._handle_websocket_connect)
        self.worker_manager.register_task_handler('websocket_message', self.action_processor._handle_websocket_message)
        self.worker_manager.register_task_handler('websocket_close', self.action_processor._handle_websocket_close)
        debug_log(f"🔗 [Server] Module integrations configured")
    def _on_data_channel_ready(self, client_id, channel):
        """Attach listeners to a client's WebRTC message handler and forward to broker."""
        try:
            handler = self.peer_manager.get_message_handler(client_id)
            if not handler:
                debug_log(f"⚠️ [Server] No message handler for client", {"client_id": client_id})
                return
            # Known actions to forward
            actions = [
                'sudo_http_request',
                'execute_code',
                'comm_msg',
                'kernel_message',
                'input',
                'canvas_data',
                'events',
                'start_kernel',
                'restart_kernel',
                'websocket_connect',
                'websocket_message',
                'websocket_close'
            ]
            import asyncio
            def register(action_name: str):
                def listener(data):
                    # Normalize payload to include action and client id
                    message = {'action': action_name, 'client_id': client_id}
                    if isinstance(data, dict):
                        message.update(data)
                    else:
                        message['data'] = data
                    # Forward to message broker
                    asyncio.create_task(self.message_broker.route_message(message))
                handler.add_listener(action_name, listener)
            for act in actions:
                register(act)
            debug_log(f"🔗 [Server] Data channel listeners attached", {
                "client_id": client_id,
                "actions": actions
            })
        except Exception as e:
            debug_log(f"❌ [Server] Failed to attach data channel listeners", {
                "client_id": client_id,
                "error": str(e),
                "error_type": type(e).__name__
            })
    async def _start_messaging_system(self):
        """Start the messaging system components."""
        try:
            debug_log(f"🚀 [Server] Starting messaging system")
            # Start message broker
            await self.message_broker.start()
            # Start worker manager
            await self.worker_manager.start_workers()
            debug_log(f"✅ [Server] Messaging system started successfully")
        except Exception as e:
            debug_log(f"❌ [Server] Failed to start messaging system", {
                "error": str(e),
                "error_type": type(e).__name__
            })
    async def initialize_jupyter(self):
        """Initialize the Jupyter manager."""
        try:
            debug_log(f"🚀 [Server] Initializing Jupyter manager")
            # Wait a bit for the server to start
            await asyncio.sleep(5)
            success = await self.jupyter_manager.initialize()
            if success:
                debug_log(f"✅ [Server] Jupyter manager initialized successfully")
            else:
                debug_log(f"❌ [Server] Failed to initialize Jupyter manager")
        except Exception as e:
            debug_log(f"❌ [Server] Jupyter initialization error", {
                "error": str(e),
                "error_type": type(e).__name__
            })
    async def handle_client(self, offer):
        """Handle new client connection using WebRTC peer manager."""
        try:
            debug_log(f"🔗 [Server] New client connection request")
            # Use the peer manager to handle the client
            response = await self.peer_manager.handle_client_offer(offer)
            debug_log(f"✅ [Server] Client connection established")
            return response
        except Exception as e:
            debug_log(f"❌ [Server] Client connection error", {
                "error": str(e),
                "error_type": type(e).__name__
            })
            raise
    async def broadcast(self, message, client_id=None):
        """Broadcast message to clients using WebRTC peer manager."""
        try:
            debug_log(f"📤 [Server] Broadcasting message", {
                "action": message.get('action'),
                "exclude_client_id": client_id
            })
            return self.peer_manager.broadcast_message(message, client_id)
        except Exception as e:
            debug_log(f"❌ [Server] Broadcast error", {
                "error": str(e),
                "error_type": type(e).__name__
            })
            return 0
    def get_server_status(self) -> dict:
        """Get comprehensive server status."""
        return {
            'server_type': 'modular',
            'modules': {
                'webrtc': self.peer_manager.get_status(),
                'jupyter': self.jupyter_manager.get_status(),
                'signaling': {
                    'total_offers': len(self.signaling_manager.offers)
                },
                'messaging': {
                    'broker': self.message_broker.get_queue_status(),
                    'worker': self.worker_manager.get_worker_status(),
                    'action_processor': self.action_processor.get_status()
                },
                'services': {
                    'http_proxy': self.http_proxy_service.get_status(),
                    'canvas': self.canvas_service.get_status(),
                    'widget': self.widget_service.get_status(),
                    'websocket_bridge': self.websocket_bridge.get_status()
                }
            }
        }
    async def cleanup(self):
        """Clean up server resources."""
        debug_log(f"🧹 [Server] Cleaning up server")
        # Cleanup modules
        await self.jupyter_manager.cleanup()
        await self.message_broker.cleanup()
        await self.worker_manager.cleanup()
        await self.action_processor.cleanup()
        # Cleanup services
        await self.http_proxy_service.cleanup()
        await self.canvas_service.cleanup()
        await self.widget_service.cleanup()
        await self.websocket_bridge.cleanup()
        debug_log(f"🧹 [Server] Server cleanup completed")
async def handle_offer(request):
    """Handle WebRTC offer from client."""
    try:
        params = await request.json()
        server = request.app['server']
        response = await server.handle_client(params)
        return web.Response(
            content_type="application/json",
            text=json.dumps(response)
        )
    except Exception as e:
        debug_log(f"❌ [HTTP] Offer handling error", {
            "error": str(e),
            "error_type": type(e).__name__
        })
        return web.Response(
            content_type="application/json",
            text=json.dumps({'error': str(e)}),
            status=500
        )
async def handle_status(request):
    """Handle status request."""
    try:
        server = request.app['server']
        status = server.get_server_status()
        return web.Response(
            content_type="application/json",
            text=json.dumps(status)
        )
    except Exception as e:
        debug_log(f"❌ [HTTP] Status handling error", {
            "error": str(e),
            "error_type": type(e).__name__
        })
        return web.Response(
            content_type="application/json",
            text=json.dumps({'error': str(e)}),
            status=500
        )
async def main():
    """Main server function."""
    try:
        # Setup logging with file output
        logger = setup_logging(log_file="tensordock_server.log")
        debug_log(f"🚀 [Main] Starting Modular TensorDock Server")
        # Create server instance
        server = ModularTensorDockServer()
        # Create aiohttp app
        app = web.Application()
        app['server'] = server
        # Add routes
        app.router.add_post("/offer", handle_offer)
        app.router.add_get("/status", handle_status)
        # Setup runner
        runner = web.AppRunner(app)
        await runner.setup()
        # Start site
        port = int(os.environ.get('VAST_TCP_PORT_70000', 8765))
        site = web.TCPSite(runner, "0.0.0.0", port)
        debug_log(f"🌐 [Main] Starting HTTP server on port {port}")
        await site.start()
        debug_log(f"✅ [Main] Modular TensorDock Server started successfully")
        print(f"Modular server started at http://0.0.0.0:{port}")
        # Run forever
        await asyncio.Future()
    except Exception as e:
        debug_log(f"❌ [Main] Server startup error", {
            "error": str(e),
            "error_type": type(e).__name__
        })
        raise
    finally:
        # Cleanup
        if 'server' in locals():
            await server.cleanup()
if __name__ == "__main__":
    asyncio.run(main())
</file>

<file path="messaging/action_processor.py">
"""
Action processor for TensorDock server.
Handles specific action types and integrates with other modules.
"""
import asyncio
import json
import datetime
from typing import Dict, Any, Optional, Callable, Set
# Use absolute imports to avoid relative import issues
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from core.logging import LoggerMixin, debug_log
class ActionProcessor(LoggerMixin):
    """Processes specific action types and integrates with other modules."""
    def __init__(self):
        # External module references (to be set by server)
        self.jupyter_manager = None
        self.broadcast_callback = None
        self.http_proxy_service = None
        self.canvas_service = None
        self.widget_service = None
        self.websocket_bridge = None
        self.peer_manager = None
        # Action handlers
        self.action_handlers: Dict[str, Callable] = {}
        # Action statistics
        self.action_stats = {
            'total_actions': 0,
            'actions_by_type': {},
            'successful_actions': 0,
            'failed_actions': 0,
            'start_time': datetime.datetime.now()
        }
        # ✅ CRITICAL FIX: Add message deduplication tracking
        self.processed_comm_messages: Set[str] = set()  # Track processed comm message IDs
        self.comm_message_tracker: Dict[str, Set[str]] = {}  # comm_id -> set of processed msg_ids
        # Register default handlers
        self._register_default_handlers()
        debug_log(f"⚙️ [ActionProcessor] Action processor initialized")
    def set_jupyter_manager(self, jupyter_manager):
        """Set the Jupyter manager reference."""
        self.jupyter_manager = jupyter_manager
        debug_log(f"🔗 [ActionProcessor] Jupyter manager reference set")
    def set_broadcast_callback(self, broadcast_callback: Callable):
        """Set the broadcast callback function."""
        self.broadcast_callback = broadcast_callback
        debug_log(f"🔗 [ActionProcessor] Broadcast callback set")
    def set_http_proxy_service(self, http_proxy_service):
        """Set the HTTP proxy service reference."""
        self.http_proxy_service = http_proxy_service
        debug_log(f"🔗 [ActionProcessor] HTTP proxy service reference set")
    def set_canvas_service(self, canvas_service):
        """Set the canvas service reference."""
        self.canvas_service = canvas_service
        debug_log(f"🔗 [ActionProcessor] Canvas service reference set")
    def set_widget_service(self, widget_service):
        """Set the widget service reference."""
        self.widget_service = widget_service
        debug_log(f"🔗 [ActionProcessor] Widget service reference set")
    def set_websocket_bridge(self, websocket_bridge):
        """Set the WebSocket bridge service."""
        self.websocket_bridge = websocket_bridge
        debug_log(f"🔌 [ActionProcessor] WebSocket bridge service set")
    def set_peer_manager(self, peer_manager):
        """Set the peer manager."""
        self.peer_manager = peer_manager
        debug_log(f"🔗 [ActionProcessor] Peer manager set")
    def _register_default_handlers(self):
        """Register default action handlers."""
        self.register_handler('execute_code', self._handle_execute_code)
        self.register_handler('comm_msg', self._handle_comm_msg)
        self.register_handler('kernel_message', self._handle_kernel_message)
        self.register_handler('start_kernel', self._handle_start_kernel)
        self.register_handler('restart_kernel', self._handle_restart_kernel)
        self.register_handler('interrupt_kernel', self._handle_interrupt_kernel)
        self.register_handler('input', self._handle_input)
        self.register_handler('sudo_http_request', self._handle_sudo_http_request)
        self.register_handler('canvas_data', self._handle_canvas_data)
        # WebSocket handlers
        self.register_handler('websocket_connect', self._handle_websocket_connect)
        self.register_handler('websocket_message', self._handle_websocket_message)
        self.register_handler('websocket_close', self._handle_websocket_close)
        debug_log(f"➕ [ActionProcessor] Default handlers registered", {
            "total_handlers": len(self.action_handlers)
        })
    def register_handler(self, action: str, handler: Callable):
        """Register a handler for a specific action."""
        self.action_handlers[action] = handler
        debug_log(f"➕ [ActionProcessor] Action handler registered", {
            "action": action,
            "handler": handler.__name__,
            "total_handlers": len(self.action_handlers)
        })
    def unregister_handler(self, action: str):
        """Unregister an action handler."""
        if action in self.action_handlers:
            del self.action_handlers[action]
            debug_log(f"➖ [ActionProcessor] Action handler unregistered", {
                "action": action,
                "total_handlers": len(self.action_handlers)
            })
    async def process_action(self, action: Dict[str, Any]) -> bool:
        """Process a single action."""
        try:
            action_type = action.get('action', 'unknown')
            debug_log(f"⚙️ [ActionProcessor] Processing action", {
                "action": action_type,
                "action_keys": list(action.keys()),
                "timestamp": datetime.datetime.now().isoformat()
            })
            # Update statistics
            self.action_stats['total_actions'] += 1
            self.action_stats['actions_by_type'][action_type] = self.action_stats['actions_by_type'].get(action_type, 0) + 1
            # Check if we have a handler for this action
            if action_type in self.action_handlers:
                handler = self.action_handlers[action_type]
                try:
                    # Execute handler
                    result = await handler(action)
                    self.action_stats['successful_actions'] += 1
                    debug_log(f"✅ [ActionProcessor] Action processed successfully", {
                        "action": action_type,
                        "result": result
                    })
                    return True
                except Exception as e:
                    self.action_stats['failed_actions'] += 1
                    debug_log(f"❌ [ActionProcessor] Action handler error", {
                        "action": action_type,
                        "error": str(e),
                        "error_type": type(e).__name__
                    })
                    return False
            else:
                self.action_stats['failed_actions'] += 1
                debug_log(f"❌ [ActionProcessor] No handler for action", {
                    "action": action_type,
                    "available_handlers": list(self.action_handlers.keys())
                })
                return False
        except Exception as e:
            self.action_stats['failed_actions'] += 1
            debug_log(f"❌ [ActionProcessor] Action processing error", {
                "error": str(e),
                "error_type": type(e).__name__,
                "action": action
            })
            return False
    async def _handle_execute_code(self, action: Dict[str, Any]) -> Optional[str]:
        """Handle code execution action."""
        if not self.jupyter_manager:
            raise Exception("Jupyter manager not available")
        code = action.get('code', '')
        cell_id = action.get('cell_id', 'unknown')
        debug_log(f"⚡ [ActionProcessor] Executing code", {
            "cell_id": cell_id,
            "code_length": len(code)
        })
        execution_count = await self.jupyter_manager.execute_code(code, cell_id)
        if execution_count is not None and self.broadcast_callback:
            await self.broadcast_callback({
                'action': 'execution_complete',
                'cell_id': cell_id,
                'execution_count': execution_count
            })
        return execution_count
    async def _handle_comm_msg(self, action: Dict[str, Any]):
        """Handle comm message action with proper Jupyter integration."""
        instance_id = action.get('instanceId')
        kernel_id = action.get('kernelId')
        if not instance_id or not kernel_id:
            raise ValueError("Missing instanceId or kernelId in comm message")
        # Extract Jupyter message from action
        jupyter_message = {
            'header': action.get('header', {}),
            'content': action.get('content', {}),
            'metadata': action.get('metadata', {}),
            'buffers': action.get('buffers', [])
        }
        # ✅ CRITICAL FIX: Check for duplicate comm message processing
        msg_id = jupyter_message.get('header', {}).get('msg_id')
        comm_id = jupyter_message.get('content', {}).get('comm_id')
        if msg_id and msg_id in self.processed_comm_messages:
            debug_log(f"🔄 [ActionProcessor] Skipping duplicate comm message", {
                "instance_id": instance_id,
                "kernel_id": kernel_id,
                "msg_id": msg_id,
                "comm_id": comm_id
            })
            return {"success": True, "message": "Duplicate comm message skipped"}
        # Track processed message
        if msg_id:
            self.processed_comm_messages.add(msg_id)
        # Track comm messages by comm_id
        if comm_id:
            if comm_id not in self.comm_message_tracker:
                self.comm_message_tracker[comm_id] = set()
            if msg_id:
                self.comm_message_tracker[comm_id].add(msg_id)
        debug_log(f"💬 [ActionProcessor] Enhanced comm message handling", {
            "instance_id": instance_id,
            "kernel_id": kernel_id,
            "msg_type": jupyter_message.get('header', {}).get('msg_type'),
            "comm_id": comm_id,
            "target_name": jupyter_message.get('content', {}).get('target_name'),
            "msg_id": msg_id
        })
        # Forward to WebSocket bridge for proper Jupyter handling
        if self.websocket_bridge:
            success = await self.websocket_bridge.send_message(instance_id, kernel_id, jupyter_message)
            if not success:
                debug_log(f"❌ [ActionProcessor] Failed to forward comm message to Jupyter")
        # Also track in widget service for state management
        if self.widget_service:
            try:
                await self.widget_service.handle_jupyter_comm_message(kernel_id, jupyter_message)
            except AttributeError:
                # Fallback to legacy method if enhanced widget service not available
                data = jupyter_message.get('content', {}).get('data', {})
                client_id = action.get('client_id', 'unknown')
                result = await self.widget_service.handle_comm_message(comm_id, data, client_id)
                if result.get('success') and self.broadcast_callback:
                    await self.broadcast_callback({
                        'action': 'comm_msg_processed',
                        'comm_id': comm_id,
                        'result': result
                    })
                return result
        return {"success": True, "message": "Comm message processed via WebSocket bridge"}
    async def _handle_kernel_message(self, action: Dict[str, Any]) -> bool:
        """Handle kernel message action via WebSocket bridge."""
        if not hasattr(self, 'websocket_bridge') or not self.websocket_bridge:
            raise Exception("WebSocket bridge service not available")
        # Extract message details from the action
        instance_id = action.get('instanceId')
        kernel_id = action.get('kernelId')
        data = action.get('data')  # The Jupyter message is in the 'data' field
        channel = action.get('channel')  # The channel information from frontend
        debug_log(f"🔍 [ActionProcessor] Kernel message via WebSocket bridge", {
            "instance_id": instance_id,
            "kernel_id": kernel_id,
            "has_data": data is not None,
            "data_type": type(data).__name__ if data else 'None'
        })
        if not instance_id or not data:
            debug_log(f"❌ [ActionProcessor] Missing required fields for kernel message", {
                "instance_id": instance_id,
                "has_data": data is not None
            })
            return False
        try:
            # Extract message details from the Jupyter message data
            msg_type = data.get('header', {}).get('msg_type', 'unknown')
            msg_id = data.get('header', {}).get('msg_id', 'unknown')
            session_id = data.get('header', {}).get('session', 'unknown')
            debug_log(f"🔍 [ActionProcessor] Jupyter message details", {
                "msg_type": msg_type,
                "msg_id": msg_id,
                "session_id": session_id,
                "channel": channel
            })
            # CRITICAL: Extract session ID from the kernel message and update WebSocket bridge
            if session_id and session_id != 'unknown':
                debug_log(f"🔍 [ActionProcessor] Extracted session ID from kernel message: {session_id}")
                # Update the WebSocket bridge with the session ID for this instance
                self.websocket_bridge.update_session_id(instance_id, session_id)
            else:
                debug_log(f"⚠️ [ActionProcessor] No valid session ID found in kernel message header")
            # Send message via WebSocket bridge with channel information
            success = await self.websocket_bridge.send_message(instance_id, kernel_id or 'default', data, channel)
            if success:
                debug_log(f"✅ [ActionProcessor] Kernel message sent via WebSocket bridge", {
                    "instance_id": instance_id,
                    "kernel_id": kernel_id,
                    "msg_type": msg_type,
                    "session_id": session_id,
                    "channel": channel
                })
                return True
            else:
                debug_log(f"❌ [ActionProcessor] Failed to send kernel message via WebSocket bridge", {
                    "instance_id": instance_id,
                    "kernel_id": kernel_id
                })
                return False
        except Exception as e:
            debug_log(f"❌ [ActionProcessor] Error sending kernel message via WebSocket bridge", {
                "instance_id": instance_id,
                "kernel_id": kernel_id,
                "error": str(e),
                "error_type": type(e).__name__
            })
            return False
    async def _route_kernel_message_via_http(self, target_kernel_id: str, message_data: Any) -> bool:
        """Route a kernel message to a specific kernel via HTTP API."""
        try:
            debug_log(f"🌐 [ActionProcessor] Routing kernel message via HTTP", {
                "target_kernel_id": target_kernel_id,
                "message_type": "kernel_info_request"
            })
            print(f"🌐 [ActionProcessor] Routing kernel message via HTTP to kernel: {target_kernel_id}")
            # Create a temporary WebSocket connection to the target kernel
            # This is a simplified approach - in production you might want to maintain a pool
            # For now, we'll just acknowledge that we received the request
            # and let the client handle the response through the HTTP API
            if self.broadcast_callback:
                # Broadcast a message indicating that the kernel is available
                await self.broadcast_callback({
                    'action': 'kernel_available',
                    'kernel_id': target_kernel_id,
                    'message': 'Kernel is available via HTTP API'
                })
            debug_log(f"✅ [ActionProcessor] Kernel message routed via HTTP", {
                "target_kernel_id": target_kernel_id
            })
            return True
        except Exception as e:
            debug_log(f"❌ [ActionProcessor] Failed to route kernel message via HTTP", {
                "target_kernel_id": target_kernel_id,
                "error": str(e)
            })
            print(f"❌ [ActionProcessor] Failed to route kernel message via HTTP: {e}")
            return False
    async def _handle_start_kernel(self, action: Dict[str, Any]):
        """Handle start kernel action."""
        if not self.jupyter_manager:
            raise Exception("Jupyter manager not available")
        debug_log(f"🚀 [ActionProcessor] Starting kernel")
        # CRITICAL FIX: Check if we already have a kernel to prevent duplicates
        existing_kernel_id = self.jupyter_manager.get_kernel_id()
        if existing_kernel_id:
            debug_log(f"⚠️ [ActionProcessor] Kernel already exists, returning existing ID", {
                "existing_kernel_id": existing_kernel_id
            })
            print(f"⚠️ [ActionProcessor] Kernel already exists: {existing_kernel_id}")
            if self.broadcast_callback:
                await self.broadcast_callback({
                    'action': 'kernel_started',
                    'kernel_id': existing_kernel_id,
                    'status': 'existing'
                })
            return existing_kernel_id
        # Only create a new kernel if we don't have one
        kernel_id = await self.jupyter_manager.create_kernel()
        if self.broadcast_callback:
            await self.broadcast_callback({
                'action': 'kernel_started',
                'kernel_id': kernel_id,
                'status': 'new'
            })
        return kernel_id
    async def _handle_restart_kernel(self, action: Dict[str, Any]):
        """Handle restart kernel action."""
        if not self.jupyter_manager:
            raise Exception("Jupyter manager not available")
        debug_log(f"🔄 [ActionProcessor] Restarting kernel")
        success = await self.jupyter_manager.restart_kernel()
        if success and self.broadcast_callback:
            await self.broadcast_callback({
                'action': 'kernel_restarted'
            })
        return success
    async def _handle_interrupt_kernel(self, action: Dict[str, Any]):
        """Handle interrupt kernel action."""
        debug_log(f"⏹️ [ActionProcessor] Interrupting kernel")
        # TODO: Implement kernel interruption
        # This would integrate with Jupyter manager
        if self.broadcast_callback:
            await self.broadcast_callback({
                'action': 'kernel_interrupted'
            })
        return True
    async def _handle_input(self, action: Dict[str, Any]):
        """Handle input action."""
        input_data = action.get('input', '')
        debug_log(f"⌨️ [ActionProcessor] Input received", {
            "input_length": len(input_data) if input_data else 0
        })
        # TODO: Implement input handling
        # This would integrate with kernel input system
        return True
    async def _handle_sudo_http_request(self, action: Dict[str, Any]) -> bool:
        """Handle sudo HTTP request action."""
        try:
            url = action.get('url')
            method = action.get('method')
            body = action.get('data', {})
            headers = action.get('headers', {})
            msg_id = action.get('msgId')
            client_id = action.get('client_id')
            # Reduce logging for frequent HTTP requests
            if hasattr(self, '_http_log_counter'):
                self._http_log_counter += 1
                if self._http_log_counter % 10 == 0:  # Log every 10th HTTP request
                    debug_log(f"🌐 [ActionProcessor] Sudo HTTP request", {
                        "url": url,
                        "method": method,
                        "body_type": type(body).__name__,
                        "body_keys": list(body.keys()) if isinstance(body, dict) else None,
                        "body_preview": str(body)[:100] if body else None,
                        "body_is_string": isinstance(body, str),
                        "body_is_dict": isinstance(body, dict),
                        "body_is_none": body is None,
                        "headers": headers,
                        "msg_id": msg_id,
                        "client_id": client_id,
                        "count": self._http_log_counter
                    })
            else:
                # Initialize counter
                self._http_log_counter = 0
                debug_log(f"🌐 [ActionProcessor] Sudo HTTP request", {
                    "url": url,
                    "method": method,
                    "body_type": type(body).__name__,
                    "body_keys": list(body.keys()) if isinstance(body, dict) else None,
                    "body_preview": str(body)[:100] if body else None,
                    "body_is_string": isinstance(body, str),
                    "body_is_dict": isinstance(body, dict),
                    "body_is_none": body is None,
                    "headers": headers,
                    "msg_id": msg_id,
                    "client_id": client_id
                })
            if not url or not method:
                debug_log(f"❌ [ActionProcessor] Missing URL or method", {
                    "url": url,
                    "method": method
                })
                return False
            # Process the HTTP request
            result = await self.http_proxy_service.sudo_http_request(url, method, body, headers)
            # Send response back to the client
            if result and self.peer_manager and client_id:
                # Format response for the client
                response_data = {
                    'action': msg_id,
                    'msgId': msg_id,
                    'data': result.get('data', {}),
                    'status': result.get('status', 500),
                    'headers': result.get('headers', {}),
                    'timestamp': datetime.datetime.now().isoformat()
                }
                # Send response to the specific client
                success = self.peer_manager.send_message(client_id, response_data)
                if success:
                    debug_log(f"✅ [ActionProcessor] Response sent to client", {
                        "client_id": client_id,
                        "action": msg_id,
                        "status": result.get('status')
                    })
                else:
                    debug_log(f"❌ [ActionProcessor] Failed to send response to client", {
                        "client_id": client_id,
                        "action": msg_id
                    })
            return result
        except Exception as e:
            debug_log(f"❌ [ActionProcessor] Error handling sudo HTTP request", {
                "error": str(e),
                "error_type": type(e).__name__
            })
            return False
    async def _handle_canvas_data(self, action: Dict[str, Any]) -> bool:
        """Handle canvas data action."""
        try:
            data = action.get('data', {})
            data_type = data.get('type', 'unknown')
            data_id = data.get('id')
            client_id = action.get('client_id')
            # Reduce logging for canvas data
            if data_type == 'mouse' and hasattr(self, '_mouse_log_counter'):
                self._mouse_log_counter += 1
                if self._mouse_log_counter % 50 == 0:  # Log every 50th mouse event
                    debug_log(f"🎨 [ActionProcessor] Canvas data", {
                        "data_type": data_type,
                        "data_id": data_id,
                        "client_id": client_id,
                        "count": self._mouse_log_counter
                    })
            else:
                # Initialize counter for non-mouse events
                if not hasattr(self, '_mouse_log_counter'):
                    self._mouse_log_counter = 0
                debug_log(f"🎨 [ActionProcessor] Canvas data", {
                    "data_type": data_type,
                    "data_id": data_id,
                    "client_id": client_id
                })
            return True
        except Exception as e:
            debug_log(f"❌ [ActionProcessor] Error handling canvas data", {
                "error": str(e),
                "error_type": type(e).__name__
            })
            return False
    def get_action_statistics(self) -> Dict[str, Any]:
        """Get action processing statistics."""
        uptime = datetime.datetime.now() - self.action_stats['start_time']
        return {
            'total_actions': self.action_stats['total_actions'],
            'successful_actions': self.action_stats['successful_actions'],
            'failed_actions': self.action_stats['failed_actions'],
            'success_rate': (self.action_stats['successful_actions'] / max(self.action_stats['total_actions'], 1)) * 100,
            'actions_by_type': dict(self.action_stats['actions_by_type']),
            'uptime_seconds': uptime.total_seconds(),
            'start_time': self.action_stats['start_time'].isoformat()
        }
    def get_status(self) -> Dict[str, Any]:
        """Get action processor status."""
        return {
            'total_handlers': len(self.action_handlers),
            'jupyter_manager_available': self.jupyter_manager is not None,
            'broadcast_callback_available': self.broadcast_callback is not None,
            'http_proxy_service_available': self.http_proxy_service is not None,
            'canvas_service_available': self.canvas_service is not None,
            'widget_service_available': self.widget_service is not None,
            'websocket_bridge_available': self.websocket_bridge is not None,
            'peer_manager_available': self.peer_manager is not None,
            'available_actions': list(self.action_handlers.keys())
        }
    async def _handle_websocket_connect(self, action: Dict[str, Any]):
        """Handle WebSocket connection request from frontend."""
        debug_log(f"🔌 [ActionProcessor] WebSocket connect request received", {
            "action": action,
            "has_websocket_bridge": hasattr(self, 'websocket_bridge'),
            "websocket_bridge_available": bool(self.websocket_bridge) if hasattr(self, 'websocket_bridge') else False
        })
        if not hasattr(self, 'websocket_bridge') or not self.websocket_bridge:
            debug_log(f"❌ [ActionProcessor] WebSocket bridge service not available")
            raise Exception("WebSocket bridge service not available")
        instance_id = action.get('instanceId')
        kernel_id = action.get('kernelId')
        url = action.get('url')
        client_id = action.get('client_id')
        debug_log(f"🔌 [ActionProcessor] WebSocket connect request", {
            "instance_id": instance_id,
            "kernel_id": kernel_id,
            "url": url,
            "client_id": client_id
        })
        if not instance_id or not url:
            debug_log(f"❌ [ActionProcessor] Missing required fields for WebSocket connect", {
                "instance_id": instance_id,
                "url": url
            })
            return False
        try:
            debug_log(f"🔌 [ActionProcessor] Calling websocket_bridge.connect_kernel", {
                "instance_id": instance_id,
                "kernel_id": kernel_id or 'default',
                "url": url
            })
            # Connect to kernel via WebSocket bridge
            success = await self.websocket_bridge.connect_kernel(instance_id, kernel_id or 'default', url)
            debug_log(f"🔌 [ActionProcessor] connect_kernel result", {
                "success": success,
                "instance_id": instance_id,
                "kernel_id": kernel_id or 'default'
            })
            if success:
                debug_log(f"✅ [ActionProcessor] WebSocket connection established", {
                    "instance_id": instance_id,
                    "kernel_id": kernel_id,
                    "url": url
                })
                # Send confirmation to frontend
                if self.broadcast_callback:
                    confirmation_message = {
                        'action': 'websocket_connected',
                        'instanceId': instance_id,
                        'kernelId': kernel_id or 'default',
                        'timestamp': datetime.datetime.now().isoformat()
                    }
                    debug_log(f"📤 [ActionProcessor] Sending websocket_connected confirmation", {
                        "message": confirmation_message,
                        "client_id": client_id
                    })
                    # Send confirmation WITHOUT excluding the client (they need to receive it)
                    await self.broadcast_callback(confirmation_message)
                    debug_log(f"✅ [ActionProcessor] websocket_connected confirmation sent")
                else:
                    debug_log(f"⚠️ [ActionProcessor] No broadcast callback available")
                return True
            else:
                debug_log(f"❌ [ActionProcessor] Failed to establish WebSocket connection", {
                    "instance_id": instance_id,
                    "kernel_id": kernel_id,
                    "url": url
                })
                return False
        except Exception as e:
            debug_log(f"❌ [ActionProcessor] Error establishing WebSocket connection", {
                "instance_id": instance_id,
                "kernel_id": kernel_id,
                "url": url,
                "error": str(e),
                "error_type": type(e).__name__
            })
            return False
    async def _handle_websocket_message(self, action: Dict[str, Any]):
        """Handle WebSocket message from frontend."""
        if not hasattr(self, 'websocket_bridge') or not self.websocket_bridge:
            raise Exception("WebSocket bridge service not available")
        instance_id = action.get('instanceId')
        kernel_id = action.get('kernelId')
        data = action.get('data')
        client_id = action.get('client_id')
        debug_log(f"📤 [ActionProcessor] WebSocket message from frontend", {
            "instance_id": instance_id,
            "kernel_id": kernel_id,
            "data_type": type(data).__name__,
            "client_id": client_id
        })
        if not instance_id or not data:
            debug_log(f"❌ [ActionProcessor] Missing required fields for WebSocket message", {
                "instance_id": instance_id,
                "has_data": data is not None
            })
            return False
        try:
            # Send message via WebSocket bridge
            success = await self.websocket_bridge.send_message(instance_id, kernel_id or 'default', data)
            if success:
                debug_log(f"✅ [ActionProcessor] WebSocket message sent successfully", {
                    "instance_id": instance_id,
                    "kernel_id": kernel_id
                })
                return True
            else:
                debug_log(f"❌ [ActionProcessor] Failed to send WebSocket message", {
                    "instance_id": instance_id,
                    "kernel_id": kernel_id
                })
                return False
        except Exception as e:
            debug_log(f"❌ [ActionProcessor] Error sending WebSocket message", {
                "instance_id": instance_id,
                "kernel_id": kernel_id,
                "error": str(e),
                "error_type": type(e).__name__
            })
            return False
    async def _handle_websocket_close(self, action: Dict[str, Any]):
        """Handle WebSocket close request from frontend."""
        if not hasattr(self, 'websocket_bridge') or not self.websocket_bridge:
            raise Exception("WebSocket bridge service not available")
        instance_id = action.get('instanceId')
        kernel_id = action.get('kernelId')
        client_id = action.get('client_id')
        debug_log(f"🔌 [ActionProcessor] WebSocket close request", {
            "instance_id": instance_id,
            "kernel_id": kernel_id,
            "client_id": client_id
        })
        if not instance_id:
            debug_log(f"❌ [ActionProcessor] Missing instance_id for WebSocket close", {
                "instance_id": instance_id
            })
            return False
        try:
            # Disconnect kernel via WebSocket bridge
            success = await self.websocket_bridge.disconnect_kernel(instance_id, kernel_id or 'default')
            if success:
                debug_log(f"✅ [ActionProcessor] WebSocket connection closed", {
                    "instance_id": instance_id,
                    "kernel_id": kernel_id
                })
                # Send confirmation to frontend
                if self.broadcast_callback:
                    await self.broadcast_callback({
                        'action': 'websocket_closed',
                        'instanceId': instance_id,
                        'kernelId': kernel_id or 'default',
                        'timestamp': datetime.datetime.now().isoformat()
                    })
                return True
            else:
                debug_log(f"❌ [ActionProcessor] Failed to close WebSocket connection", {
                    "instance_id": instance_id,
                    "kernel_id": kernel_id
                })
                return False
        except Exception as e:
            debug_log(f"❌ [ActionProcessor] Error closing WebSocket connection", {
                "instance_id": instance_id,
                "kernel_id": kernel_id,
                "error": str(e),
                "error_type": type(e).__name__
            })
            return False
    def _build_websocket_url(self, url: str) -> str:
        """Build WebSocket URL from HTTP URL."""
        if url.startswith('http://'):
            return url.replace('http://', 'ws://')
        elif url.startswith('https://'):
            return url.replace('https://', 'wss://')
        else:
            # Assume localhost if no protocol
            return f"ws://localhost:8888{url}"
    async def cleanup(self):
        """Clean up action processor resources."""
        debug_log(f"🧹 [ActionProcessor] Cleaning up action processor")
        # Clear handlers
        self.action_handlers.clear()
        # Clear references
        self.jupyter_manager = None
        self.broadcast_callback = None
        self.http_proxy_service = None
        self.canvas_service = None
        self.widget_service = None
        self.websocket_bridge = None
        self.peer_manager = None
        debug_log(f"🧹 [ActionProcessor] Action processor cleanup completed")
</file>

<file path="services/websocket_bridge.py">
"""
WebSocket Bridge Service for TensorDock.
Handles all WebSocket functionality via WebRTC, including:
- Real WebSocket connections to Jupyter server
- Bidirectional message routing between frontend and Jupyter
- Complete JupyterLab protocol implementation
- Connection lifecycle management
"""
import asyncio
import json
import datetime
import uuid
from typing import Dict, Any, Optional, Callable, Set, List
from websockets.client import connect
from websockets.exceptions import WebSocketException
# Use absolute imports to avoid relative import issues
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from core.logging import LoggerMixin, debug_log
from core.config import ServerConfig
class WebSocketBridge(LoggerMixin):
    """Complete WebSocket bridge that handles all WebSocket functionality via WebRTC."""
    def __init__(self, config: ServerConfig):
        super().__init__()
        self.config = config
        # Connection management
        self.jupyter_connections: Dict[str, Dict[str, Any]] = {}  # kernel_id -> connection info
        self.frontend_connections: Dict[str, Dict[str, Any]] = {}  # instance_id -> connection info
        self.connection_states: Dict[str, str] = {}  # instance_id -> state
        # Message tracking
        self.pending_messages: Dict[str, Dict[str, Any]] = {}  # msg_id -> message info
        self.processed_messages: Set[str] = set()  # Track processed message IDs to prevent duplicates
        self.comm_message_tracker: Dict[str, Set[str]] = {}  # comm_id -> set of processed msg_ids
        self.most_recent_comm_messages: Dict[str, Dict[str, Any]] = {}  # kernel_id -> most recent comm message
        # ✅ CRITICAL FIX: Add missing message_queues attribute
        self.message_queues: Dict[str, asyncio.Queue] = {}  # instance_id -> message queue
        # ✅ CRITICAL FIX: Add missing message_processor_tasks attribute
        self.message_processor_tasks: Dict[str, asyncio.Task] = {}  # kernel_id -> message processor task
        # Broadcast callback
        self.broadcast_callback: Optional[Callable] = None
        # Start periodic cleanup task
        asyncio.create_task(self._periodic_cleanup())
        # Start connection health monitoring task
        asyncio.create_task(self._periodic_connection_health_check())
        debug_log(f"🔌 [WebSocketBridge] WebSocket bridge service initialized")
    async def _periodic_cleanup(self):
        """Periodic cleanup task to prevent memory leaks."""
        while True:
            try:
                await asyncio.sleep(300)  # Run every 5 minutes
                await self._cleanup_old_messages()
            except Exception as e:
                debug_log(f"❌ [WebSocketBridge] Error in periodic cleanup", {
                    "error": str(e),
                    "error_type": type(e).__name__
                })
    async def _periodic_connection_health_check(self):
        """Periodically check the health of all WebSocket connections."""
        while True:
            try:
                await asyncio.sleep(300)  # Check every 5 minutes
                current_time = datetime.datetime.now()
                stale_connections = []
                for kernel_id, connection_info in self.jupyter_connections.items():
                    websocket = connection_info.get('websocket')
                    connected_at = connection_info.get('connected_at')
                    if websocket is None:
                        continue
                    # Check if connection is too old (more than 1 hour)
                    if connected_at and (current_time - connected_at).total_seconds() > 3600:
                        debug_log(f"🕐 [WebSocketBridge] Connection is stale, marking for cleanup", {
                            "kernel_id": kernel_id,
                            "connected_at": connected_at.isoformat(),
                            "age_seconds": (current_time - connected_at).total_seconds()
                        })
                        stale_connections.append(kernel_id)
                        continue
                    # Check if websocket is closed
                    if websocket.closed:
                        debug_log(f"🔌 [WebSocketBridge] WebSocket connection is closed, marking for cleanup", {
                            "kernel_id": kernel_id
                        })
                        stale_connections.append(kernel_id)
                        continue
                    # Try to ping the connection
                    try:
                        pong_waiter = await websocket.ping()
                        await asyncio.wait_for(pong_waiter, timeout=5.0)
                        debug_log(f"💓 [WebSocketBridge] Connection health check passed", {
                            "kernel_id": kernel_id
                        })
                    except (asyncio.TimeoutError, Exception) as e:
                        debug_log(f"❌ [WebSocketBridge] Connection health check failed", {
                            "kernel_id": kernel_id,
                            "error": str(e)
                        })
                        stale_connections.append(kernel_id)
                # Clean up stale connections
                for kernel_id in stale_connections:
                    await self._cleanup_stale_connection(kernel_id)
            except Exception as e:
                debug_log(f"❌ [WebSocketBridge] Error in periodic connection health check", {
                    "error": str(e),
                    "error_type": type(e).__name__
                })
    async def _cleanup_stale_connection(self, kernel_id: str):
        """Clean up a stale WebSocket connection."""
        try:
            if kernel_id in self.jupyter_connections:
                connection_info = self.jupyter_connections[kernel_id]
                websocket = connection_info.get('websocket')
                if websocket and not websocket.closed:
                    try:
                        await websocket.close(code=1000, reason="Connection cleanup")
                    except Exception as e:
                        debug_log(f"⚠️ [WebSocketBridge] Error closing websocket during cleanup", {
                            "kernel_id": kernel_id,
                            "error": str(e)
                        })
                # Remove connection
                del self.jupyter_connections[kernel_id]
                # Notify frontend instances
                instance_ids = connection_info.get('instance_ids', [])
                for instance_id in instance_ids:
                    if instance_id in self.frontend_connections:
                        await self._notify_connection_status(kernel_id, 'disconnected')
                debug_log(f"🧹 [WebSocketBridge] Stale connection cleaned up", {
                    "kernel_id": kernel_id
                })
        except Exception as e:
            debug_log(f"❌ [WebSocketBridge] Error cleaning up stale connection", {
                "kernel_id": kernel_id,
                "error": str(e)
            })
    def set_broadcast_callback(self, callback: Callable):
        """Set the broadcast callback for sending messages to frontend."""
        self.broadcast_callback = callback
        debug_log(f"🔌 [WebSocketBridge] Broadcast callback set")
    async def connect_kernel(self, instance_id: str, kernel_id: str, url: str = None) -> bool:
        """Connect to a Jupyter kernel via WebSocket for all channels."""
        try:
            debug_log(f"🔌 [WebSocketBridge] Starting kernel connection", {
                "instance_id": instance_id,
                "kernel_id": kernel_id,
                "url": url,
                "existing_connections": len(self.jupyter_connections),
                "existing_frontend_connections": len(self.frontend_connections)
            })
            # Use default URL if none provided
            if url is None:
                url = "http://localhost:8888"
            debug_log(f"🔌 [WebSocketBridge] Connecting to kernel", {
                "kernel_id": kernel_id,
                "instance_id": instance_id,
                "url": url
            })
            # CRITICAL: Check if kernel exists before trying to connect
            # If kernel doesn't exist, we need to create it first
            kernel_exists = await self._check_kernel_exists(kernel_id, "http://localhost:8888")
            if not kernel_exists:
                debug_log(f"⚠️ [WebSocketBridge] Kernel {kernel_id} doesn't exist, attempting to create it", {
                    "kernel_id": kernel_id,
                    "instance_id": instance_id
                })
                # Try to create the kernel
                kernel_created = await self._create_kernel(kernel_id, "http://localhost:8888")
                if not kernel_created:
                    debug_log(f"❌ [WebSocketBridge] Failed to create kernel {kernel_id}", {
                        "kernel_id": kernel_id,
                        "instance_id": instance_id
                    })
                    return False
                debug_log(f"✅ [WebSocketBridge] Successfully created kernel {kernel_id}", {
                    "kernel_id": kernel_id,
                    "instance_id": instance_id
                })
            # Connect to Jupyter kernel using single WebSocket endpoint
            # This endpoint handles all channels (shell, iopub, stdin, control)
            ws_url = self._build_websocket_url(url, kernel_id)
            # Create WebSocket connection to Jupyter server
            headers = self.config.get_jupyter_headers()
            debug_log(f"🔌 [WebSocketBridge] Attempting WebSocket connection", {
                "ws_url": ws_url,
                "headers": headers,
                "instance_id": instance_id,
                "kernel_id": kernel_id
            })
            try:
                websocket = await connect(
                    ws_url,
                    extra_headers=headers or {},
                    ping_interval=30,  # Send ping every 30 seconds
                    ping_timeout=10,   # Wait 10 seconds for pong response
                    close_timeout=10,  # Wait 10 seconds for close
                    max_size=2**20,    # 1MB max message size
                    max_queue=2**10    # 1024 messages max queue
                )
                debug_log(f"✅ [WebSocketBridge] WebSocket connection established", {
                    "ws_url": ws_url,
                    "instance_id": instance_id,
                    "kernel_id": kernel_id
                })
                # Store single connection that handles all channels
                self.jupyter_connections[kernel_id] = {
                    'websocket': websocket,
                    'url': ws_url,
                    'connected_at': datetime.datetime.now(),
                    'instance_ids': [instance_id],
                    'connection_type': 'websocket_single'
                }
                debug_log(f"📝 [WebSocketBridge] Jupyter connection stored", {
                    "kernel_id": kernel_id,
                    "jupyter_connections": self.jupyter_connections,
                    "total_jupyter_connections": len(self.jupyter_connections)
                })
                # Store frontend connection info
                self.frontend_connections[instance_id] = {
                    'kernel_id': kernel_id,
                    'session_id': None,  # Will be set when frontend sends session info
                    'connected_at': datetime.datetime.now(),
                    'status': 'connected',
                    'channels': ['shell', 'iopub', 'stdin', 'control']  # All channels available
                }
                debug_log(f"📝 [WebSocketBridge] Frontend connection stored", {
                    "instance_id": instance_id,
                    "kernel_id": kernel_id,
                    "frontend_connections": self.frontend_connections,
                    "total_connections": len(self.frontend_connections)
                })
                # Update connection state
                self.connection_states[instance_id] = 'connected'
                # Create message queue for this kernel
                if kernel_id not in self.message_queues:
                    self.message_queues[kernel_id] = asyncio.Queue()
                # Start message processor for this kernel
                if kernel_id not in self.message_processor_tasks:
                    self.message_processor_tasks[kernel_id] = asyncio.create_task(
                        self._process_kernel_messages(kernel_id)
                    )
                # Start listening for messages from Jupyter (single connection handles all channels)
                asyncio.create_task(self._listen_jupyter_messages(kernel_id, websocket))
                debug_log(f"✅ [WebSocketBridge] Kernel connected successfully", {
                    "kernel_id": kernel_id,
                    "instance_id": instance_id,
                    "ws_url": ws_url,
                    "channels": ['shell', 'iopub', 'stdin', 'control']
                })
                return True
            except Exception as ws_error:
                debug_log(f"❌ [WebSocketBridge] WebSocket connection failed", {
                    "kernel_id": kernel_id,
                    "instance_id": instance_id,
                    "error": str(ws_error),
                    "error_type": type(ws_error).__name__,
                    "ws_url": ws_url
                })
                return False
        except Exception as e:
            debug_log(f"❌ [WebSocketBridge] Failed to connect to kernel", {
                "kernel_id": kernel_id,
                "instance_id": instance_id,
                "error": str(e),
                "error_type": type(e).__name__
            })
            # Update connection state
            self.connection_states[instance_id] = 'failed'
            return False
    async def _check_kernel_exists(self, kernel_id: str, base_url: str) -> bool:
        """Check if a kernel exists on the Jupyter server."""
        try:
            import aiohttp
            # CRITICAL: Extract the actual Jupyter base URL from the WebRTC URL
            # The base_url parameter contains the WebRTC URL, we need to extract the Jupyter server URL
            jupyter_base_url = "http://localhost:8888"  # Default Jupyter server URL
            # Build the kernel info URL
            kernel_url = f"{jupyter_base_url}/api/kernels/{kernel_id}"
            debug_log(f"🔍 [WebSocketBridge] Checking if kernel exists", {
                "kernel_id": kernel_id,
                "jupyter_url": kernel_url,
                "original_base_url": base_url
            })
            # Make HTTP request to check kernel info
            async with aiohttp.ClientSession() as session:
                headers = self.config.get_jupyter_headers()
                async with session.get(kernel_url, headers=headers) as response:
                    if response.status == 200:
                        debug_log(f"✅ [WebSocketBridge] Kernel {kernel_id} exists", {
                            "kernel_id": kernel_id,
                            "status": response.status
                        })
                        return True
                    elif response.status == 404:
                        debug_log(f"❌ [WebSocketBridge] Kernel {kernel_id} does not exist", {
                            "kernel_id": kernel_id,
                            "status": response.status
                        })
                        return False
                    else:
                        debug_log(f"⚠️ [WebSocketBridge] Unexpected status checking kernel", {
                            "kernel_id": kernel_id,
                            "status": response.status,
                            "response_text": await response.text()
                        })
                        return False
        except Exception as e:
            debug_log(f"❌ [WebSocketBridge] Error checking kernel existence", {
                "kernel_id": kernel_id,
                "error": str(e),
                "error_type": type(e).__name__
            })
            return False
    async def _create_kernel(self, kernel_id: str, base_url: str) -> bool:
        """Create a new kernel on the Jupyter server."""
        try:
            import aiohttp
            # CRITICAL: Extract the actual Jupyter base URL from the WebRTC URL
            # The base_url parameter contains the WebRTC URL, we need to extract the Jupyter server URL
            jupyter_base_url = "http://localhost:8888"  # Default Jupyter server URL
            # Build the kernels creation URL
            kernels_url = f"{jupyter_base_url}/api/kernels"
            debug_log(f"📝 [WebSocketBridge] Creating kernel", {
                "kernel_id": kernel_id,
                "jupyter_url": kernels_url,
                "original_base_url": base_url
            })
            # Create kernel with Python3 (default)
            kernel_data = {
                "name": "python3"
            }
            # Make HTTP request to create kernel
            async with aiohttp.ClientSession() as session:
                headers = self.config.get_jupyter_headers()
                headers['Content-Type'] = 'application/json'
                async with session.post(kernels_url, headers=headers, json=kernel_data) as response:
                    if response.status == 201:
                        response_data = await response.json()
                        created_kernel_id = response_data.get('id')
                        debug_log(f"✅ [WebSocketBridge] Successfully created kernel", {
                            "requested_id": kernel_id,
                            "created_id": created_kernel_id,
                            "status": response.status,
                            "response": response_data
                        })
                        # Update kernel_id to use the actual created ID
                        if created_kernel_id and created_kernel_id != kernel_id:
                            debug_log(f"🔄 [WebSocketBridge] Kernel ID changed from {kernel_id} to {created_kernel_id}", {
                                "old_id": kernel_id,
                                "new_id": created_kernel_id
                            })
                            kernel_id = created_kernel_id
                        return True
                    else:
                        response_text = await response.text()
                        debug_log(f"❌ [WebSocketBridge] Failed to create kernel", {
                            "kernel_id": kernel_id,
                            "status": response.status,
                            "response": response_text
                        })
                        return False
        except Exception as e:
            debug_log(f"❌ [WebSocketBridge] Error creating kernel", {
                "kernel_id": kernel_id,
                "error": str(e),
                "error_type": type(e).__name__
            })
            return False
    def _get_target_channel(self, msg_type: str) -> str:
        """Determine which Jupyter channel a message should be sent to."""
        # Map message types to channels based on JupyterLab protocol
        channel_mapping = {
            # Shell channel (execution requests, kernel info, etc.)
            'execute_request': 'shell',
            'kernel_info_request': 'shell',
            'complete_request': 'shell',
            'inspect_request': 'shell',
            'history_request': 'shell',
            'is_complete_request': 'shell',
            'comm_info_request': 'shell',
            # Control channel (interrupt, restart, shutdown)
            'interrupt_request': 'control',
            'restart_request': 'control',
            'shutdown_request': 'control',
            # Stdin channel (user input)
            'input_request': 'stdin',
            # Iopub channel (output, status updates)
            'execute_input': 'iopub',
            'execute_result': 'iopub',
            'stream': 'iopub',
            'error': 'iopub',
            'status': 'iopub',
            'clear_output': 'iopub',
            'display_data': 'iopub',
            'update_display_data': 'iopub',
            'comm_open': 'iopub',  # Kernel → Frontend: IOPub channel
            'comm_msg': 'iopub',   # Kernel → Frontend: IOPub channel (for responses)
            'comm_close': 'iopub'  # Kernel → Frontend: IOPub channel
        }
        return channel_mapping.get(msg_type, 'shell')  # Default to shell channel
    async def disconnect_kernel(self, instance_id: str, kernel_id: str) -> bool:
        """Disconnect a kernel connection."""
        try:
            debug_log(f"🔌 [WebSocketBridge] Disconnecting kernel", {
                "instance_id": instance_id,
                "kernel_id": kernel_id
            })
            # Remove frontend connection
            if instance_id in self.frontend_connections:
                del self.frontend_connections[instance_id]
            # Remove connection state
            if instance_id in self.connection_states:
                del self.connection_states[instance_id]
            # Check if this was the last instance for this kernel
            if kernel_id in self.jupyter_connections:
                kernel_info = self.jupyter_connections[kernel_id]
                if instance_id in kernel_info['instance_ids']:
                    kernel_info['instance_ids'].remove(instance_id)
                # If no more instances, close the WebSocket connection
                if not kernel_info['instance_ids']:
                    await self._close_jupyter_connection(kernel_id)
                    # ✅ CRITICAL FIX: Clean up message tracking for this kernel
                    await self._cleanup_kernel_messages(kernel_id)
            debug_log(f"✅ [WebSocketBridge] Kernel disconnected", {
                "instance_id": instance_id,
                "kernel_id": kernel_id
            })
            return True
        except Exception as e:
            debug_log(f"❌ [WebSocketBridge] Failed to disconnect kernel", {
                "instance_id": instance_id,
                "kernel_id": kernel_id,
                "error": str(e),
                "error_type": type(e).__name__
            })
            return False
    async def send_message(self, instance_id: str, kernel_id: str, data: Any, channel: str = None) -> bool:
        """Send a message from frontend to Jupyter server."""
        try:
            # Auto-connect if no connection exists
            if kernel_id not in self.jupyter_connections:
                debug_log(f"🔄 [WebSocketBridge] No connection for kernel, attempting auto-connect", {
                    "kernel_id": kernel_id,
                    "instance_id": instance_id
                })
                # Try to auto-connect to the kernel
                success = await self.connect_kernel(instance_id, kernel_id)
                if not success:
                    debug_log(f"❌ [WebSocketBridge] Auto-connect failed for kernel", {
                        "kernel_id": kernel_id,
                        "instance_id": instance_id
                    })
                    return False
                debug_log(f"✅ [WebSocketBridge] Auto-connect successful for kernel", {
                    "kernel_id": kernel_id,
                    "instance_id": instance_id
                })
            connection_info = self.jupyter_connections[kernel_id]
            websocket = connection_info.get('websocket')
            connection_type = connection_info.get('connection_type', 'websocket_multi_channel')
            # Log what we're sending
            msg_type = data.get('header', {}).get('msg_type', 'unknown') if isinstance(data, dict) else 'unknown'
            msg_id = data.get('header', {}).get('msg_id', 'unknown') if isinstance(data, dict) else 'unknown'
            if connection_type == 'websocket_single' and websocket:
                # Use provided channel or determine based on message type
                target_channel = channel if channel else self._get_target_channel(msg_type)
                # Store message as pending for response matching
                if msg_id != 'unknown':
                    self.pending_messages[msg_id] = {
                        'instance_id': instance_id,
                        'kernel_id': kernel_id,
                        'msg_type': msg_type,
                        'timestamp': datetime.datetime.now(),
                        'target_channel': target_channel
                    }
                    debug_log(f"📝 [WebSocketBridge] Message stored as pending", {
                        "msg_id": msg_id,
                        "instance_id": instance_id,
                        "kernel_id": kernel_id,
                        "msg_type": msg_type
                    })
                # Send via WebSocket to specific channel
                debug_log(f"📤 [WebSocketBridge] Sending message via WebSocket to {target_channel} channel", {
                    "msg_id": msg_id,
                    "instance_id": instance_id,
                    "kernel_id": kernel_id,
                    "msg_type": msg_type,
                    "target_channel": target_channel
                })
                try:
                    # Send the complete Jupyter message structure to the server
                    # The Jupyter server expects the standard message format
                    await websocket.send(json.dumps(data))
                except Exception as send_error:
                    debug_log(f"❌ [WebSocketBridge] Failed to send message via WebSocket", {
                        "msg_id": msg_id,
                        "instance_id": instance_id,
                        "kernel_id": kernel_id,
                        "msg_type": msg_type,
                        "error": str(send_error),
                        "error_type": type(send_error).__name__
                    })
                    # Mark connection as failed
                    if kernel_id in self.jupyter_connections:
                        self.jupyter_connections[kernel_id]['websocket'] = None
                    # Notify frontend about connection failure
                    await self._notify_connection_status(kernel_id, 'failed')
                    return False
            else:
                debug_log(f"❌ [WebSocketBridge] No valid connection type or WebSocket", {
                    "connection_type": connection_type,
                    "has_websocket": bool(websocket)
                })
                return False
            debug_log(f"📤 [WebSocketBridge] Message sent to Jupyter", {
                "msg_id": msg_id,
                "instance_id": instance_id,
                "kernel_id": kernel_id,
                "msg_type": msg_type,
                "connection_type": connection_type,
                "target_channel": target_channel if 'target_channel' in locals() else 'unknown'
            })
            return True
        except Exception as e:
            debug_log(f"❌ [WebSocketBridge] Error sending message", {
                "kernel_id": kernel_id,
                "instance_id": instance_id,
                "error": str(e),
                "error_type": type(e).__name__
            })
            return False
    async def _listen_jupyter_messages(self, kernel_id: str, websocket):
        """Listen for messages from Jupyter server for a specific channel."""
        try:
            debug_log(f"👂 [WebSocketBridge] Listening for messages from kernel channel", {
                "kernel_id": kernel_id
            })
            # Start connection health monitoring
            health_task = asyncio.create_task(self._monitor_connection_health(kernel_id, websocket))
            try:
                async for message in websocket:
                    try:
                        # Parse message
                        if isinstance(message, str):
                            data = json.loads(message)
                        else:
                            data = message
                        # The Jupyter server sends standard Jupyter messages
                        # We need to determine the channel based on message type
                        msg_type = data.get('header', {}).get('msg_type', 'unknown')
                        channel = self._get_target_channel(msg_type)
                        # Forward the complete Jupyter message
                        await self._handle_jupyter_message(kernel_id, data, channel)
                    except json.JSONDecodeError as e:
                        debug_log(f"❌ [WebSocketBridge] Failed to parse Jupyter message", {
                            "kernel_id": kernel_id,
                            "error": str(e)
                        })
                    except Exception as e:
                        debug_log(f"❌ [WebSocketBridge] Error handling Jupyter message", {
                            "kernel_id": kernel_id,
                            "error": str(e),
                            "error_type": type(e).__name__
                        })
            finally:
                # Cancel health monitoring task
                health_task.cancel()
                try:
                    await health_task
                except asyncio.CancelledError:
                    pass
        except WebSocketException as e:
            debug_log(f"🔌 [WebSocketBridge] WebSocket connection closed", {
                "kernel_id": kernel_id,
                "error": str(e)
            })
            # Mark connection as disconnected
            if kernel_id in self.jupyter_connections:
                self.jupyter_connections[kernel_id]['websocket'] = None
            # Notify frontend
            await self._notify_connection_status(kernel_id, 'disconnected')
        except Exception as e:
            debug_log(f"❌ [WebSocketBridge] Error in Jupyter message listener", {
                "kernel_id": kernel_id,
                "error": str(e),
                "error_type": type(e).__name__
            })
    async def _monitor_connection_health(self, kernel_id: str, websocket):
        """Monitor WebSocket connection health and handle reconnection."""
        try:
            while True:
                await asyncio.sleep(60)  # Check every minute
                # Check if websocket is still open
                if websocket.closed:
                    debug_log(f"🔌 [WebSocketBridge] WebSocket connection closed, attempting reconnection", {
                        "kernel_id": kernel_id
                    })
                    break
                # Send a ping to check connection health
                try:
                    pong_waiter = await websocket.ping()
                    await asyncio.wait_for(pong_waiter, timeout=5.0)
                    debug_log(f"💓 [WebSocketBridge] Connection health check passed", {
                        "kernel_id": kernel_id
                    })
                except asyncio.TimeoutError:
                    debug_log(f"⚠️ [WebSocketBridge] Connection health check timeout", {
                        "kernel_id": kernel_id
                    })
                    break
                except Exception as e:
                    debug_log(f"❌ [WebSocketBridge] Connection health check failed", {
                        "kernel_id": kernel_id,
                        "error": str(e)
                    })
                    break
        except asyncio.CancelledError:
            debug_log(f"🔄 [WebSocketBridge] Connection health monitoring cancelled", {
                "kernel_id": kernel_id
            })
            raise
        except Exception as e:
            debug_log(f"❌ [WebSocketBridge] Error in connection health monitoring", {
                "kernel_id": kernel_id,
                "error": str(e)
            })
    async def _notify_connection_status(self, kernel_id: str, status: str):
        """Notify frontend about connection status changes."""
        try:
            if kernel_id in self.jupyter_connections:
                instance_ids = self.jupyter_connections[kernel_id].get('instance_ids', [])
                for instance_id in instance_ids:
                    if instance_id in self.frontend_connections:
                        # Update frontend connection status
                        self.frontend_connections[instance_id]['status'] = status
                        # Notify frontend via broadcast callback
                        if self.broadcast_callback:
                            await self.broadcast_callback({
                                'action': 'connection_status',
                                'instance_id': instance_id,
                                'kernel_id': kernel_id,
                                'status': status,
                                'timestamp': datetime.datetime.now().isoformat()
                            })
                        debug_log(f"📡 [WebSocketBridge] Connection status notification sent", {
                            "instance_id": instance_id,
                            "kernel_id": kernel_id,
                            "status": status
                        })
        except Exception as e:
            debug_log(f"❌ [WebSocketBridge] Error notifying connection status", {
                "kernel_id": kernel_id,
                "status": status,
                "error": str(e)
            })
    async def _handle_jupyter_message(self, kernel_id: str, message: Dict[str, Any], channel: str = 'shell'):
        """Handle incoming message from Jupyter server."""
        try:
            # Extract message details
            msg_type = message.get('header', {}).get('msg_type', 'unknown')
            msg_id = message.get('header', {}).get('msg_id', 'unknown')
            parent_header = message.get('parent_header', {})
            parent_msg_id = parent_header.get('msg_id') if parent_header else None
            # ✅ CRITICAL FIX: Check for duplicate message processing
            if msg_id in self.processed_messages:
                debug_log(f"🔄 [WebSocketBridge] Skipping duplicate message", {
                    "kernel_id": kernel_id,
                    "channel": channel,
                    "msg_type": msg_type,
                    "msg_id": msg_id
                })
                return
            # Add to processed messages set
            self.processed_messages.add(msg_id)
            # For comm messages, also track by comm_id to prevent loops
            if msg_type in ['comm_open', 'comm_msg', 'comm_close']:
                comm_id = message.get('content', {}).get('comm_id')
                if comm_id:
                    if comm_id not in self.comm_message_tracker:
                        self.comm_message_tracker[comm_id] = set()
                    self.comm_message_tracker[comm_id].add(msg_id)
                    debug_log(f"🔗 [WebSocketBridge] Tracking comm message", {
                        "kernel_id": kernel_id,
                        "comm_id": comm_id,
                        "msg_type": msg_type,
                        "msg_id": msg_id,
                        "total_tracked": len(self.comm_message_tracker[comm_id])
                    })
            debug_log(f"📥 [WebSocketBridge] Jupyter message received", {
                "kernel_id": kernel_id,
                "channel": channel,
                "msg_type": msg_type,
                "msg_id": msg_id,
                "parent_msg_id": parent_msg_id
            })
            # Check if this is a response to a pending message
            # Jupyter responses often have a different msg_id but reference the parent_msg_id
            response_to_msg_id = None
            if msg_id in self.pending_messages:
                response_to_msg_id = msg_id
            elif parent_msg_id and parent_msg_id in self.pending_messages:
                response_to_msg_id = parent_msg_id
            # Handle pending message response (but don't return early!)
            if response_to_msg_id:
                await self._handle_response(response_to_msg_id, message)
                # ✅ CRITICAL FIX: Don't return here! Continue to forward the message
            # Handle different message types according to Jupyter protocol
            if msg_type == 'status':
                await self._handle_status_update(kernel_id, message)
            elif msg_type == 'kernel_info_reply':
                await self._handle_kernel_info(kernel_id, message)
            elif msg_type == 'comm_msg':
                # Handle comm messages and send echo responses
                await self._handle_comm_message(kernel_id, message, channel)
            elif msg_type == 'comm_open':
                # Handle comm open messages
                await self._handle_comm_open(kernel_id, message, channel)
            elif msg_type == 'comm_close':
                # Handle comm close messages
                await self._handle_comm_close(kernel_id, message, channel)
            else:
                # Forward all other messages to frontend with proper channel information
                await self._forward_to_frontend(kernel_id, message, channel)
        except Exception as e:
            debug_log(f"❌ [WebSocketBridge] Error handling Jupyter message", {
                "kernel_id": kernel_id,
                "channel": channel,
                "error": str(e),
                "error_type": type(e).__name__
            })
    async def _handle_response(self, msg_id: str, response: Dict[str, Any]):
        """Handle response to a pending message."""
        try:
            pending_msg = self.pending_messages[msg_id]
            kernel_id = pending_msg['kernel_id']
            # Create a reverse mapping from kernel_id to instance_id
            kernel_to_instance = {}
            for frontend_instance_id, frontend_info in self.frontend_connections.items():
                if frontend_info.get('kernel_id'):
                    kernel_to_instance[frontend_info['kernel_id']] = frontend_instance_id
            # Find the correct instance ID for this kernel
            instance_id = kernel_to_instance.get(kernel_id)
            if not instance_id:
                debug_log(f"⚠️ [WebSocketBridge] No frontend instance found for response", {
                    "msg_id": msg_id,
                    "kernel_id": kernel_id,
                    "available_instances": list(self.frontend_connections.keys()),
                    "kernel_to_instance_mapping": kernel_to_instance
                })
                return
            debug_log(f"📥 [WebSocketBridge] Response received", {
                "msg_id": msg_id,
                "instance_id": instance_id,
                "kernel_id": kernel_id,
                "response_type": response.get('header', {}).get('msg_type', 'unknown')
            })
            # Send response to frontend
            if self.broadcast_callback:
                await self.broadcast_callback({
                    'action': 'websocket_message',
                    'instanceId': instance_id,  # Use the actual instance ID
                    'kernelId': kernel_id,
                    'data': response,
                    'timestamp': datetime.datetime.now().isoformat()
                })
            # Remove from pending messages
            del self.pending_messages[msg_id]
        except Exception as e:
            debug_log(f"❌ [WebSocketBridge] Error handling response", {
                "msg_id": msg_id,
                "error": str(e),
                "error_type": type(e).__name__
            })
    async def _handle_status_update(self, kernel_id: str, message: Dict[str, Any]):
        """Handle kernel status update message."""
        try:
            execution_state = message.get('content', {}).get('execution_state', 'unknown')
            debug_log(f"📊 [WebSocketBridge] Status update", {
                "kernel_id": kernel_id,
                "status": execution_state
            })
            # Forward status update to frontend
            await self._forward_to_frontend(kernel_id, message, 'iopub')
        except Exception as e:
            debug_log(f"❌ [WebSocketBridge] Error handling status update", {
                "kernel_id": kernel_id,
                "error": str(e),
                "error_type": type(e).__name__
            })
    async def _handle_kernel_info(self, kernel_id: str, message: Dict[str, Any]):
        """Handle kernel info reply message."""
        try:
            debug_log(f"ℹ️ [WebSocketBridge] Kernel info received", {
                "kernel_id": kernel_id,
                "msg_id": message.get('header', {}).get('msg_id')
            })
            # Forward to all frontend instances
            await self._forward_to_frontend(kernel_id, message, 'shell') # Assuming kernel_info_reply is typically shell
        except Exception as e:
            debug_log(f"❌ [WebSocketBridge] Error handling kernel info", {
                "kernel_id": kernel_id,
                "error": str(e),
                "error_type": type(e).__name__
            })
    async def _handle_comm_message(self, kernel_id: str, message: Dict[str, Any], channel: str):
        """Handle comm messages and send echo responses."""
        try:
            content = message.get('content', {})
            comm_id = content.get('comm_id')
            data = content.get('data', {})
            method = data.get('method')
            msg_id = message.get('header', {}).get('msg_id')
            debug_log(f"🔗 [WebSocketBridge] Comm message received", {
                "kernel_id": kernel_id,
                "comm_id": comm_id,
                "method": method,
                "channel": channel,
                "msg_id": msg_id,
                "direction": "kernel_to_frontend" if channel == 'iopub' else "frontend_to_kernel"
            })
            # Track the most recent comm message for this kernel
            if channel == 'shell':
                self.most_recent_comm_messages[kernel_id] = {
                    'msg_id': msg_id,
                    'comm_id': comm_id,
                    'method': method,
                    'timestamp': datetime.datetime.now().isoformat()
                }
                debug_log(f"📝 [WebSocketBridge] Updated most recent comm message for kernel", {
                    "kernel_id": kernel_id,
                    "msg_id": msg_id,
                    "comm_id": comm_id,
                    "method": method
                })
            # Forward the original comm message to frontend
            await self._forward_to_frontend(kernel_id, message, channel)
            # If this is a frontend-to-kernel update message, send an echo response
            if channel == 'shell' and method == 'update':
                original_msg_id = message.get('header', {}).get('msg_id')
                await self._send_comm_echo_response(kernel_id, comm_id, data.get('state', {}), original_msg_id)
        except Exception as e:
            debug_log(f"❌ [WebSocketBridge] Error handling comm message", {
                "kernel_id": kernel_id,
                "channel": channel,
                "error": str(e),
                "error_type": type(e).__name__
            })
    async def _handle_comm_open(self, kernel_id: str, message: Dict[str, Any], channel: str):
        """Handle comm_open messages according to Jupyter protocol."""
        try:
            content = message.get('content', {})
            comm_id = content.get('comm_id')
            target_name = content.get('target_name')
            data = content.get('data', {})
            debug_log(f"🔗 [WebSocketBridge] Comm open received", {
                "kernel_id": kernel_id,
                "comm_id": comm_id,
                "target_name": target_name,
                "channel": channel,
                "direction": "kernel_to_frontend" if channel == 'iopub' else "frontend_to_kernel"
            })
            # Forward the comm_open message to frontend
            await self._forward_to_frontend(kernel_id, message, channel)
        except Exception as e:
            debug_log(f"❌ [WebSocketBridge] Error handling comm_open", {
                "kernel_id": kernel_id,
                "channel": channel,
                "error": str(e),
                "error_type": type(e).__name__
            })
    async def _handle_comm_close(self, kernel_id: str, message: Dict[str, Any], channel: str):
        """Handle comm_close messages according to Jupyter protocol."""
        try:
            content = message.get('content', {})
            comm_id = content.get('comm_id')
            data = content.get('data', {})
            debug_log(f"🔗 [WebSocketBridge] Comm close received", {
                "kernel_id": kernel_id,
                "comm_id": comm_id,
                "channel": channel,
                "direction": "kernel_to_frontend" if channel == 'iopub' else "frontend_to_kernel"
            })
            # Forward the comm_close message to frontend
            await self._forward_to_frontend(kernel_id, message, channel)
        except Exception as e:
            debug_log(f"❌ [WebSocketBridge] Error handling comm_close", {
                "kernel_id": kernel_id,
                "channel": channel,
                "error": str(e),
                "error_type": type(e).__name__
            })
    def _validate_jupyter_message(self, message: Dict[str, Any]) -> bool:
        """Validate that a message follows the Jupyter protocol structure."""
        try:
            # Check required top-level fields
            required_fields = ['header', 'parent_header', 'metadata', 'content', 'buffers']
            for field in required_fields:
                if field not in message:
                    debug_log(f"❌ [WebSocketBridge] Missing required field in Jupyter message", {
                        "field": field,
                        "message_keys": list(message.keys())
                    })
                    return False
            # Check header structure
            header = message.get('header', {})
            required_header_fields = ['msg_id', 'msg_type', 'session', 'username', 'version', 'date']
            for field in required_header_fields:
                if field not in header:
                    debug_log(f"❌ [WebSocketBridge] Missing required header field", {
                        "field": field,
                        "header_keys": list(header.keys())
                    })
                    return False
            # Validate msg_id is a string
            if not isinstance(header.get('msg_id'), str):
                debug_log(f"❌ [WebSocketBridge] msg_id must be a string", {
                    "msg_id": header.get('msg_id'),
                    "msg_id_type": type(header.get('msg_id'))
                })
                return False
            # Validate session is a string
            if not isinstance(header.get('session'), str):
                debug_log(f"❌ [WebSocketBridge] session must be a string", {
                    "session": header.get('session'),
                    "session_type": type(header.get('session'))
                })
                return False
            return True
        except Exception as e:
            debug_log(f"❌ [WebSocketBridge] Error validating Jupyter message", {
                "error": str(e),
                "error_type": type(e).__name__
            })
            return False
    def _create_jupyter_message(self, msg_type: str, content: Dict[str, Any], parent_header: Dict[str, Any] = None) -> Dict[str, Any]:
        """Create a properly formatted Jupyter message following the protocol."""
        try:
            # Generate proper UUIDs
            msg_id = str(uuid.uuid4())
            session_id = str(uuid.uuid4())
            # Create header
            header = {
                'msg_id': msg_id,
                'msg_type': msg_type,
                'session': session_id,
                'username': 'kernel',
                'version': '5.4',  # Current Jupyter protocol version
                'date': datetime.datetime.now().isoformat()
            }
            # Create parent header (copy of original message header)
            parent_header = parent_header or {}
            # Create message
            message = {
                'header': header,
                'parent_header': parent_header,
                'metadata': {},
                'content': content,
                'buffers': []
            }
            # Validate the message
            if not self._validate_jupyter_message(message):
                raise ValueError("Failed to create valid Jupyter message")
            return message
        except Exception as e:
            debug_log(f"❌ [WebSocketBridge] Error creating Jupyter message", {
                "msg_type": msg_type,
                "error": str(e),
                "error_type": type(e).__name__
            })
            raise
    async def _send_comm_echo_response(self, kernel_id: str, comm_id: str, state: Dict[str, Any], original_msg_id: str = None):
        """Send an echo response for a comm message."""
        try:
            # Create echo response message following Jupyter protocol
            content = {
                'comm_id': comm_id,
                'data': {
                    'method': 'echo_update',
                    'state': state
                }
            }
            # Create parent header if we have the original message ID
            parent_header = None
            if original_msg_id:
                parent_header = {
                    'msg_id': original_msg_id,
                    'msg_type': 'comm_msg',
                    'session': str(uuid.uuid4()),
                    'username': 'kernel',
                    'version': '5.4',
                    'date': datetime.datetime.now().isoformat()
                }
            echo_msg = self._create_jupyter_message('comm_msg', content, parent_header)
            debug_log(f"🔄 [WebSocketBridge] Sending comm echo response", {
                "kernel_id": kernel_id,
                "comm_id": comm_id,
                "state": state,
                "channel": "iopub"
            })
            # Forward echo response to frontend on IOPub channel
            await self._forward_to_frontend(kernel_id, echo_msg, 'iopub')
        except Exception as e:
            debug_log(f"❌ [WebSocketBridge] Error sending comm echo response", {
                "kernel_id": kernel_id,
                "comm_id": comm_id,
                "error": str(e),
                "error_type": type(e).__name__
            })
    async def _forward_to_frontend(self, kernel_id: str, message: Dict[str, Any], channel: str = 'shell'):
        """Forward message from Jupyter to frontend via WebRTC."""
        try:
            # Validate the Jupyter message structure
            if not self._validate_jupyter_message(message):
                debug_log(f"❌ [WebSocketBridge] Invalid Jupyter message structure, skipping forward", {
                    "kernel_id": kernel_id,
                    "channel": channel,
                    "message_keys": list(message.keys()) if isinstance(message, dict) else "not a dict"
                })
                return
            # Find the correct instance ID for this kernel
            instance_id = None
            # CRITICAL: Jupyter messages have a session field, not kernel_id
            # We need to map by session ID, not kernel ID
            session_id = message.get('header', {}).get('session')
            if session_id:
                debug_log(f"🔍 [WebSocketBridge] Message has session ID: {session_id}")
                debug_log(f"🔍 [WebSocketBridge] Frontend connections", {
                    "frontend_connections": self.frontend_connections
                })
                # Look for a frontend connection that matches this session
                # frontend_connections is a dictionary of we
                for frontend_instance_id, frontend_info in self.frontend_connections.items():
                    if frontend_info.get('session_id') == session_id:
                        instance_id = frontend_instance_id
                        debug_log(f"🔍 [WebSocketBridge] Found instance {instance_id} for session {session_id}")
                        break
                if not instance_id:
                    debug_log(f"⚠️ [WebSocketBridge] No frontend instance found for session {session_id}")
                    # Fall back to kernel_id mapping
                    pass
            # Fallback: Create a reverse mapping from kernel_id to instance_id
            if not instance_id:
                kernel_to_instance = {}
                for frontend_instance_id, frontend_info in self.frontend_connections.items():
                    if frontend_info.get('kernel_id'):
                        kernel_to_instance[frontend_info['kernel_id']] = frontend_instance_id
                        debug_log(f"🔍 [WebSocketBridge] Mapping kernel {frontend_info['kernel_id']} to instance {frontend_instance_id}")
                debug_log(f"🔍 [WebSocketBridge] Kernel to instance mapping", {
                    "kernel_id": kernel_id,
                    "kernel_to_instance": kernel_to_instance,
                    "target_instance_id": kernel_to_instance.get(kernel_id),
                    "all_kernel_ids": list(kernel_to_instance.keys())
                })
                # Look up the instance ID for this kernel
                instance_id = kernel_to_instance.get(kernel_id)
            if not instance_id:
                debug_log(f"⚠️ [WebSocketBridge] No frontend instance found for kernel", {
                    "kernel_id": kernel_id,
                    "available_instances": list(self.frontend_connections.keys()),
                    "frontend_connections": self.frontend_connections,
                    "kernel_to_instance_mapping": kernel_to_instance
                })
                return
            # Forward the original Jupyter message structure without modification
            # Channel is determined by message type, not added as a field
            message_for_frontend = {
                'action': 'websocket_message',
                'instanceId': instance_id,
                'kernelId': kernel_id,
                'channel': channel,  # Channel for routing purposes only
                'timestamp': datetime.datetime.now().isoformat(),
                # Preserve the original Jupyter message structure
                'msg': message  # Send the complete Jupyter message as-is
            }
            # If this is an output message (stream, clear_output, etc.) and we have a recent comm message,
            # add the comm message info to help with routing
            msg_type = message.get('header', {}).get('msg_type')
            if msg_type in ['stream', 'clear_output', 'display_data', 'execute_result'] and kernel_id in self.most_recent_comm_messages:
                recent_comm = self.most_recent_comm_messages[kernel_id]
                time_since_comm = (datetime.datetime.now() - datetime.datetime.fromisoformat(recent_comm['timestamp'])).total_seconds()
                # Only include if the comm message was recent (within 10 seconds)
                if time_since_comm < 10:
                    message_for_frontend['recent_comm_info'] = {
                        'msg_id': recent_comm['msg_id'],
                        'comm_id': recent_comm['comm_id'],
                        'method': recent_comm['method'],
                        'time_since_comm': time_since_comm
                    }
                    debug_log(f"📝 [WebSocketBridge] Added recent comm info to output message", {
                        "kernel_id": kernel_id,
                        "msg_type": msg_type,
                        "recent_comm_msg_id": recent_comm['msg_id'],
                        "recent_comm_id": recent_comm['comm_id'],
                        "time_since_comm": time_since_comm
                    })
            # debug_log(f"📤 [WebSocketBridge] Prepared message for frontend", {
            #     "message_structure": message_with_channel,
            #     "instanceId": instance_id,
            #     "kernelId": kernel_id,
            #     "channel": channel
            # })
            # Broadcast to all connected frontend instances
            if self.broadcast_callback:
                await self.broadcast_callback(message_for_frontend)
                debug_log(f"📤 [WebSocketBridge] Message forwarded to frontend", {
                    "kernel_id": kernel_id,
                    "instance_id": instance_id,
                    "instance_count": len(self.frontend_connections),
                    "msg_type": message.get('header', {}).get('msg_type', 'unknown'),
                    "channel": channel,
                    "message_structure": message_for_frontend
                })
            else:
                debug_log(f"⚠️ [WebSocketBridge] No broadcast callback available", {
                    "kernel_id": kernel_id,
                    "instance_id": instance_id,
                    "channel": channel
                })
        except Exception as e:
            debug_log(f"❌ [WebSocketBridge] Error forwarding message to frontend", {
                "kernel_id": kernel_id,
                "channel": channel,
                "error": str(e),
                "error_type": type(e).__name__
            })
    async def _notify_connection_status(self, kernel_id: str, status: str):
        """Notify frontend of connection status change."""
        try:
            if kernel_id not in self.jupyter_connections:
                return
            instance_ids = self.jupyter_connections[kernel_id]['instance_ids']
            for instance_id in instance_ids:
                if self.broadcast_callback:
                    await self.broadcast_callback({
                        'action': 'websocket_connected' if status == 'connected' else 'websocket_closed',
                        'instanceId': instance_id,
                        'kernelId': kernel_id,
                        'timestamp': datetime.datetime.now().isoformat()
                    })
        except Exception as e:
            debug_log(f"❌ [WebSocketBridge] Error notifying connection status", {
                "kernel_id": kernel_id,
                "status": status,
                "error": str(e),
                "error_type": type(e).__name__
            })
    def update_session_id(self, instance_id: str, session_id: str):
        """Update the session ID for a frontend connection."""
        try:
            if instance_id in self.frontend_connections:
                self.frontend_connections[instance_id]['session_id'] = session_id
                debug_log(f"📝 [WebSocketBridge] Updated session ID for instance {instance_id}: {session_id}")
            else:
                debug_log(f"⚠️ [WebSocketBridge] Instance {instance_id} not found when updating session ID")
        except Exception as e:
            debug_log(f"❌ [WebSocketBridge] Error updating session ID", {
                "instance_id": instance_id,
                "session_id": session_id,
                "error": str(e),
                "error_type": type(e).__name__
            })
    async def _process_kernel_messages(self, kernel_id: str):
        """Process messages from the message queue for a kernel."""
        try:
            if kernel_id not in self.message_queues:
                return
            queue = self.message_queues[kernel_id]
            while True:
                try:
                    # Get message from queue
                    message = await queue.get()
                    if message is None:  # Shutdown signal
                        break
                    # Process message
                    await self._process_message(kernel_id, message)
                except asyncio.CancelledError:
                    break
                except Exception as e:
                    debug_log(f"❌ [WebSocketBridge] Error processing message", {
                        "kernel_id": kernel_id,
                        "error": str(e),
                        "error_type": type(e).__name__
                    })
        except Exception as e:
            debug_log(f"❌ [WebSocketBridge] Error in message processor", {
                "kernel_id": kernel_id,
                "error": str(e),
                "error_type": type(e).__name__
            })
    async def _process_message(self, kernel_id: str, message: Dict[str, Any]):
        """Process a single message for a kernel."""
        try:
            # Extract message details
            instance_id = message.get('instanceId')
            data = message.get('data')
            if not instance_id or not data:
                debug_log(f"⚠️ [WebSocketBridge] Invalid message format", {
                    "kernel_id": kernel_id,
                    "message_keys": list(message.keys())
                })
                return
            # Send message to Jupyter server
            success = await self.send_message(instance_id, kernel_id, data)
            if success:
                debug_log(f"✅ [WebSocketBridge] Message processed successfully", {
                    "kernel_id": kernel_id,
                    "instance_id": instance_id
                })
            else:
                debug_log(f"❌ [WebSocketBridge] Failed to process message", {
                    "kernel_id": kernel_id,
                    "instance_id": instance_id
                })
        except Exception as e:
            debug_log(f"❌ [WebSocketBridge] Error processing message", {
                "kernel_id": kernel_id,
                "error": str(e),
                "error_type": type(e).__name__
            })
    async def _close_jupyter_connection(self, kernel_id: str):
        """Close WebSocket connection to Jupyter server."""
        try:
            if kernel_id in self.jupyter_connections:
                websocket = self.jupyter_connections[kernel_id]['websocket']
                if websocket:
                    await websocket.close()
                del self.jupyter_connections[kernel_id]
                debug_log(f"🔌 [WebSocketBridge] Jupyter connection closed", {
                    "kernel_id": kernel_id
                })
        except Exception as e:
            debug_log(f"❌ [WebSocketBridge] Error closing Jupyter connection", {
                "kernel_id": kernel_id,
                "error": str(e),
                "error_type": type(e).__name__
            })
    def _build_websocket_url(self, url: str, kernel_id: str = None, channel: str = None) -> str:
        """Build WebSocket URL from HTTP URL."""
        if url.startswith('http://'):
            base_url = url.replace('http://', 'ws://')
        elif url.startswith('https://'):
            base_url = url.replace('https://', 'wss://')
        else:
            # Assume localhost if no protocol
            base_url = f"ws://localhost:8888"
        # Add kernel WebSocket endpoint
        if not base_url.endswith('/'):
            base_url += '/'
        if kernel_id:
            # Use the standard Jupyter kernel WebSocket endpoint
            # This single endpoint handles all channels (shell, iopub, stdin, control)
            ws_url = f"{base_url}api/kernels/{kernel_id}/channels"
        else:
            ws_url = f"{base_url}api/kernels"
        debug_log(f"🔗 [WebSocketBridge] Built WebSocket URL", {
            "base_url": base_url,
            "kernel_id": kernel_id,
            "channel": channel,
            "ws_url": ws_url
        })
        return ws_url
    def get_status(self) -> Dict[str, Any]:
        """Get WebSocket bridge status."""
        return {
            'jupyter_connections': len(self.jupyter_connections),
            'frontend_connections': len(self.frontend_connections),
            'pending_messages': len(self.pending_messages),
            'connection_states': dict(self.connection_states),
            'active_processors': len(self.message_processor_tasks)
        }
    async def cleanup(self):
        """Clean up WebSocket bridge resources."""
        debug_log(f"🧹 [WebSocketBridge] Cleaning up WebSocket bridge")
        try:
            # Cancel all message processor tasks
            for task in self.message_processor_tasks.values():
                if not task.done():
                    task.cancel()
                    try:
                        await task
                    except asyncio.CancelledError:
                        pass
            # Close all Jupyter connections
            for kernel_id in list(self.jupyter_connections.keys()):
                await self._close_jupyter_connection(kernel_id)
            # Clear all data structures
            self.jupyter_connections.clear()
            self.frontend_connections.clear()
            self.connection_states.clear()
            self.pending_messages.clear()
            self.message_queues.clear()
            self.message_processor_tasks.clear()
            debug_log(f"🧹 [WebSocketBridge] WebSocket bridge cleanup completed")
        except Exception as e:
            debug_log(f"❌ [WebSocketBridge] Error during cleanup", {
                "error": str(e),
                "error_type": type(e).__name__
            })
    async def _cleanup_old_messages(self):
        """Clean up old processed messages to prevent memory leaks."""
        try:
            # Keep only the last 1000 processed messages
            if len(self.processed_messages) > 1000:
                # Convert to list and keep only the most recent 1000
                processed_list = list(self.processed_messages)
                self.processed_messages = set(processed_list[-1000:])
                debug_log(f"🧹 [WebSocketBridge] Cleaned up processed messages", {
                    "old_count": len(processed_list),
                    "new_count": len(self.processed_messages)
                })
            # Clean up comm message tracker (keep only active comms)
            if len(self.comm_message_tracker) > 100:
                # Remove comms with no recent activity
                current_time = datetime.datetime.now()
                comms_to_remove = []
                for comm_id, msg_ids in self.comm_message_tracker.items():
                    if len(msg_ids) > 50:  # Too many messages for one comm
                        comms_to_remove.append(comm_id)
                for comm_id in comms_to_remove:
                    del self.comm_message_tracker[comm_id]
                if comms_to_remove:
                    debug_log(f"🧹 [WebSocketBridge] Cleaned up comm message tracker", {
                        "removed_comms": len(comms_to_remove),
                        "remaining_comms": len(self.comm_message_tracker)
                    })
        except Exception as e:
            debug_log(f"❌ [WebSocketBridge] Error during message cleanup", {
                "error": str(e),
                "error_type": type(e).__name__
            })
    async def _cleanup_kernel_messages(self, kernel_id: str):
        """Clean up message tracking for a specific kernel."""
        try:
            # Remove pending messages for this kernel
            pending_to_remove = []
            for msg_id, pending_msg in self.pending_messages.items():
                if pending_msg.get('kernel_id') == kernel_id:
                    pending_to_remove.append(msg_id)
            for msg_id in pending_to_remove:
                del self.pending_messages[msg_id]
            if pending_to_remove:
                debug_log(f"🧹 [WebSocketBridge] Cleaned up pending messages for kernel", {
                    "kernel_id": kernel_id,
                    "removed_count": len(pending_to_remove)
                })
        except Exception as e:
            debug_log(f"❌ [WebSocketBridge] Error cleaning up kernel messages", {
                "kernel_id": kernel_id,
                "error": str(e),
                "error_type": type(e).__name__
            })
</file>

</files>
